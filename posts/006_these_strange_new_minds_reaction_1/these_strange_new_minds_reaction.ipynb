{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d25af-a503-418c-8fda-d8cc34888daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: My Thoughts on These Strange New Minds\n",
    "description: \"Intro & Section 1\"\n",
    "author: \"Eric Zou\"\n",
    "date: \"9/19/2025\"\n",
    "categories:\n",
    "  - Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875b8cf-966e-41ad-996e-3da96a96a15c",
   "metadata": {},
   "source": [
    "## What It's About\n",
    "From what I've read so far, it seems like the book is about where large language model (LLM) technology is headed, and how it's different from what we've seen before. Christopher Summerfield (the author) spends the first section explaining the development of this technology. He cites historical examples of how humans have approached trying to imitate our own thinking ability. He starts with attempted constructions of thinking machines and moves into the modern era where new discoveries in neurons and computational modeling have allowed us to train large-scale deep neural networks to learn from massive datasets and generalize on unseen cases. Along the way, he contrasts two modes of thought, one being the rationalist/logical approach to thinking that was originally championed (expressing our understanding of the world in formal rules and logic) and the other being the empricist view, in which we learn continuously from experience in a way that doesn't restrict itself to structure from the start. In the last chapter of this section, Summerfield leads into the development of the GPT series of LLMs, which I assume leads into an exploration into this novel technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a64af-1f0f-4a85-ad47-3012fe47121d",
   "metadata": {},
   "source": [
    "## What I Thought\n",
    "I think that the section was pretty well-written. I haven't read much print text lately, so I don't think it could compare to any book directly. However, I thought the narrative was engaging enough to keep me reading, which is more than I can say for some other nonfiction books that I've read. I thought the conflict between the rationalist and empiricist approaches in knowledge were contrasted. I think it's interesting how the huge breakthrough in GPT began as the training of a practical deep learning system, but now in current events we're moving back to some rationalist, structured approaches like chain-of-thought prompting in order to emulate thinking much better. Summerfield brings up chess and ice skating as examples of the rationalist vs. empiricist approach in our lives, and he introduces the idea that our thinking may be a mix of both. I definitely think that's the case, though I'm not sure if I could prove that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d5682-91c1-4ca1-a951-e59a3a721b7b",
   "metadata": {},
   "source": [
    "## Reflecting\n",
    "Even reading the intro of this book has made me pretty appreciative of where we've come from. Certainly, I'm a bit apprehensive about where we're going with this technology and the multiple ways in which it could be misused or go haywire. At the same time, I think that with this breakthrough there's much more that we'll be able to do with this tool. AI might be able to help in the same way that the Internet complemented many people's jobs and allowed so many more people to access information cheaply, enhancing people's creativity by empowering people to understand difficult concepts without the super extensive technical backgrounds that others have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
