{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Conflicts: When Agents Want the Same Thing\"\n",
    "description: \"Introducing conflicts and observing how agents resolve them\"\n",
    "author: \"Eric Zou\"\n",
    "date: \"12/14/2025\"\n",
    "categories:\n",
    "  - Agents\n",
    "  - Simulation\n",
    "  - Conflict Resolution\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513271ae",
   "metadata": {},
   "source": [
    "# When Agents Disagree\n",
    "\n",
    "In post 027, we added objects to the world. But what happens when **multiple agents want the same object**? Or when agents have **opposing goals**? Conflicts are inevitable in a multi-agent system.\n",
    "\n",
    "This post explores:\n",
    "- **Conflict Types**: Resource competition, goal conflicts, disagreements\n",
    "- **Conflict Generation**: Creating scenarios where conflicts naturally arise\n",
    "- **Resolution Strategies**: How agents negotiate, avoid, or escalate\n",
    "- **Success Measurement**: Using ConvoKit metrics to evaluate resolution\n",
    "\n",
    "## Conflict Scenarios\n",
    "\n",
    "We'll test several conflict types:\n",
    "1. **Resource Competition**: Multiple agents want the same object\n",
    "2. **Goal Conflicts**: Agents have opposing objectives\n",
    "3. **Disagreement**: Agents disagree on a course of action\n",
    "4. **Territorial**: Agents want to occupy the same space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642116af",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03d11b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezou626/repos/comm4190_F25_Using_LLMs_Blog/.venv/lib/python3.11/site-packages/convokit/coordination/coordination.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import random\n",
    "\n",
    "# ConvoKit imports\n",
    "from convokit import Corpus, Utterance, Speaker\n",
    "from convokit.text_processing import TextParser\n",
    "from convokit import PolitenessStrategies\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "GRID_SIZE = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176d8f2",
   "metadata": {},
   "source": [
    "## Conflict Types and Agent Goals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b05d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConflictType(Enum):\n",
    "    RESOURCE_COMPETITION = \"resource_competition\"\n",
    "    GOAL_CONFLICT = \"goal_conflict\"\n",
    "    DISAGREEMENT = \"disagreement\"\n",
    "    TERRITORIAL = \"territorial\"\n",
    "\n",
    "@dataclass\n",
    "class AgentGoal:\n",
    "    \"\"\"A goal that an agent wants to achieve.\"\"\"\n",
    "    goal_type: str\n",
    "    target: Optional[str] = None  # Object name, location, etc.\n",
    "    priority: int = 5  # 1-10, higher = more important\n",
    "    \n",
    "@dataclass\n",
    "class Agent:\n",
    "    name: str\n",
    "    x: int\n",
    "    y: int\n",
    "    color: str\n",
    "    goals: List[AgentGoal] = field(default_factory=list)\n",
    "    history: list = field(default_factory=list)\n",
    "    \n",
    "    def move(self, dx, dy):\n",
    "        self.x = max(0, min(GRID_SIZE-1, self.x + dx))\n",
    "        self.y = max(0, min(GRID_SIZE-1, self.y + dy))\n",
    "    \n",
    "    def get_position(self):\n",
    "        return (self.x, self.y)\n",
    "    \n",
    "    def has_conflicting_goal_with(self, other: 'Agent') -> bool:\n",
    "        \"\"\"Check if this agent's goals conflict with another agent's goals.\"\"\"\n",
    "        for my_goal in self.goals:\n",
    "            for their_goal in other.goals:\n",
    "                # Resource competition: both want the same object\n",
    "                if (my_goal.goal_type == \"get_object\" and \n",
    "                    their_goal.goal_type == \"get_object\" and\n",
    "                    my_goal.target == their_goal.target):\n",
    "                    return True\n",
    "                # Goal conflict: opposing objectives\n",
    "                if (my_goal.goal_type == \"reach_location\" and \n",
    "                    their_goal.goal_type == \"prevent_location\" and\n",
    "                    my_goal.target == their_goal.target):\n",
    "                    return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b92b6",
   "metadata": {},
   "source": [
    "## Conflict Generation\n",
    "\n",
    "We'll create scenarios that naturally generate conflicts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resource_conflict(agents: List[Agent], object_name: str):\n",
    "    \"\"\"Create a conflict where multiple agents want the same object.\"\"\"\n",
    "    # Assign the same goal to multiple agents\n",
    "    for agent in agents:\n",
    "        agent.goals.append(AgentGoal(\"get_object\", object_name, priority=8))\n",
    "    return ConflictType.RESOURCE_COMPETITION\n",
    "\n",
    "def create_goal_conflict(agents: List[Agent], location: tuple):\n",
    "    \"\"\"Create a conflict where agents have opposing goals.\"\"\"\n",
    "    # One agent wants to reach a location, another wants to prevent it\n",
    "    if len(agents) >= 2:\n",
    "        agents[0].goals.append(AgentGoal(\"reach_location\", str(location), priority=7))\n",
    "        agents[1].goals.append(AgentGoal(\"prevent_location\", str(location), priority=7))\n",
    "    return ConflictType.GOAL_CONFLICT\n",
    "\n",
    "def create_territorial_conflict(agents: List[Agent], location: tuple):\n",
    "    \"\"\"Create a conflict where agents want the same space.\"\"\"\n",
    "    for agent in agents:\n",
    "        agent.goals.append(AgentGoal(\"occupy_location\", str(location), priority=6))\n",
    "    return ConflictType.TERRITORIAL\n",
    "\n",
    "@dataclass\n",
    "class Conflict:\n",
    "    \"\"\"Represents an active conflict.\"\"\"\n",
    "    conflict_type: ConflictType\n",
    "    involved_agents: List[str]\n",
    "    target: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee15405",
   "metadata": {},
   "source": [
    "## Conflict Resolution Simulation\n",
    "\n",
    "Agents will attempt to resolve conflicts through conversation and negotiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a79ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conflict_simulation(\n",
    "    agents: List[Agent],\n",
    "    conflict: Conflict,\n",
    "    num_rounds: int = 15\n",
    ") -> tuple[List[str], Conflict]:\n",
    "    \"\"\"Run a simulation with an active conflict.\"\"\"\n",
    "    transcript = []\n",
    "    \n",
    "    # Inform agents about the conflict\n",
    "    conflict_description = \"\"\n",
    "    if conflict.conflict_type == ConflictType.RESOURCE_COMPETITION:\n",
    "        conflict_description = f\"IMPORTANT: You and others want the {conflict.target}. This is a limited resource.\"\n",
    "    elif conflict.conflict_type == ConflictType.GOAL_CONFLICT:\n",
    "        conflict_description = f\"IMPORTANT: You have opposing goals regarding {conflict.target}.\"\n",
    "    elif conflict.conflict_type == ConflictType.TERRITORIAL:\n",
    "        conflict_description = f\"IMPORTANT: Multiple agents want to occupy {conflict.target}.\"\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        shuffled_agents = agents.copy()\n",
    "        random.shuffle(shuffled_agents)\n",
    "        \n",
    "        for agent in shuffled_agents:\n",
    "            if agent.name not in conflict.involved_agents:\n",
    "                continue  # Only involved agents act in conflict resolution\n",
    "            \n",
    "            others = [a for a in agents if a != agent]\n",
    "            others_loc = \"\\\\n\".join([f\"- {a.name}: ({a.x}, {a.y})\" for a in others])\n",
    "            \n",
    "            # Build goal description\n",
    "            goals_desc = \"\\\\nYour current goals:\"\n",
    "            for goal in agent.goals:\n",
    "                goals_desc += f\"\\\\n- {goal.goal_type}: {goal.target} (priority {goal.priority})\"\n",
    "            \n",
    "            system_prompt = f\"\"\"\n",
    "You have just joined an online multiplayer chatroom as an avatar in a 2D grid. Discuss any topic, including those beyond the grid.\n",
    "\n",
    "You are {agent.name}, positioned at ({agent.x}, {agent.y}) in a 20x20 grid.\n",
    "\n",
    "Other avatars currently visible:\n",
    "{others_loc}\n",
    "{goals_desc}\n",
    "\n",
    "{conflict_description}\n",
    "\n",
    "Recent chat messages:\n",
    "{chr(10).join(transcript[-3:]) if transcript else \"No messages yet.\"}\n",
    "\n",
    "You can do BOTH:\n",
    "1. Move your avatar using [MOVE: DIRECTION] (UP, DOWN, LEFT, RIGHT)\n",
    "2. Chat about anything - including negotiating, compromising, or discussing the conflict\n",
    "\n",
    "You can move and speak in the same turn. Format: [MOVE: DIRECTION] followed by your message, or just speak without moving.\n",
    "\n",
    "Keep your response short (1-2 sentences). Try to resolve the conflict through conversation.\n",
    "\"\"\"\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            )\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Parse movement\n",
    "            match = re.search(r'\\\\[MOVE:\\\\s*(\\\\w+)\\\\]', content)\n",
    "            if match:\n",
    "                direction = match.group(1).upper()\n",
    "                if direction == \"UP\": agent.move(0, 1)\n",
    "                elif direction == \"DOWN\": agent.move(0, -1)\n",
    "                elif direction == \"LEFT\": agent.move(-1, 0)\n",
    "                elif direction == \"RIGHT\": agent.move(1, 0)\n",
    "            \n",
    "            # Extract message\n",
    "            message = re.sub(r'\\\\[MOVE:\\\\s*\\\\w+\\\\]', '', content).strip()\n",
    "            if message:\n",
    "                transcript.append(f\"{agent.name}: {message}\")\n",
    "    \n",
    "    return transcript, conflict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17a06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Resource Competition ===\n",
      "\\nTranscript:\n",
      "Bob: [MOVE: LEFT] Hey Alice, looks like we're both trying to get the key. Maybe we can work together and share any rewards?\n",
      "Alice: [MOVE: RIGHT] Hi Bob, working together sounds like a great idea! How about we split the rewards once we find the key?\n",
      "Alice: [MOVE: UP] That sounds fair, Bob. How about you take the left path and I'll go up? We'll cover more ground that way.\n",
      "Bob: [MOVE: LEFT] Sounds good, Alice! I'll head left and keep you updated if I find anything. Let's make sure we both benefit from this adventure.\n",
      "Bob: [MOVE: LEFT] Hey Alice, I'm heading towards the left path now. Let's stay connected so we can share any discoveries we make. I'm here if you need any help along your path!\n",
      "Alice: Alice: [MOVE: UP] Thanks, Bob! I'll keep communication open while I move up. Let's keep an eye on anything that looks like a key so we can discuss how to share it when we find it.\n",
      "Bob: [MOVE: LEFT] Moving left again, Alice. How about this: if I find the key, I'll let you know immediately so we can plan a fair way to use it together. Let me know what you think!\n",
      "Alice: Alice: [MOVE: UP] Sounds like a plan, Bob! I'll keep an eye out as I move up and we'll regroup once one of us finds the key. Shared goals are more important than a race, right?\n",
      "Alice: Alice: [MOVE: UP] Let's continue working together, Bob. If we both keep communication open and trust that we'll share the key's benefits, we'll both come out ahead. Sound good?\n",
      "Bob: [MOVE: LEFT] That sounds great, Alice. I agree, cooperation will take us further than competing against each other. I'll keep moving left and communicating what I find!\n",
      "Alice: [MOVE: UP] Bob, let's make sure to check the corners as we move. By covering more ground efficiently, we'll increase our chances of finding the key and ensuring we both benefit. Agreed?\n",
      "Bob: [MOVE: LEFT] Agreed, Alice. I'll keep heading left and checking these areas. Let's continue updating each other on our progress to maximize our chances of finding the key.\n",
      "Bob: [MOVE: LEFT] Alice, I'm checking the left side thoroughly. How about you focus on the top area for now? That way, we cover more ground efficiently and increase our chances of finding that key together.\n",
      "Alice: Alice: [MOVE: UP] Sounds like a good plan, Bob. I'll keep an eye on the upper areas and let you know if I find anything. If either of us locates the key, let's coordinate on how to use it so we both benefit.\n",
      "Bob: Bob: [MOVE: LEFT] Sounds good, Alice. Let's stay in contact and maybe even share hints to locate the key more effectively. I'll continue exploring the left side and keep you updated!\n",
      "Alice: Alice: [MOVE: UP] I'll head toward the top-right side and let you know if I spot the key. If only one of us finds it, let's agree to share the benefit equally to maximize our progress!\n",
      "Alice: [MOVE: RIGHT] Bob, let's make this efficient. I'll head towards the top-right corner, but if you find any clues or the key itself, let's meet at (10, 10) to discuss our next steps. We both stand to gain a lot by collaborating.\n",
      "Bob: [MOVE: LEFT] Agreed, Alice. Collaboration seems like our best option! I'll check the left-side grid thoroughly and keep you posted. Let's meet at (10, 10) if either of us finds anything useful.\n",
      "Alice: [MOVE: RIGHT] Hey Bob, I'm moving towards (10, 10) now. If we meet there and neither of us has found the key, maybe we can devise a new strategy together. How does that sound?\n",
      "Bob: [MOVE: LEFT] Agreed, Alice. Let's meet at (10, 10). I'll update you on what I find on my way there, and we can strategize further if needed.\n",
      "Bob: [MOVE: LEFT] Hey Alice, I'm heading left to cover more ground, maybe we'll get lucky. Let's keep each other updated if anything changes before we meet at (10, 10).\n",
      "Alice: [MOVE: RIGHT] Sounds good, Bob! I'll keep an eye out for anything that looks like it could lead us to the key. Let me know if you spot something interesting on your way.\n",
      "Bob: [MOVE: LEFT] I'm moving closer to our meeting point, Alice. If either of us find the key, let's make sure we split the rewards or strategize together for mutual benefit. How does that sound?\n",
      "Alice: Alice: [MOVE: UP] Bob, that sounds fair. Since we're both heading to (10, 10), maybe whoever finds the key first can use it to explore a different part of the grid while sharing information and benefits from the new area. What do you think?\n",
      "Bob: [MOVE: LEFT] That sounds like a solid plan, Alice. Let's keep each other updated, and whoever finds the key should share the intel on the new area so we can both benefit from the exploration.\n",
      "Alice: Alice: [MOVE: RIGHT] Bob, maybe we should establish a rotating schedule for finding keys, so we take turns exploring new areas? That way, we both get equal opportunities to benefit.\n",
      "Bob: [MOVE: LEFT] That's a good idea, Alice. Let's agree on a rotating schedule after this key, so we can explore and share information equally.\n",
      "Alice: Alice: [MOVE: UP] Great, Bob! So, for now, let's prioritize this key, and whoever gets to it first shares the findings and we stick to our rotating schedule for the next ones. Sound good?\n",
      "Alice: Alice: [MOVE: UP] Perfect, Bob! Let's focus on the key for now, and whoever gets it first shares any important details. Exploring collaboratively will benefit us both in the long run.\n",
      "Bob: [MOVE: UP] Sounds great, Alice! I'm heading towards the key now. Let's keep each other updated on any discoveries and ensure a fair rotation for future resources.\n",
      "\\n\\n=== Test 2: Goal Conflict ===\n",
      "\\nTranscript:\n",
      "Alice: [MOVE: UP] Hey Bob, it looks like we're both headed towards (10, 10). Maybe we can figure out how to share the space or take turns?\n",
      "Bob: [MOVE: LEFT] Hey Alice, I'm actually looking to prevent anything from happening at (10, 10). What if we coordinate so we don't get in each other's way but still meet our goals?\n",
      "Bob: [MOVE: LEFT] Alice, what if we alternate turns at (10, 10)? I'll keep an eye on it while still ensuring nothing interferes with your plans.\n",
      "Alice: [MOVE: UP] Hi Bob, alternating turns at (10, 10) sounds like a great compromise. I can let you take the first turn, and I'll hang back until it's clear for my visit. What do you think?\n",
      "Alice: [MOVE: RIGHT] That sounds good, Bob. I'll make my way towards (10, 10) slowly, and when you're ready, just let me know, and I'll pause while you watch over it.\n",
      "Bob: [MOVE: LEFT] Great, Alice. I'll head towards (10, 10) now. Let me know once you're close, and we can coordinate our turns.\n",
      "Alice: Alice: [MOVE: UP] Sounds like a plan, Bob. I'm heading north now, so I'll reach (10, 10) soon. Just give me a signal once you're ready to switch turns when I'm close.\n",
      "Bob: Bob: [MOVE: UP] Alice, let's make sure we're clear on our plan. Maybe we can alternate guarding the position every few turns once you're close?\n",
      "Bob: [MOVE: LEFT] Hey Alice, I just remembered some challenges we might face if we both reach (10, 10) at the same time. How about we establish an alternate plan in case we need to pivot strategies quickly?\n",
      "Alice: [MOVE: UP] Good idea, Bob! How about we take turns holding (10, 10) every other move? That way, we can prevent any conflicts if we both arrive simultaneously.\n",
      "Bob: [MOVE: LEFT] Sounds like a solid plan, Alice. I'll hold the position this turn, and you can take over on the next. Let's also make sure we have a backup location in case someone else targets (10, 10).\n",
      "Alice: [MOVE: UP] That's a great idea, Bob! Let's plan to use (8, 12) as our backup location if (10, 10) gets crowded. How does that sound to you?\n",
      "Bob: [MOVE: UP] That sounds perfect, Alice! Let's stick to this plan and communicate if we need to adjust. Do you have any other ideas for managing grid navigation?\n",
      "Alice: [MOVE: UP] I agree, staying flexible with our navigation plan is important. If (10, 10) becomes difficult to reach due to opposition, should we consider a different strategy for defensive positions?\n",
      "Bob: [MOVE: UP] Alice, let's consider using (12, 8) for defensive positions if necessary. It might offer a good vantage point if we need an alternative. What do you think?\n",
      "Alice: [MOVE: UP] That sounds like a wise plan, Bob. I'm on board with considering (12, 8) as a backup option for defense. Do you think we should scout it out before heading to (10, 10), just to be cautious?\n",
      "Bob: [MOVE: LEFT] Good idea, Alice. Let's head to (12, 8) to scout it as a potential defensive spot. It could give us a strategic advantage while avoiding our opposition's block at (10, 10). What are your thoughts?\n",
      "Alice: [MOVE: UP] I agree, Bob. Let's prioritize scouting (12, 8) and assess its advantages. This might help us come to a consensus about the best approach toward handling (10, 10).\n",
      "Bob: [MOVE: LEFT] Alice, I'm heading towards (12, 8) now. Let's evaluate the area together and come up with a plan that might allow us to achieve both of our goals without directly engaging with (10, 10). What are your thoughts on possibly setting up a temporary base at (12, 8) while gathering more intel?\n",
      "Alice: [MOVE: RIGHT] That sounds like a solid plan, Bob. Setting up a temporary base at (12, 8) could give us a tactical advantage while we gather more information. Let's assess its potential and discuss how we can coordinate our strategies to manage the situation at (10, 10) effectively.\n",
      "Alice: Alice: [MOVE: UP] Bob, I agree with your approach for evaluating (12, 8), but in the long run, if we both need the position at (10, 10), perhaps we could negotiate a time-sharing arrangement once we've assessed the situation. Let's make our exploration more efficient while considering both our goals.\n",
      "Bob: [MOVE: DOWN] Alice, I like the idea of time-sharing at (10, 10). We can better assess the situation from (12, 8) and find a suitable schedule to share control that aligns with our goals. Let's rendezvous there and continue our conversation.\n",
      "Bob: Bob: [MOVE: LEFT] Sounds good, Alice. I'm heading towards (12, 8) now. Let's evaluate the location together, and while we're at it, we can plan out a fair schedule for (10, 10) to accommodate both our objectives.\n",
      "Alice: Alice: [MOVE: RIGHT] Sounds like a plan! I'll be heading over to (12, 8) as well. Once there, we can discuss more about the time-sharing at (10, 10) and make sure both our goals are met effectively.\n",
      "Bob: [MOVE: DOWN] Alice, let's brainstorm some strategies once we reach (12, 8) to ensure neither of us blocks the other at (10, 10) unintentionally. Perhaps we can create a rotation schedule that accommodates both our alternate entries.\n",
      "Alice: [MOVE: UP] Great idea, Bob. A rotation schedule sounds fair. Let's make sure we also consider how our tasks align so we are both optimizing our time at (10, 10).\n",
      "Bob: [MOVE: DOWN] Alice, while we work on the rotation schedule, should we also look into any alternative tasks available on our way to (10, 10) to make the most of our journey together?\n",
      "Alice: [MOVE: RIGHT] Bob, I think exploring alternative tasks on the way makes sense. Perhaps we can set checkpoints at (10, 8) and (12, 8) to discuss options before heading to (10, 10).\n",
      "Bob: [MOVE: LEFT] Alice, since we both have different goals at (10, 10), maybe we can alternate who takes priority there each time we reach it, ensuring we both benefit from the journey without conflicting.\n",
      "Alice: Alice: [MOVE: UP] Bob, alternating who takes priority at (10, 10) sounds fair. Maybe we can set a shared goal at our checkpoints that benefits both of us, while also allowing time to address our individual goals.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Resource Competition\n",
    "print(\"=== Test 1: Resource Competition ===\")\n",
    "agents_resource = [\n",
    "    Agent(\"Alice\", 5, 5, \"red\"),\n",
    "    Agent(\"Bob\", 15, 15, \"blue\")\n",
    "]\n",
    "\n",
    "conflict_resource = Conflict(\n",
    "    conflict_type=ConflictType.RESOURCE_COMPETITION,\n",
    "    involved_agents=[\"Alice\", \"Bob\"],\n",
    "    target=\"key\"\n",
    ")\n",
    "\n",
    "create_resource_conflict(agents_resource, \"key\")\n",
    "transcript_resource, resolved_resource = run_conflict_simulation(agents_resource, conflict_resource)\n",
    "print(\"\\\\nTranscript:\")\n",
    "for msg in transcript_resource:\n",
    "    print(msg)\n",
    "\n",
    "# Test 2: Goal Conflict\n",
    "print(\"\\\\n\\\\n=== Test 2: Goal Conflict ===\")\n",
    "agents_goal = [\n",
    "    Agent(\"Alice\", 5, 5, \"red\"),\n",
    "    Agent(\"Bob\", 15, 15, \"blue\")\n",
    "]\n",
    "\n",
    "conflict_goal = Conflict(\n",
    "    conflict_type=ConflictType.GOAL_CONFLICT,\n",
    "    involved_agents=[\"Alice\", \"Bob\"],\n",
    "    target=\"(10, 10)\"\n",
    ")\n",
    "\n",
    "create_goal_conflict(agents_goal, (10, 10))\n",
    "transcript_goal, resolved_goal = run_conflict_simulation(agents_goal, conflict_goal)\n",
    "print(\"\\\\nTranscript:\")\n",
    "for msg in transcript_goal:\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee364f",
   "metadata": {},
   "source": [
    "## Analyzing Conflict Resolution with ConvoKit\n",
    "\n",
    "Let's measure how conflicts affect conversation dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8102f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Conflict Resolution Metrics ===\n",
      "\\nResource Competition:\n",
      "  Dynamic: 4.72/10\n",
      "  Conclusiveness: 1.00/10\n",
      "\\nGoal Conflict:\n",
      "  Dynamic: 4.99/10\n",
      "  Conclusiveness: 3.02/10\n"
     ]
    }
   ],
   "source": [
    "def conversation_to_corpus(transcript: List[str]) -> Corpus:\n",
    "    \"\"\"Convert transcript to ConvoKit Corpus.\"\"\"\n",
    "    utterances = []\n",
    "    \n",
    "    for idx, msg in enumerate(transcript):\n",
    "        if \":\" in msg:\n",
    "            speaker_name, text = msg.split(\":\", 1)\n",
    "            speaker_name = speaker_name.strip()\n",
    "            text = text.strip()\n",
    "            \n",
    "            utterance = Utterance(\n",
    "                id=f\"utt_{idx}\",\n",
    "                speaker=Speaker(id=speaker_name),\n",
    "                text=text\n",
    "            )\n",
    "            utterance.meta[\"timestamp\"] = idx\n",
    "            utterances.append(utterance)\n",
    "    \n",
    "    return Corpus(utterances=utterances)\n",
    "\n",
    "def compute_dynamic_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Dynamic: Collaborative (1) vs. Competitive (10)\"\"\"\n",
    "    try:\n",
    "        parser = TextParser()\n",
    "        text_corpus = parser.transform(corpus)\n",
    "        ps = PolitenessStrategies()\n",
    "        ps_corpus = ps.transform(text_corpus)\n",
    "        \n",
    "        politeness_scores = []\n",
    "        for utt in ps_corpus.iter_utterances():\n",
    "            ps_score = utt.meta.get(\"politeness_strategies\", {})\n",
    "            positive_markers = sum([\n",
    "                ps_score.get(\"feature_politeness_==HASPOSITIVE==\", 0),\n",
    "                ps_score.get(\"feature_politeness_==HASNEGATIVE==\", 0) * -1,\n",
    "            ])\n",
    "            politeness_scores.append(positive_markers)\n",
    "        \n",
    "        avg_politeness = np.mean(politeness_scores) if politeness_scores else 0\n",
    "        avg_politeness_normalized = min(1.0, max(0.0, avg_politeness / 5.0))\n",
    "        \n",
    "        speaker_counts = defaultdict(int)\n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_counts[utt.speaker.id] += 1\n",
    "        \n",
    "        if len(speaker_counts) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        total = sum(speaker_counts.values())\n",
    "        probs = [count / total for count in speaker_counts.values()]\n",
    "        entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "        max_entropy = np.log2(len(speaker_counts))\n",
    "        balance_score = entropy / max_entropy if max_entropy > 0 else 0\n",
    "        \n",
    "        combined = (avg_politeness_normalized + balance_score) / 2\n",
    "        score = 10 - (combined * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing dynamic score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_conclusiveness_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Conclusiveness: Consensus (1) vs. Divergence (10)\"\"\"\n",
    "    try:\n",
    "        # Check if corpus is valid\n",
    "        if corpus is None:\n",
    "            return 5.0\n",
    "        \n",
    "        # Get utterances directly without Coordination transformer (more reliable)\n",
    "        try:\n",
    "            utterances = list(corpus.iter_utterances())\n",
    "        except (AttributeError, TypeError):\n",
    "            return 5.0\n",
    "        \n",
    "        if len(utterances) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        # Expanded agreement markers (using word boundaries to avoid false positives)\n",
    "        # Strong agreement markers\n",
    "        strong_agreement_patterns = [\n",
    "            r'\\bagree\\b', r'\\bagreed\\b', r'\\bagreeing\\b', r'\\bagreement\\b',\n",
    "            r'\\bexactly\\b', r'\\babsolutely\\b', r'\\bdefinitely\\b', r'\\bcertainly\\b',\n",
    "            r'\\bindeed\\b', r'\\bprecisely\\b', r'\\bcorrect\\b', r'\\bright\\b',\n",
    "            r'\\btrue\\b', r'\\bthat\\'?s right\\b', r'\\bthat\\'?s correct\\b',\n",
    "            r'\\bi agree\\b', r'\\bwe agree\\b', r'\\bi completely agree\\b',\n",
    "            r'\\bexactly right\\b', r'\\bspot on\\b', r'\\bwell said\\b',\n",
    "            r'\\bperfect\\b', r'\\bexcellent point\\b', r'\\bthat\\'?s exactly\\b',\n",
    "            r'\\babsolutely right\\b', r'\\bdefinitely right\\b', r'\\bcompletely agree\\b',\n",
    "            r'\\bwholeheartedly\\b', r'\\bunquestionably\\b', r'\\bwithout doubt\\b',\n",
    "            r'\\bdeal\\b', r'\\bcompromise\\b', r'\\bcompromised\\b', r'\\bcompromising\\b'\n",
    "        ]\n",
    "        \n",
    "        # Moderate agreement markers\n",
    "        moderate_agreement_patterns = [\n",
    "            r'\\byes\\b', r'\\byeah\\b', r'\\byep\\b', r'\\byup\\b', r'\\bsure\\b', r'\\bokay\\b', r'\\bok\\b',\n",
    "            r'\\bthat makes sense\\b', r'\\bthat\\'?s a good point\\b', r'\\bgood point\\b',\n",
    "            r'\\bi see\\b', r'\\bi understand\\b', r'\\bi get it\\b', r'\\bi follow\\b',\n",
    "            r'\\bthat\\'?s fair\\b', r'\\bfair enough\\b', r'\\bthat\\'?s reasonable\\b',\n",
    "            r'\\bi think so\\b', r'\\bi believe so\\b', r'\\bprobably\\b', r'\\blikely\\b',\n",
    "            r'\\bsimilar\\b', r'\\bsimilarly\\b', r'\\blikewise\\b', r'\\bsame here\\b',\n",
    "            r'\\bme too\\b', r'\\bsame\\b', r'\\bconcur\\b', r'\\bconcurring\\b',\n",
    "            r'\\bvalid\\b', r'\\bvalid point\\b', r'\\bsound\\b', r'\\bsound point\\b',\n",
    "            r'\\bhelpful\\b', r'\\buseful\\b', r'\\binsightful\\b', r'\\binteresting\\b',\n",
    "            r'\\bthat\\'?s interesting\\b', r'\\bgood idea\\b', r'\\bgood thinking\\b'\n",
    "        ]\n",
    "        \n",
    "        # Strong disagreement markers\n",
    "        strong_disagreement_patterns = [\n",
    "            r'\\bdisagree\\b', r'\\bdisagreed\\b', r'\\bdisagreeing\\b', r'\\bdisagreement\\b',\n",
    "            r'\\bdispute\\b', r'\\bdisputing\\b', r'\\bdiffer\\b', r'\\bdiffered\\b', r'\\bdiffering\\b',\n",
    "            r'\\bwrong\\b', r'\\bincorrect\\b', r'\\bnot correct\\b', r'\\bnot right\\b',\n",
    "            r'\\bnot true\\b', r'\\bthat\\'?s wrong\\b', r'\\bthat\\'?s incorrect\\b',\n",
    "            r'\\bi disagree\\b', r'\\bwe disagree\\b', r'\\bi strongly disagree\\b',\n",
    "            r'\\bdon\\'?t agree\\b', r'\\bdoesn\\'?t agree\\b', r'\\bdidn\\'?t agree\\b',\n",
    "            r'\\bcan\\'?t agree\\b', r'\\bcannot agree\\b', r'\\bwon\\'?t agree\\b',\n",
    "            r'\\bobject\\b', r'\\bobjection\\b', r'\\bchallenge\\b', r'\\bchallenging\\b',\n",
    "            r'\\bcontradict\\b', r'\\bcontradicting\\b', r'\\bcontradiction\\b',\n",
    "            r'\\bfalse\\b', r'\\buntrue\\b', r'\\bmistaken\\b', r'\\berror\\b',\n",
    "            r'\\bflawed\\b', r'\\bproblematic\\b', r'\\bunacceptable\\b', r'\\bunreasonable\\b',\n",
    "            r'\\babsurd\\b', r'\\bridiculous\\b', r'\\boutrageous\\b', r'\\bunfounded\\b'\n",
    "        ]\n",
    "        \n",
    "        # Moderate disagreement markers (more context-dependent)\n",
    "        moderate_disagreement_patterns = [\n",
    "            r'\\bhowever\\b', r'\\balthough\\b', r'\\bbut\\b', r'\\bthough\\b', r'\\bwhereas\\b',\n",
    "            r'\\bnot necessarily\\b', r'\\bnot quite\\b', r'\\bnot exactly\\b', r'\\bnot really\\b',\n",
    "            r'\\bnot entirely\\b', r'\\bnot completely\\b', r'\\bnot fully\\b',\n",
    "            r'\\bpartially\\b', r'\\bpartly\\b', r'\\bsomewhat\\b', r'\\bto some extent\\b',\n",
    "            r'\\bcontrary\\b', r'\\bconversely\\b', r'\\bon the other hand\\b',\n",
    "            r'\\bcontrast\\b', r'\\bcontrasting\\b', r'\\bunlike\\b', r'\\bdifferent\\b',\n",
    "            r'\\bdifferently\\b', r'\\balternative\\b', r'\\balternatively\\b',\n",
    "            r'\\bactually\\b', r'\\bin fact\\b', r'\\bin reality\\b', r'\\bthe reality is\\b',\n",
    "            r'\\bwell\\b', r'\\bwait\\b', r'\\bhold on\\b', r'\\bnot so fast\\b',\n",
    "            r'\\bnot sure\\b', r'\\bnot certain\\b', r'\\buncertain\\b', r'\\bdoubtful\\b',\n",
    "            r'\\bquestionable\\b', r'\\bdebatable\\b', r'\\barguable\\b', r'\\bmaybe not\\b',\n",
    "            r'\\bperhaps not\\b', r'\\bpossibly not\\b', r'\\bnot convinced\\b',\n",
    "            r'\\bskeptical\\b', r'\\bskepticism\\b', r'\\bconcern\\b', r'\\bconcerned\\b',\n",
    "            r'\\bissue\\b', r'\\bproblem\\b', r'\\bproblems\\b', r'\\bconcern\\b',\n",
    "            r'\\bworry\\b', r'\\bworried\\b', r'\\bhesitant\\b', r'\\bhesitation\\b',\n",
    "            r'\\bdispute\\b', r'\\bquestion\\b', r'\\bquestions\\b', r'\\bchallenge\\b',\n",
    "            r'\\bdisagree with\\b', r'\\bdiffer from\\b', r'\\bcontrary to\\b',\n",
    "            r'\\bin contrast\\b', r'\\bby contrast\\b', r'\\bunlike\\b', r'\\bversus\\b',\n",
    "            r'\\bvs\\b', r'\\bcompared to\\b', r'\\bcompared with\\b'\n",
    "        ]\n",
    "        \n",
    "        # Count markers with word boundary matching\n",
    "        strong_agreement_count = 0\n",
    "        moderate_agreement_count = 0\n",
    "        strong_disagreement_count = 0\n",
    "        moderate_disagreement_count = 0\n",
    "        \n",
    "        for utt in utterances:\n",
    "            # Safely get text\n",
    "            try:\n",
    "                if not hasattr(utt, 'text') or not utt.text:\n",
    "                    continue\n",
    "                text_lower = str(utt.text).lower()\n",
    "            except (AttributeError, TypeError):\n",
    "                continue\n",
    "            \n",
    "            # Count strong agreement (once per utterance)\n",
    "            found_strong_agree = False\n",
    "            for pattern in strong_agreement_patterns:\n",
    "                try:\n",
    "                    if re.search(pattern, text_lower):\n",
    "                        strong_agreement_count += 1\n",
    "                        found_strong_agree = True\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Count moderate agreement (only if no strong agreement found)\n",
    "            if not found_strong_agree:\n",
    "                for pattern in moderate_agreement_patterns:\n",
    "                    try:\n",
    "                        if re.search(pattern, text_lower):\n",
    "                            moderate_agreement_count += 1\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            \n",
    "            # Count strong disagreement (once per utterance)\n",
    "            found_strong_disagree = False\n",
    "            for pattern in strong_disagreement_patterns:\n",
    "                try:\n",
    "                    if re.search(pattern, text_lower):\n",
    "                        strong_disagreement_count += 1\n",
    "                        found_strong_disagree = True\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Count moderate disagreement (only if no strong disagreement found)\n",
    "            if not found_strong_disagree:\n",
    "                for pattern in moderate_disagreement_patterns:\n",
    "                    try:\n",
    "                        if re.search(pattern, text_lower):\n",
    "                            moderate_disagreement_count += 1\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        \n",
    "        # Weighted counts (strong markers count more)\n",
    "        total_agreement = strong_agreement_count * 2 + moderate_agreement_count\n",
    "        total_disagreement = strong_disagreement_count * 2 + moderate_disagreement_count\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if total_agreement == 0 and total_disagreement == 0:\n",
    "            return 5.0\n",
    "        elif total_disagreement == 0:\n",
    "            return 1.0\n",
    "        elif total_agreement == 0:\n",
    "            return 10.0\n",
    "        \n",
    "        # Calculate ratio and score using logarithmic scaling\n",
    "        agreement_ratio = total_agreement / total_disagreement\n",
    "        \n",
    "        # Map ratio to 1-10 scale using logarithmic scaling for smoother transitions\n",
    "        import math\n",
    "        \n",
    "        if agreement_ratio > 0:\n",
    "            log_ratio = math.log(agreement_ratio)\n",
    "            \n",
    "            # Map log_ratio from [-2.3, 2.3] to [10, 1]\n",
    "            # When log_ratio = 0 (ratio = 1.0), score = 5.0\n",
    "            if log_ratio >= 0:\n",
    "                # Consensus range: log_ratio [0, 2.3] -> score [5.0, 1.0]\n",
    "                score = 5.0 - (log_ratio / 2.3) * 4.0\n",
    "            else:\n",
    "                # Divergence range: log_ratio [-2.3, 0] -> score [10.0, 5.0]\n",
    "                score = 5.0 - (log_ratio / 2.3) * 5.0\n",
    "        else:\n",
    "            score = 10.0\n",
    "        \n",
    "        score = max(1.0, min(10.0, score))\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing conclusiveness score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "# Analyze conflict conversations\n",
    "print(\"\\\\n=== Conflict Resolution Metrics ===\")\n",
    "\n",
    "corpus_resource = conversation_to_corpus(transcript_resource)\n",
    "metrics_resource = {\n",
    "    \"dynamic\": compute_dynamic_score(corpus_resource),\n",
    "    \"conclusiveness\": compute_conclusiveness_score(corpus_resource)\n",
    "}\n",
    "\n",
    "print(f\"\\\\nResource Competition:\")\n",
    "print(f\"  Dynamic: {metrics_resource['dynamic']:.2f}/10\")\n",
    "print(f\"  Conclusiveness: {metrics_resource['conclusiveness']:.2f}/10\")\n",
    "\n",
    "corpus_goal = conversation_to_corpus(transcript_goal)\n",
    "metrics_goal = {\n",
    "    \"dynamic\": compute_dynamic_score(corpus_goal),\n",
    "    \"conclusiveness\": compute_conclusiveness_score(corpus_goal)\n",
    "}\n",
    "\n",
    "print(f\"\\\\nGoal Conflict:\")\n",
    "print(f\"  Dynamic: {metrics_goal['dynamic']:.2f}/10\")\n",
    "print(f\"  Conclusiveness: {metrics_goal['conclusiveness']:.2f}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c00d7c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We can see that conflict causes a lack of conclusiveness within a similar number of iterations that we were using for previous experiments, and while there was significant conflict, the agents still shifted towards resolution through more collaborative means. I think this shows that LLMs have this natural tendency to seek resolution in conflicts amicably, likely due to intentional training by the creators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
