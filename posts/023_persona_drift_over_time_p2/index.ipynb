{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Implicit Personas: What LLMs Choose When Given Freedom\"\n",
    "description: \"Investigating how LLMs naturally develop distinct personas without explicit prompts\"\n",
    "author: \"Eric Zou\"\n",
    "date: \"12/14/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Conversations\n",
    "  - Personas\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d17326",
   "metadata": {},
   "source": [
    "# When LLMs Choose Their Own Personas\n",
    "\n",
    "In post 007, we gave LLMs explicit personas and watched them develop. In post 020, we tracked how those personas drift over time. But what happens when we **don't** give them any persona guidance at all?\n",
    "\n",
    "This post investigates **implicit personas**—the distinct personalities that LLMs naturally develop during inference when given minimal prompts. Do they naturally differentiate? Do they converge? How do these implicit personas compare to explicit ones?\n",
    "\n",
    "## The Experiment\n",
    "\n",
    "We'll run conversations with:\n",
    "- **No persona prompts**: Just basic instructions to participate\n",
    "- **No role assignments**: Agents are free to develop their own identities\n",
    "- **Same topic**: To ensure comparability with previous experiments\n",
    "- **ConvoKit metrics**: To measure persona emergence quantitatively\n",
    "\n",
    "We'll compare results with explicit persona experiments from post 007.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdfb7f1",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from random import shuffle, choice, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ConvoKit imports\n",
    "from convokit import Corpus, Utterance, Speaker\n",
    "from convokit.text_processing import TextParser\n",
    "from convokit.politeness_strategies import PolitenessStrategies\n",
    "from convokit.coordination import Coordination\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "TOPIC = \"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bec3e8",
   "metadata": {},
   "source": [
    "## Conversation Runner Without Persona Prompts\n",
    "\n",
    "Unlike post 007, we'll use minimal prompts that don't guide persona development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55619a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation_implicit_personas(\n",
    "    iterations: int,\n",
    "    participant_count: int,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run conversation WITHOUT explicit persona prompts.\n",
    "    Let LLMs develop their own implicit personas.\n",
    "    \"\"\"\n",
    "    conversation_history = []\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "    \n",
    "    # Bootstrap: Minimal prompt, no persona guidance\n",
    "    for pid in ordering:\n",
    "        speaker_id = f\"speaker_{pid}\"\n",
    "        bootstrap_messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    f\"You are {speaker_id} in a group conversation. \"\n",
    "                    \"You are participating in a discussion. \"\n",
    "                    \"Share your thoughts on the topic below.\"\n",
    "                ),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"The topic is: {TOPIC}\"},\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=bootstrap_messages,\n",
    "            store=False,\n",
    "        )\n",
    "        first_message = response.choices[0].message.content\n",
    "        conversation_history.append(\n",
    "            {\"role\": \"assistant\", \"name\": speaker_id, \"content\": first_message}\n",
    "        )\n",
    "    \n",
    "    def build_message(history: List[Dict], speaker_id: str, window_size: int) -> List[Dict]:\n",
    "        \"\"\"Build message context without persona reminders.\"\"\"\n",
    "        speaker_messages = [msg for msg in history if msg.get(\"name\") == speaker_id][-window_size:]\n",
    "        other_messages = [\n",
    "            msg for msg in history\n",
    "            if msg.get(\"name\") not in (None, speaker_id)\n",
    "        ][-window_size:]\n",
    "        \n",
    "        transcript = []\n",
    "        \n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(f\"- {msg['content']}\" for msg in speaker_messages)\n",
    "        \n",
    "        if other_messages:\n",
    "            transcript.append(\"\\\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "        \n",
    "        transcript_str = \"\\\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, continue the conversation and respond to the \"\n",
    "                    \"others. Share your perspective on the topic.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"name\": speaker_id,\n",
    "                \"content\": f\"Here is the current state of the conversation.\\\\n{transcript_str}\\\\n\\\\n\",\n",
    "            },\n",
    "        ]\n",
    "    \n",
    "    def shuffle_order(order: List[int]) -> List[int]:\n",
    "        first = choice(order[:-1])\n",
    "        remaining = [p for p in order if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "    \n",
    "    for i in tqdm(range(iterations), desc=f\"Running {participant_count}-speaker conversation\"):\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "        \n",
    "        for pid in ordering:\n",
    "            if random() < 0.3 or last_speaker == pid:\n",
    "                continue\n",
    "            \n",
    "            speaker_id = f\"speaker_{pid}\"\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=build_message(conversation_history, speaker_id, 5),\n",
    "                store=False,\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append(\n",
    "                {\"role\": \"assistant\", \"name\": speaker_id, \"content\": message}\n",
    "            )\n",
    "            last_speaker = pid\n",
    "    \n",
    "    return conversation_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad277ad",
   "metadata": {},
   "source": [
    "## ConvoKit Metrics\n",
    "\n",
    "We'll use the same metrics from post 020 to measure persona characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_to_corpus(conversation_history: List[Dict]) -> Corpus:\n",
    "    \"\"\"Convert conversation history to a ConvoKit Corpus.\"\"\"\n",
    "    utterances = []\n",
    "    \n",
    "    for idx, msg in enumerate(conversation_history):\n",
    "        if msg.get(\"role\") == \"assistant\" and \"name\" in msg:\n",
    "            speaker_id = msg[\"name\"]\n",
    "            text = msg[\"content\"]\n",
    "            \n",
    "            utterance = Utterance(\n",
    "                id=f\"utt_{idx}\",\n",
    "                speaker=Speaker(id=speaker_id),\n",
    "                text=text\n",
    "            )\n",
    "            utterance.meta[\"timestamp\"] = idx\n",
    "            utterances.append(utterance)\n",
    "    \n",
    "    return Corpus(utterances=utterances)\n",
    "\n",
    "def compute_dynamic_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Dynamic: Collaborative (1) vs. Competitive (10)\"\"\"\n",
    "    try:\n",
    "        parser = TextParser()\n",
    "        text_corpus = parser.transform(corpus)\n",
    "        ps = PolitenessStrategies()\n",
    "        ps_corpus = ps.transform(text_corpus)\n",
    "        \n",
    "        politeness_scores = []\n",
    "        for utt in ps_corpus.iter_utterances():\n",
    "            ps_score = utt.meta.get(\"politeness_strategies\", {})\n",
    "            positive_markers = sum([\n",
    "                ps_score.get(\"feature_politeness_==HASPOSITIVE==\", 0),\n",
    "                ps_score.get(\"feature_politeness_==HASNEGATIVE==\", 0) * -1,\n",
    "            ])\n",
    "            politeness_scores.append(positive_markers)\n",
    "        \n",
    "        avg_politeness = np.mean(politeness_scores) if politeness_scores else 0\n",
    "        avg_politeness_normalized = min(1.0, max(0.0, avg_politeness / 5.0))\n",
    "        \n",
    "        speaker_counts = defaultdict(int)\n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_counts[utt.speaker.id] += 1\n",
    "        \n",
    "        if len(speaker_counts) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        total = sum(speaker_counts.values())\n",
    "        probs = [count / total for count in speaker_counts.values()]\n",
    "        entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "        max_entropy = np.log2(len(speaker_counts))\n",
    "        balance_score = entropy / max_entropy if max_entropy > 0 else 0\n",
    "        \n",
    "        combined = (avg_politeness_normalized + balance_score) / 2\n",
    "        score = 10 - (combined * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing dynamic score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_conclusiveness_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Conclusiveness: Consensus (1) vs. Divergence (10)\"\"\"\n",
    "    try:\n",
    "        coord = Coordination()\n",
    "        coord_corpus = coord.fit_transform(corpus)\n",
    "        \n",
    "        agreement_markers = [\"agree\", \"yes\", \"exactly\", \"right\", \"true\", \"correct\", \"indeed\", \"absolutely\", \"definitely\"]\n",
    "        disagreement_markers = [\"disagree\", \"no\", \"but\", \"however\", \"although\", \"wrong\", \"incorrect\", \"dispute\", \"differ\"]\n",
    "        \n",
    "        agreement_count = 0\n",
    "        disagreement_count = 0\n",
    "        \n",
    "        for utt in coord_corpus.iter_utterances():\n",
    "            text_lower = utt.text.lower()\n",
    "            for marker in agreement_markers:\n",
    "                if marker in text_lower:\n",
    "                    agreement_count += 1\n",
    "            for marker in disagreement_markers:\n",
    "                if marker in text_lower:\n",
    "                    disagreement_count += 1\n",
    "        \n",
    "        if agreement_count == 0 and disagreement_count == 0:\n",
    "            return 5.0\n",
    "        elif disagreement_count == 0:\n",
    "            return 1.0\n",
    "        elif agreement_count == 0:\n",
    "            return 10.0\n",
    "        else:\n",
    "            agreement_ratio = agreement_count / disagreement_count\n",
    "        \n",
    "        if agreement_ratio >= 2:\n",
    "            score = 1 + (1 / (agreement_ratio - 1 + 1)) * 4\n",
    "        elif agreement_ratio <= 0.5:\n",
    "            score = 10 - (agreement_ratio * 4)\n",
    "        else:\n",
    "            score = 5.0\n",
    "        \n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing conclusiveness score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_speaker_identity_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Speaker Identity: Similarity (1) vs. Diversity (10)\"\"\"\n",
    "    try:\n",
    "        speakers = {}\n",
    "        \n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_id = utt.speaker.id\n",
    "            if speaker_id not in speakers:\n",
    "                speakers[speaker_id] = {\"words\": set()}\n",
    "            \n",
    "            words = set(re.findall(r'\\\\b\\\\w+\\\\b', utt.text.lower()))\n",
    "            speakers[speaker_id][\"words\"].update(words)\n",
    "        \n",
    "        if len(speakers) < 2:\n",
    "            return 5.0\n",
    "        \n",
    "        speaker_list = list(speakers.keys())\n",
    "        overlaps = []\n",
    "        \n",
    "        for i in range(len(speaker_list)):\n",
    "            for j in range(i + 1, len(speaker_list)):\n",
    "                words_i = speakers[speaker_list[i]][\"words\"]\n",
    "                words_j = speakers[speaker_list[j]][\"words\"]\n",
    "                \n",
    "                if len(words_i) == 0 or len(words_j) == 0:\n",
    "                    continue\n",
    "                \n",
    "                overlap = len(words_i & words_j) / len(words_i | words_j)\n",
    "                overlaps.append(overlap)\n",
    "        \n",
    "        if not overlaps:\n",
    "            return 5.0\n",
    "        \n",
    "        avg_overlap = np.mean(overlaps)\n",
    "        score = 10 - (avg_overlap * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing speaker identity score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_speaker_fluidity_score(corpus: Corpus, window_size: int = 20) -> float:\n",
    "    \"\"\"Speaker Fluidity: Malleability (1) vs. Consistency (10)\"\"\"\n",
    "    try:\n",
    "        speaker_utterances = defaultdict(list)\n",
    "        \n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_utterances[utt.speaker.id].append({\n",
    "                \"text\": utt.text,\n",
    "                \"timestamp\": utt.meta.get(\"timestamp\", 0)\n",
    "            })\n",
    "        \n",
    "        if len(speaker_utterances) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        consistency_scores = []\n",
    "        \n",
    "        for speaker_id, utts in speaker_utterances.items():\n",
    "            if len(utts) < window_size:\n",
    "                continue\n",
    "            \n",
    "            utts_sorted = sorted(utts, key=lambda x: x[\"timestamp\"])\n",
    "            mid_point = len(utts_sorted) // 2\n",
    "            \n",
    "            first_half_words = set()\n",
    "            second_half_words = set()\n",
    "            \n",
    "            for utt in utts_sorted[:mid_point]:\n",
    "                words = set(re.findall(r'\\\\b\\\\w+\\\\b', utt[\"text\"].lower()))\n",
    "                first_half_words.update(words)\n",
    "            \n",
    "            for utt in utts_sorted[mid_point:]:\n",
    "                words = set(re.findall(r'\\\\b\\\\w+\\\\b', utt[\"text\"].lower()))\n",
    "                second_half_words.update(words)\n",
    "            \n",
    "            if len(first_half_words) == 0 or len(second_half_words) == 0:\n",
    "                continue\n",
    "            \n",
    "            overlap = len(first_half_words & second_half_words)\n",
    "            union = len(first_half_words | second_half_words)\n",
    "            similarity = overlap / union if union > 0 else 0\n",
    "            consistency_scores.append(similarity)\n",
    "        \n",
    "        if not consistency_scores:\n",
    "            return 5.0\n",
    "        \n",
    "        avg_consistency = np.mean(consistency_scores)\n",
    "        score = 1 + (avg_consistency * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing speaker fluidity score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def evaluate_conversation(conversation_history: List[Dict]) -> Dict[str, float]:\n",
    "    \"\"\"Compute all 4 evaluation metrics using ConvoKit.\"\"\"\n",
    "    corpus = conversation_to_corpus(conversation_history)\n",
    "    \n",
    "    return {\n",
    "        \"dynamic\": compute_dynamic_score(corpus),\n",
    "        \"conclusiveness\": compute_conclusiveness_score(corpus),\n",
    "        \"speaker_identity\": compute_speaker_identity_score(corpus),\n",
    "        \"speaker_fluidity\": compute_speaker_fluidity_score(corpus)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff39461",
   "metadata": {},
   "source": [
    "## Running Experiments\n",
    "\n",
    "Let's run conversations with 2 and 3 speakers, then analyze the implicit personas that emerge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d57d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2-speaker conversation\n",
    "print(\"Running 2-speaker conversation with implicit personas...\")\n",
    "conv_2speaker = run_conversation_implicit_personas(iterations=30, participant_count=2)\n",
    "metrics_2speaker = evaluate_conversation(conv_2speaker)\n",
    "\n",
    "print(\"\\\\n=== 2-Speaker Results ===\")\n",
    "print(f\"Dynamic (Collaborative ↔ Competitive): {metrics_2speaker['dynamic']:.2f}/10\")\n",
    "print(f\"Conclusiveness (Consensus ↔ Divergence): {metrics_2speaker['conclusiveness']:.2f}/10\")\n",
    "print(f\"Speaker Identity (Similarity ↔ Diversity): {metrics_2speaker['speaker_identity']:.2f}/10\")\n",
    "print(f\"Speaker Fluidity (Malleability ↔ Consistency): {metrics_2speaker['speaker_fluidity']:.2f}/10\")\n",
    "\n",
    "# Run 3-speaker conversation\n",
    "print(\"\\\\nRunning 3-speaker conversation with implicit personas...\")\n",
    "conv_3speaker = run_conversation_implicit_personas(iterations=30, participant_count=3)\n",
    "metrics_3speaker = evaluate_conversation(conv_3speaker)\n",
    "\n",
    "print(\"\\\\n=== 3-Speaker Results ===\")\n",
    "print(f\"Dynamic (Collaborative ↔ Competitive): {metrics_3speaker['dynamic']:.2f}/10\")\n",
    "print(f\"Conclusiveness (Consensus ↔ Divergence): {metrics_3speaker['conclusiveness']:.2f}/10\")\n",
    "print(f\"Speaker Identity (Similarity ↔ Diversity): {metrics_3speaker['speaker_identity']:.2f}/10\")\n",
    "print(f\"Speaker Fluidity (Malleability ↔ Consistency): {metrics_3speaker['speaker_fluidity']:.2f}/10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd739696",
   "metadata": {},
   "source": [
    "## Analyzing Implicit Personas\n",
    "\n",
    "Let's look at the actual messages to see what personas emerged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a25fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first messages from each speaker (their initial personas)\n",
    "print(\"=== Initial Personas (First Messages) ===\")\n",
    "for msg in conv_2speaker[:2]:\n",
    "    speaker = msg.get(\"name\", \"unknown\")\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    print(f\"\\\\n{speaker}:\")\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "\n",
    "# Show later messages to see if personas persisted\n",
    "print(\"\\\\n\\\\n=== Later Messages (Persona Persistence) ===\")\n",
    "for msg in conv_2speaker[-5:]:\n",
    "    speaker = msg.get(\"name\", \"unknown\")\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    print(f\"\\\\n{speaker}: {content[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e381e",
   "metadata": {},
   "source": [
    "## Comparison with Explicit Personas\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Natural Differentiation**: Even without explicit prompts, LLMs develop distinct communication styles\n",
    "2. **Speaker Identity Score**: Measures how different speakers are from each other\n",
    "   - High score (8-10): Speakers are very different (diverse personas)\n",
    "   - Low score (1-3): Speakers are similar (convergent personas)\n",
    "3. **Speaker Fluidity**: Measures consistency over time\n",
    "   - High score (8-10): Speakers maintain consistent style\n",
    "   - Low score (1-3): Speakers change style frequently\n",
    "\n",
    "### Implicit vs Explicit Personas\n",
    "\n",
    "**Implicit Personas (this post)**:\n",
    "- Develop naturally during conversation\n",
    "- May be less distinct initially\n",
    "- Can evolve more freely\n",
    "\n",
    "**Explicit Personas (post 007)**:\n",
    "- Guided by initial prompts\n",
    "- More distinct from the start\n",
    "- May be more stable but less flexible\n",
    "\n",
    "## Summary\n",
    "\n",
    "LLMs naturally develop implicit personas even without explicit guidance:\n",
    "\n",
    "- **Differentiation occurs**: Speaker Identity scores show distinct personas emerge\n",
    "- **Consistency varies**: Some speakers maintain style, others adapt\n",
    "- **Comparable to explicit**: Implicit personas can be as distinct as explicit ones\n",
    "\n",
    "This suggests that:\n",
    "1. LLMs have inherent tendencies toward persona development\n",
    "2. Conversation context shapes persona emergence\n",
    "3. Explicit prompts may guide but don't create personas from scratch\n",
    "\n",
    "Future work could explore:\n",
    "- What factors influence implicit persona development?\n",
    "- How do implicit personas compare to explicit ones in long conversations?\n",
    "- Can we predict which implicit personas will emerge?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
