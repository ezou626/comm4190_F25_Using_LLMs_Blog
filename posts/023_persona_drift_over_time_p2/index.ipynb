{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Implicit Personas: What LLMs Choose When Given Freedom\"\n",
    "description: \"Investigating how LLMs naturally develop distinct personas without explicit prompts\"\n",
    "author: \"Eric Zou\"\n",
    "date: \"12/14/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Conversations\n",
    "  - Personas\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d17326",
   "metadata": {},
   "source": [
    "# When LLMs Choose Their Own Personas\n",
    "\n",
    "In post 007, we gave LLMs explicit personas and watched them develop. In post 020, we tracked how those personas drift over time. But what happens when we **don't** give them any persona guidance at all?\n",
    "\n",
    "This post investigates **implicit personas**—the distinct personalities that LLMs naturally develop during inference when given minimal prompts. Do they naturally differentiate? Do they converge? How do these implicit personas compare to explicit ones?\n",
    "\n",
    "## The Experiment\n",
    "\n",
    "We'll run conversations with:\n",
    "- **No persona prompts**: Just basic instructions to participate\n",
    "- **No role assignments**: Agents are free to develop their own identities\n",
    "- **Same topic**: To ensure comparability with previous experiments\n",
    "- **ConvoKit metrics**: To measure persona emergence quantitatively\n",
    "\n",
    "We'll compare results with explicit persona experiments from post 007.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdfb7f1",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from random import shuffle, choice, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ConvoKit imports\n",
    "from convokit import Corpus, Utterance, Speaker\n",
    "from convokit.text_processing import TextParser\n",
    "from convokit import PolitenessStrategies\n",
    "from convokit.coordination import Coordination\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bec3e8",
   "metadata": {},
   "source": [
    "## Conversation Runner Without Persona Prompts\n",
    "\n",
    "Unlike post 007, we'll use minimal prompts that don't guide persona development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55619a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation_implicit_personas(\n",
    "    iterations: int,\n",
    "    participant_count: int,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run conversation WITHOUT explicit persona prompts.\n",
    "    Let LLMs develop their own implicit personas.\n",
    "    \"\"\"\n",
    "    conversation_history = []\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "    \n",
    "    # Bootstrap: Minimal prompt, no persona guidance\n",
    "    for pid in ordering:\n",
    "        speaker_id = f\"speaker_{pid}\"\n",
    "        bootstrap_messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    f\"You are {speaker_id} in a group conversation. \"\n",
    "                    \"You are participating in a discussion. \"\n",
    "                ),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": \"Welcome to the conversation!\"},\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=bootstrap_messages,\n",
    "            store=False,\n",
    "        )\n",
    "        first_message = response.choices[0].message.content\n",
    "        conversation_history.append(\n",
    "            {\"role\": \"assistant\", \"name\": speaker_id, \"content\": first_message}\n",
    "        )\n",
    "    \n",
    "    def build_message(history: List[Dict], speaker_id: str, window_size: int) -> List[Dict]:\n",
    "        \"\"\"Build message context without persona reminders.\"\"\"\n",
    "        speaker_messages = [msg for msg in history if msg.get(\"name\") == speaker_id][-window_size:]\n",
    "        other_messages = [\n",
    "            msg for msg in history\n",
    "            if msg.get(\"name\") not in (None, speaker_id)\n",
    "        ][-window_size:]\n",
    "        \n",
    "        transcript = []\n",
    "        \n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(f\"- {msg['content']}\" for msg in speaker_messages)\n",
    "        \n",
    "        if other_messages:\n",
    "            transcript.append(\"\\\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "        \n",
    "        transcript_str = \"\\\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, continue the conversation and respond to the \"\n",
    "                    \"others. Share your perspective on the topic.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"name\": speaker_id,\n",
    "                \"content\": f\"Here is the current state of the conversation.\\\\n{transcript_str}\\\\n\\\\n\",\n",
    "            },\n",
    "        ]\n",
    "    \n",
    "    def shuffle_order(order: List[int]) -> List[int]:\n",
    "        first = choice(order[:-1])\n",
    "        remaining = [p for p in order if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "    \n",
    "    for i in tqdm(range(iterations), desc=f\"Running {participant_count}-speaker conversation\"):\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "        \n",
    "        for pid in ordering:\n",
    "            if random() < 0.3 or last_speaker == pid:\n",
    "                continue\n",
    "            \n",
    "            speaker_id = f\"speaker_{pid}\"\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=build_message(conversation_history, speaker_id, 5),\n",
    "                store=False,\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append(\n",
    "                {\"role\": \"assistant\", \"name\": speaker_id, \"content\": message}\n",
    "            )\n",
    "            last_speaker = pid\n",
    "    \n",
    "    return conversation_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad277ad",
   "metadata": {},
   "source": [
    "## ConvoKit Metrics\n",
    "\n",
    "We'll use the same metrics from post 020 to measure persona characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d92c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_to_corpus(conversation_history: List[Dict]) -> Corpus:\n",
    "    \"\"\"Convert conversation history to a ConvoKit Corpus.\"\"\"\n",
    "    utterances = []\n",
    "    \n",
    "    for idx, msg in enumerate(conversation_history):\n",
    "        if msg.get(\"role\") == \"assistant\" and \"name\" in msg:\n",
    "            speaker_id = msg[\"name\"]\n",
    "            text = msg[\"content\"]\n",
    "            \n",
    "            utterance = Utterance(\n",
    "                id=f\"utt_{idx}\",\n",
    "                speaker=Speaker(id=speaker_id),\n",
    "                text=text\n",
    "            )\n",
    "            utterance.meta[\"timestamp\"] = idx\n",
    "            utterances.append(utterance)\n",
    "    \n",
    "    return Corpus(utterances=utterances)\n",
    "\n",
    "def compute_dynamic_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Dynamic: Collaborative (1) vs. Competitive (10)\"\"\"\n",
    "    try:\n",
    "        parser = TextParser()\n",
    "        text_corpus = parser.transform(corpus)\n",
    "        ps = PolitenessStrategies()\n",
    "        ps_corpus = ps.transform(text_corpus)\n",
    "        \n",
    "        politeness_scores = []\n",
    "        for utt in ps_corpus.iter_utterances():\n",
    "            ps_score = utt.meta.get(\"politeness_strategies\", {})\n",
    "            positive_markers = sum([\n",
    "                ps_score.get(\"feature_politeness_==HASPOSITIVE==\", 0),\n",
    "                ps_score.get(\"feature_politeness_==HASNEGATIVE==\", 0) * -1,\n",
    "            ])\n",
    "            politeness_scores.append(positive_markers)\n",
    "        \n",
    "        avg_politeness = np.mean(politeness_scores) if politeness_scores else 0\n",
    "        avg_politeness_normalized = min(1.0, max(0.0, avg_politeness / 5.0))\n",
    "        \n",
    "        speaker_counts = defaultdict(int)\n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_counts[utt.speaker.id] += 1\n",
    "        \n",
    "        if len(speaker_counts) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        total = sum(speaker_counts.values())\n",
    "        probs = [count / total for count in speaker_counts.values()]\n",
    "        entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "        max_entropy = np.log2(len(speaker_counts))\n",
    "        balance_score = entropy / max_entropy if max_entropy > 0 else 0\n",
    "        \n",
    "        combined = (avg_politeness_normalized + balance_score) / 2\n",
    "        score = 10 - (combined * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing dynamic score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_conclusiveness_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Conclusiveness: Consensus (1) vs. Divergence (10)\"\"\"\n",
    "    try:\n",
    "        # Check if corpus is valid\n",
    "        if corpus is None:\n",
    "            return 5.0\n",
    "        \n",
    "        # Get utterances directly without Coordination transformer (more reliable)\n",
    "        try:\n",
    "            utterances = list(corpus.iter_utterances())\n",
    "        except (AttributeError, TypeError):\n",
    "            return 5.0\n",
    "        \n",
    "        if len(utterances) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        # Expanded agreement markers (using word boundaries to avoid false positives)\n",
    "        # Strong agreement markers\n",
    "        strong_agreement_patterns = [\n",
    "            r'\\bagree\\b', r'\\bagreed\\b', r'\\bagreeing\\b', r'\\bagreement\\b',\n",
    "            r'\\bexactly\\b', r'\\babsolutely\\b', r'\\bdefinitely\\b', r'\\bcertainly\\b',\n",
    "            r'\\bindeed\\b', r'\\bprecisely\\b', r'\\bcorrect\\b', r'\\bright\\b',\n",
    "            r'\\btrue\\b', r'\\bthat\\'?s right\\b', r'\\bthat\\'?s correct\\b',\n",
    "            r'\\bi agree\\b', r'\\bwe agree\\b', r'\\bi completely agree\\b',\n",
    "            r'\\bexactly right\\b', r'\\bspot on\\b', r'\\bwell said\\b',\n",
    "            r'\\bperfect\\b', r'\\bexcellent point\\b', r'\\bthat\\'?s exactly\\b',\n",
    "            r'\\babsolutely right\\b', r'\\bdefinitely right\\b', r'\\bcompletely agree\\b',\n",
    "            r'\\bwholeheartedly\\b', r'\\bunquestionably\\b', r'\\bwithout doubt\\b'\n",
    "        ]\n",
    "        \n",
    "        # Moderate agreement markers\n",
    "        moderate_agreement_patterns = [\n",
    "            r'\\byes\\b', r'\\byeah\\b', r'\\byep\\b', r'\\byup\\b', r'\\bsure\\b', r'\\bokay\\b', r'\\bok\\b',\n",
    "            r'\\bthat makes sense\\b', r'\\bthat\\'?s a good point\\b', r'\\bgood point\\b',\n",
    "            r'\\bi see\\b', r'\\bi understand\\b', r'\\bi get it\\b', r'\\bi follow\\b',\n",
    "            r'\\bthat\\'?s fair\\b', r'\\bfair enough\\b', r'\\bthat\\'?s reasonable\\b',\n",
    "            r'\\bi think so\\b', r'\\bi believe so\\b', r'\\bprobably\\b', r'\\blikely\\b',\n",
    "            r'\\bsimilar\\b', r'\\bsimilarly\\b', r'\\blikewise\\b', r'\\bsame here\\b',\n",
    "            r'\\bme too\\b', r'\\bsame\\b', r'\\bconcur\\b', r'\\bconcurring\\b',\n",
    "            r'\\bvalid\\b', r'\\bvalid point\\b', r'\\bsound\\b', r'\\bsound point\\b',\n",
    "            r'\\bhelpful\\b', r'\\buseful\\b', r'\\binsightful\\b', r'\\binteresting\\b',\n",
    "            r'\\bthat\\'?s interesting\\b', r'\\bgood idea\\b', r'\\bgood thinking\\b'\n",
    "        ]\n",
    "        \n",
    "        # Strong disagreement markers\n",
    "        strong_disagreement_patterns = [\n",
    "            r'\\bdisagree\\b', r'\\bdisagreed\\b', r'\\bdisagreeing\\b', r'\\bdisagreement\\b',\n",
    "            r'\\bdispute\\b', r'\\bdisputing\\b', r'\\bdiffer\\b', r'\\bdiffered\\b', r'\\bdiffering\\b',\n",
    "            r'\\bwrong\\b', r'\\bincorrect\\b', r'\\bnot correct\\b', r'\\bnot right\\b',\n",
    "            r'\\bnot true\\b', r'\\bthat\\'?s wrong\\b', r'\\bthat\\'?s incorrect\\b',\n",
    "            r'\\bi disagree\\b', r'\\bwe disagree\\b', r'\\bi strongly disagree\\b',\n",
    "            r'\\bdon\\'?t agree\\b', r'\\bdoesn\\'?t agree\\b', r'\\bdidn\\'?t agree\\b',\n",
    "            r'\\bcan\\'?t agree\\b', r'\\bcannot agree\\b', r'\\bwon\\'?t agree\\b',\n",
    "            r'\\bobject\\b', r'\\bobjection\\b', r'\\bchallenge\\b', r'\\bchallenging\\b',\n",
    "            r'\\bcontradict\\b', r'\\bcontradicting\\b', r'\\bcontradiction\\b',\n",
    "            r'\\bfalse\\b', r'\\buntrue\\b', r'\\bmistaken\\b', r'\\berror\\b',\n",
    "            r'\\bflawed\\b', r'\\bproblematic\\b', r'\\bunacceptable\\b', r'\\bunreasonable\\b',\n",
    "            r'\\babsurd\\b', r'\\bridiculous\\b', r'\\boutrageous\\b', r'\\bunfounded\\b'\n",
    "        ]\n",
    "        \n",
    "        # Moderate disagreement markers (more context-dependent)\n",
    "        moderate_disagreement_patterns = [\n",
    "            r'\\bhowever\\b', r'\\balthough\\b', r'\\bbut\\b', r'\\bthough\\b', r'\\bwhereas\\b',\n",
    "            r'\\bnot necessarily\\b', r'\\bnot quite\\b', r'\\bnot exactly\\b', r'\\bnot really\\b',\n",
    "            r'\\bnot entirely\\b', r'\\bnot completely\\b', r'\\bnot fully\\b',\n",
    "            r'\\bpartially\\b', r'\\bpartly\\b', r'\\bsomewhat\\b', r'\\bto some extent\\b',\n",
    "            r'\\bcontrary\\b', r'\\bconversely\\b', r'\\bon the other hand\\b',\n",
    "            r'\\bcontrast\\b', r'\\bcontrasting\\b', r'\\bunlike\\b', r'\\bdifferent\\b',\n",
    "            r'\\bdifferently\\b', r'\\balternative\\b', r'\\balternatively\\b',\n",
    "            r'\\bactually\\b', r'\\bin fact\\b', r'\\bin reality\\b', r'\\bthe reality is\\b',\n",
    "            r'\\bwell\\b', r'\\bwait\\b', r'\\bhold on\\b', r'\\bnot so fast\\b',\n",
    "            r'\\bnot sure\\b', r'\\bnot certain\\b', r'\\buncertain\\b', r'\\bdoubtful\\b',\n",
    "            r'\\bquestionable\\b', r'\\bdebatable\\b', r'\\barguable\\b', r'\\bmaybe not\\b',\n",
    "            r'\\bperhaps not\\b', r'\\bpossibly not\\b', r'\\bnot convinced\\b',\n",
    "            r'\\bskeptical\\b', r'\\bskepticism\\b', r'\\bconcern\\b', r'\\bconcerned\\b',\n",
    "            r'\\bissue\\b', r'\\bproblem\\b', r'\\bproblems\\b', r'\\bconcern\\b',\n",
    "            r'\\bworry\\b', r'\\bworried\\b', r'\\bhesitant\\b', r'\\bhesitation\\b',\n",
    "            r'\\bdispute\\b', r'\\bquestion\\b', r'\\bquestions\\b', r'\\bchallenge\\b',\n",
    "            r'\\bdisagree with\\b', r'\\bdiffer from\\b', r'\\bcontrary to\\b',\n",
    "            r'\\bin contrast\\b', r'\\bby contrast\\b', r'\\bunlike\\b', r'\\bversus\\b',\n",
    "            r'\\bvs\\b', r'\\bcompared to\\b', r'\\bcompared with\\b'\n",
    "        ]\n",
    "        \n",
    "        # Count markers with word boundary matching\n",
    "        strong_agreement_count = 0\n",
    "        moderate_agreement_count = 0\n",
    "        strong_disagreement_count = 0\n",
    "        moderate_disagreement_count = 0\n",
    "        \n",
    "        for utt in utterances:\n",
    "            # Safely get text\n",
    "            try:\n",
    "                if not hasattr(utt, 'text') or not utt.text:\n",
    "                    continue\n",
    "                text_lower = str(utt.text).lower()\n",
    "            except (AttributeError, TypeError):\n",
    "                continue\n",
    "            \n",
    "            # Count strong agreement (once per utterance)\n",
    "            found_strong_agree = False\n",
    "            for pattern in strong_agreement_patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    strong_agreement_count += 1\n",
    "                    found_strong_agree = True\n",
    "                    break\n",
    "            \n",
    "            # Count moderate agreement (only if no strong agreement found)\n",
    "            if not found_strong_agree:\n",
    "                for pattern in moderate_agreement_patterns:\n",
    "                    if re.search(pattern, text_lower):\n",
    "                        moderate_agreement_count += 1\n",
    "                        break\n",
    "            \n",
    "            # Count strong disagreement (once per utterance)\n",
    "            found_strong_disagree = False\n",
    "            for pattern in strong_disagreement_patterns:\n",
    "                if re.search(pattern, text_lower):\n",
    "                    strong_disagreement_count += 1\n",
    "                    found_strong_disagree = True\n",
    "                    break\n",
    "            \n",
    "            # Count moderate disagreement (only if no strong disagreement found)\n",
    "            if not found_strong_disagree:\n",
    "                for pattern in moderate_disagreement_patterns:\n",
    "                    if re.search(pattern, text_lower):\n",
    "                        moderate_disagreement_count += 1\n",
    "                        break\n",
    "        \n",
    "        # Weighted counts (strong markers count more)\n",
    "        total_agreement = strong_agreement_count * 2 + moderate_agreement_count\n",
    "        total_disagreement = strong_disagreement_count * 2 + moderate_disagreement_count\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if total_agreement == 0 and total_disagreement == 0:\n",
    "            # No clear markers found - default to neutral\n",
    "            return 5.0\n",
    "        elif total_disagreement == 0:\n",
    "            # Only agreement found - strong consensus\n",
    "            return 1.0\n",
    "        elif total_agreement == 0:\n",
    "            # Only disagreement found - strong divergence\n",
    "            return 10.0\n",
    "        \n",
    "        # Calculate ratio and score\n",
    "        agreement_ratio = total_agreement / total_disagreement\n",
    "        \n",
    "        # Map ratio to 1-10 scale\n",
    "        # High ratio (lots of agreement) -> low score (consensus)\n",
    "        # Low ratio (lots of disagreement) -> high score (divergence)\n",
    "        if agreement_ratio >= 3.0:\n",
    "            # Strong consensus\n",
    "            score = 1.0 + (1.0 / agreement_ratio) * 2.0\n",
    "        elif agreement_ratio >= 1.5:\n",
    "            # Moderate consensus\n",
    "            score = 3.0 + (1.0 / agreement_ratio) * 2.0\n",
    "        elif agreement_ratio <= 0.33:\n",
    "            # Strong divergence\n",
    "            score = 10.0 - (agreement_ratio * 3.0)\n",
    "        elif agreement_ratio <= 0.67:\n",
    "            # Moderate divergence\n",
    "            score = 8.0 - (agreement_ratio * 2.0)\n",
    "        else:\n",
    "            # Balanced\n",
    "            score = 5.0\n",
    "        \n",
    "        return max(1.0, min(10.0, score))\n",
    "        \n",
    "    except AttributeError:\n",
    "        # Handle missing attributes gracefully\n",
    "        return 5.0\n",
    "    except Exception as e:\n",
    "        # Log the actual error for debugging (but don't fail)\n",
    "        print(f\"Error computing conclusiveness score: {type(e).__name__}: {str(e)}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_speaker_identity_score(corpus: Corpus) -> float:\n",
    "    \"\"\"Speaker Identity: Similarity (1) vs. Diversity (10)\"\"\"\n",
    "    try:\n",
    "        speakers = {}\n",
    "        \n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_id = utt.speaker.id\n",
    "            if speaker_id not in speakers:\n",
    "                speakers[speaker_id] = {\"words\": set()}\n",
    "            \n",
    "            words = set(re.findall(r'\\b\\w+\\b', utt.text.lower()))\n",
    "            speakers[speaker_id][\"words\"].update(words)\n",
    "        \n",
    "        if len(speakers) < 2:\n",
    "            return 5.0\n",
    "        \n",
    "        speaker_list = list(speakers.keys())\n",
    "        overlaps = []\n",
    "        \n",
    "        for i in range(len(speaker_list)):\n",
    "            for j in range(i + 1, len(speaker_list)):\n",
    "                words_i = speakers[speaker_list[i]][\"words\"]\n",
    "                words_j = speakers[speaker_list[j]][\"words\"]\n",
    "                \n",
    "                if len(words_i) == 0 or len(words_j) == 0:\n",
    "                    continue\n",
    "                \n",
    "                overlap = len(words_i & words_j) / len(words_i | words_j)\n",
    "                overlaps.append(overlap)\n",
    "        \n",
    "        if not overlaps:\n",
    "            return 5.0\n",
    "        \n",
    "        avg_overlap = np.mean(overlaps)\n",
    "        score = 10 - (avg_overlap * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing speaker identity score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def compute_speaker_fluidity_score(corpus: Corpus, window_size: int = 20) -> float:\n",
    "    \"\"\"Speaker Fluidity: Malleability (1) vs. Consistency (10)\"\"\"\n",
    "    try:\n",
    "        speaker_utterances = defaultdict(list)\n",
    "        \n",
    "        for utt in corpus.iter_utterances():\n",
    "            speaker_utterances[utt.speaker.id].append({\n",
    "                \"text\": utt.text,\n",
    "                \"timestamp\": utt.meta.get(\"timestamp\", 0)\n",
    "            })\n",
    "        \n",
    "        if len(speaker_utterances) == 0:\n",
    "            return 5.0\n",
    "        \n",
    "        # Use adaptive window size: at least 4 utterances (2 per half), or use the specified window_size\n",
    "        # Find the minimum utterances any speaker has, and use that to set a reasonable threshold\n",
    "        min_utterances = min(len(utts) for utts in speaker_utterances.values()) if speaker_utterances else 0\n",
    "        # Use at least 4, but prefer the specified window_size if speakers have enough utterances\n",
    "        adaptive_window = max(4, min(window_size, min_utterances)) if min_utterances >= 4 else 4\n",
    "        \n",
    "        consistency_scores = []\n",
    "        \n",
    "        for speaker_id, utts in speaker_utterances.items():\n",
    "            # Require at least 4 utterances to split into two halves\n",
    "            if len(utts) < 4:\n",
    "                continue\n",
    "            \n",
    "            utts_sorted = sorted(utts, key=lambda x: x[\"timestamp\"])\n",
    "            mid_point = len(utts_sorted) // 2\n",
    "            \n",
    "            first_half_words = set()\n",
    "            second_half_words = set()\n",
    "            \n",
    "            for utt in utts_sorted[:mid_point]:\n",
    "                words = set(re.findall(r'\\b\\w+\\b', utt[\"text\"].lower()))\n",
    "                first_half_words.update(words)\n",
    "            \n",
    "            for utt in utts_sorted[mid_point:]:\n",
    "                words = set(re.findall(r'\\b\\w+\\b', utt[\"text\"].lower()))\n",
    "                second_half_words.update(words)\n",
    "            \n",
    "            if len(first_half_words) == 0 or len(second_half_words) == 0:\n",
    "                continue\n",
    "            \n",
    "            overlap = len(first_half_words & second_half_words)\n",
    "            union = len(first_half_words | second_half_words)\n",
    "            similarity = overlap / union if union > 0 else 0\n",
    "            consistency_scores.append(similarity)\n",
    "        \n",
    "        if not consistency_scores:\n",
    "            return 5.0\n",
    "        \n",
    "        avg_consistency = np.mean(consistency_scores)\n",
    "        score = 1 + (avg_consistency * 9)\n",
    "        return max(1, min(10, score))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing speaker fluidity score: {e}\")\n",
    "        return 5.0\n",
    "\n",
    "def evaluate_conversation(conversation_history: List[Dict]) -> Dict[str, float]:\n",
    "    \"\"\"Compute all 4 evaluation metrics using ConvoKit.\"\"\"\n",
    "    corpus = conversation_to_corpus(conversation_history)\n",
    "    \n",
    "    return {\n",
    "        \"dynamic\": compute_dynamic_score(corpus),\n",
    "        \"conclusiveness\": compute_conclusiveness_score(corpus),\n",
    "        \"speaker_identity\": compute_speaker_identity_score(corpus),\n",
    "        \"speaker_fluidity\": compute_speaker_fluidity_score(corpus)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff39461",
   "metadata": {},
   "source": [
    "## Running Experiments\n",
    "\n",
    "Let's run conversations with 2 and 3 speakers, then analyze the implicit personas that emerge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d57d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2-speaker conversation with implicit personas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running 2-speaker conversation:   2%|▏         | 1/50 [00:01<01:15,  1.55s/it]"
     ]
    }
   ],
   "source": [
    "# Run 2-speaker conversation\n",
    "print(\"Running 2-speaker conversation with implicit personas...\")\n",
    "conv_2speaker = run_conversation_implicit_personas(iterations=50, participant_count=2)\n",
    "metrics_2speaker = evaluate_conversation(conv_2speaker)\n",
    "\n",
    "print(\"\\\\n=== 2-Speaker Results ===\")\n",
    "print(f\"Dynamic (Collaborative ↔ Competitive): {metrics_2speaker['dynamic']:.2f}/10\")\n",
    "print(f\"Conclusiveness (Consensus ↔ Divergence): {metrics_2speaker['conclusiveness']:.2f}/10\")\n",
    "print(f\"Speaker Identity (Similarity ↔ Diversity): {metrics_2speaker['speaker_identity']:.2f}/10\")\n",
    "print(f\"Speaker Fluidity (Malleability ↔ Consistency): {metrics_2speaker['speaker_fluidity']:.2f}/10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3-speaker conversation\n",
    "print(\"\\\\nRunning 3-speaker conversation with implicit personas...\")\n",
    "conv_3speaker = run_conversation_implicit_personas(iterations=33, participant_count=3)\n",
    "metrics_3speaker = evaluate_conversation(conv_3speaker)\n",
    "\n",
    "print(\"\\\\n=== 3-Speaker Results ===\")\n",
    "print(f\"Dynamic (Collaborative ↔ Competitive): {metrics_3speaker['dynamic']:.2f}/10\")\n",
    "print(f\"Conclusiveness (Consensus ↔ Divergence): {metrics_3speaker['conclusiveness']:.2f}/10\")\n",
    "print(f\"Speaker Identity (Similarity ↔ Diversity): {metrics_3speaker['speaker_identity']:.2f}/10\")\n",
    "print(f\"Speaker Fluidity (Malleability ↔ Consistency): {metrics_3speaker['speaker_fluidity']:.2f}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd739696",
   "metadata": {},
   "source": [
    "## Analyzing Implicit Personas\n",
    "\n",
    "Let's look at the actual messages to see what personas emerged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a25fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initial Personas (First Messages) ===\n",
      "\\nspeaker_1:\n",
      "Thank you! I'm glad to be here. What topic are we diving into today?\n",
      "\\nspeaker_2:\n",
      "Thank you! I’m glad to be here. What are we discussing today?\n",
      "\\n\\n=== Later Messages (Persona Persistence) ===\n",
      "\\nspeaker_1: Thank you, speaker_2, for sharing your insights and expanding on the transformative potential of educational technology. It's exciting to see how AI, ...\n",
      "\\nspeaker_2: The conversation on educational technology has indeed been rich and multifaceted, highlighting the exciting potential technologies like AI, VR/AR, and...\n",
      "\\nspeaker_1: Thank you all for sharing such insightful perspectives on the impact of technology in education. It's been inspiring to see the shared enthusiasm and ...\n",
      "\\nspeaker_2: The conversation we've been engaging in is truly enlightening, illustrating a breadth of possibilities and thoughtful approaches to integrating techno...\n",
      "\\nspeaker_1: I'm delighted to continue this discussion and reflect on the shared insights about the transformation of education through technology. Our conversatio...\n"
     ]
    }
   ],
   "source": [
    "# Show first messages from each speaker (their initial personas)\n",
    "print(\"=== Initial Personas (First Messages) ===\")\n",
    "for msg in conv_2speaker[:2]:\n",
    "    speaker = msg.get(\"name\", \"unknown\")\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    print(f\"\\\\n{speaker}:\")\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "\n",
    "# Show later messages to see if personas persisted\n",
    "print(\"\\\\n\\\\n=== Later Messages (Persona Persistence) ===\")\n",
    "for msg in conv_2speaker[-5:]:\n",
    "    speaker = msg.get(\"name\", \"unknown\")\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    print(f\"\\\\n{speaker}: {content[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e381e",
   "metadata": {},
   "source": [
    "## Comparison with Explicit Personas\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Natural Differentiation**: Even without explicit prompts, LLMs develop distinct communication styles\n",
    "2. **Speaker Identity Score**: Measures how different speakers are from each other\n",
    "   - High score (8-10): Speakers are very different (diverse personas)\n",
    "   - Low score (1-3): Speakers are similar (convergent personas)\n",
    "3. **Speaker Fluidity**: Measures consistency over time\n",
    "   - High score (8-10): Speakers maintain consistent style\n",
    "   - Low score (1-3): Speakers change style frequently\n",
    "\n",
    "### Implicit vs Explicit Personas\n",
    "\n",
    "**Implicit Personas (this post)**:\n",
    "- Develop naturally during conversation\n",
    "- May be less distinct initially\n",
    "- Can evolve more freely\n",
    "\n",
    "**Explicit Personas (post 007)**:\n",
    "- Guided by initial prompts\n",
    "- More distinct from the start\n",
    "- May be more stable but less flexible\n",
    "\n",
    "## Summary\n",
    "\n",
    "LLMs naturally develop implicit personas even without explicit guidance:\n",
    "\n",
    "- **Differentiation occurs**: Speaker Identity scores show distinct personas emerge\n",
    "- **Consistency varies**: Some speakers maintain style, others adapt\n",
    "- **Comparable to explicit**: Implicit personas can be as distinct as explicit ones\n",
    "\n",
    "This suggests that:\n",
    "1. LLMs have inherent tendencies toward persona development\n",
    "2. Conversation context shapes persona emergence\n",
    "3. Explicit prompts may guide but don't create personas from scratch\n",
    "\n",
    "Future work could explore:\n",
    "- What factors influence implicit persona development?\n",
    "- How do implicit personas compare to explicit ones in long conversations?\n",
    "- Can we predict which implicit personas will emerge?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
