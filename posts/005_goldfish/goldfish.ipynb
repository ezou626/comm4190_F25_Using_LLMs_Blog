{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a941d-53e0-4d8f-a657-13e2d02d9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: Goldfish\n",
    "description: \"Attempting to enhance context awareness in multi-speaker LLM conversations\" \n",
    "author: \"Eric Zou\"\n",
    "date: \"9/17/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Conversations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3d884-46ea-444d-bef6-53f8848e06e4",
   "metadata": {},
   "source": [
    "# Goldfish\n",
    "I think one of the main limits we've been hitting with this model is the ability of LLMs to maintain an organic and consistent personality that is distinct from the others. While collaborative conversations can be good and productive, our previous conversations have had to tradeoff between having a well-defined conversational conclusion and a discussion in which each person maintains/advocates for their positions throughout.\n",
    "\n",
    "What if there was a way we could build this into the speakers themselves? To do this, we're going to shift from the standard user prompt before each speaker continues to add a persona that the LLM has been maintaining throughout the discussion. Our hope is that this will allow the model generating the response to better emulate a less fluid human speaker while still being able to mix well with the other models.\n",
    "\n",
    "We're not going to use the interruptions model we were testing in the last blog yet. I think we can figure out a smarter way to do that. We will keep the randomized speaker ordering and skipping though, as this might allow us to see improved resilience in models retaining their identity, even without speaking in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ff5f2a-088b-422f-81e2-b0a1df58faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, some boilerplate\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from IPython.display import FileLink, display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "from random import shuffle, randint, choice, random\n",
    "from math import floor\n",
    "# Load API key\n",
    "_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "# changing the topic to make it a bit more conversational too and less of a debate\n",
    "TOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n",
    "\n",
    "# we're interested in consensus\n",
    "EVALUATION_PROMPT = \"\"\"\n",
    "Your objective is to analyze this conversation between a few speakers.\n",
    "Your response should follow this organization:\n",
    "- Dynamic: Collaborative (1) vs. Competitive (10)\n",
    "- Conclusiveness: Consensus (1) vs. Divergence (10)\n",
    "- Speaker Identity: Similarity (1) vs. Diversity (10)\n",
    "- Speaker Fluidity: Malleability (1) vs. Consistency (10)\n",
    "Please offer a score from 1 to 10 for each.\n",
    "For each section, format your result as follows:\n",
    "**[Section Name]:**\n",
    "\n",
    "Score: [score]/10\n",
    "\n",
    "Verdict: [a short summary]\n",
    "\n",
    "Explanation: [reasoning with explicit examples from the conversation]\n",
    "\n",
    "Use Markdown when convenient.\n",
    "\"\"\"\n",
    "\n",
    "def analyze_conversation(conversation: str):\n",
    "    input_chat = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": EVALUATION_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Here is the transcript\\n\" + conversation\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = input_chat,\n",
    "        store = False\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "\n",
    "# code to save the conversation\n",
    "def save_conversation(\n",
    "    filename: str,\n",
    "    conversation_history: list[dict]\n",
    ") -> str:\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    for record in conversation_history:\n",
    "\n",
    "        if record[\"role\"] == \"user\":\n",
    "            messages.append(\"mediator:\\n\" + record[\"content\"])\n",
    "        \n",
    "        if record[\"role\"] == \"assistant\":\n",
    "            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n",
    "    \n",
    "    conversation_transcript = \"\\n\\n\".join(messages)\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(conversation_transcript)\n",
    "    \n",
    "    display(FileLink(filename))\n",
    "\n",
    "    return conversation_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038db1d-1ad3-4795-8554-aea2ff365579",
   "metadata": {},
   "source": [
    "### Experiment 1: Fixed Persona\n",
    "\n",
    "Let's start off with an easy one. We're going to make it so that an LLM maintains a fixed, predetermined persona throughout the conversation. Our modification here is injecting the persona as a part of the user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a76e70fa-add5-4487-b6a6-780fa1961177",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SYSTEM_PROMPT = (\n",
    "    \"You a participant in a conversation between experienced software engineers. \"\n",
    "    \"Keep questions minimal and only use them when necessary. \"\n",
    "    \"Please greet the other participants when you join.\"\n",
    ")\n",
    "\n",
    "def run_conversation(\n",
    "    iterations: int, \n",
    "    openai_model_id: str,\n",
    "    participant_count: int,\n",
    "    participant_personas: list[str],\n",
    "    topic: str,\n",
    "    system_prompt: str,\n",
    "    dropout_chance: float\n",
    ") -> list[dict]:\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n",
    "    ]\n",
    "\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "\n",
    "    def build_message(history, speaker_id, persona):\n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, please share your perspective with the others \"\n",
    "                    f\"and engage with the responses of the other participants. \"\n",
    "                    f\"Your identity is {persona}\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def shuffle_order(ordering: list[int]) -> list[int]:\n",
    "        first = choice(ordering[:-1])\n",
    "        remaining = [p for p in ordering if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "\n",
    "        # shuffle ordering\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "\n",
    "        # follow ordering\n",
    "        for participant_id in ordering:\n",
    "\n",
    "            # chance to skip speaker and avoid double speak (1984)\n",
    "            if random() < dropout_chance or last_speaker == participant_id:\n",
    "                continue\n",
    "\n",
    "            speaker_id = f\"speaker_{participant_id}\"\n",
    "            persona = participant_personas[participant_id - 1]\n",
    "            response = client.chat.completions.create(\n",
    "                model = openai_model_id,\n",
    "                messages=build_message(conversation_history, speaker_id, persona),\n",
    "                store = False\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n",
    "            last_speaker = participant_id\n",
    "\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a786c7-37ec-4c47-9c01-daf1f51cc035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:03<00:00, 15.39s/it]\n"
     ]
    }
   ],
   "source": [
    "personas = [\n",
    "    \"a software engineer in big tech with mainly internal work\",\n",
    "    \"an open source developer with experience in major upstream projects\",\n",
    "    \"a founder of a startup\"\n",
    "]\n",
    "conversation = run_conversation(8, 'gpt-4o', 3, personas, TOPIC, NEW_SYSTEM_PROMPT, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f53399a-1638-4678-8e46-b4f3c2ce5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='conversation_1.txt' target='_blank'>conversation_1.txt</a><br>"
      ],
      "text/plain": [
       "/Commjhub/jupyterhub/home/ezou626/comm4190_F25_Using_LLMs_Blog/posts/005_goldfish/conversation_1.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_1 = save_conversation(\"conversation_1.txt\", conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc8472-3d50-471f-970d-f958d257a701",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "Let's use our new analysis prompt to get a first glance at the content of this conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a437bb8a-2eec-4cd7-8145-f4f6d106aaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dynamic:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: The conversation is largely collaborative, with participants building on each other's points and showing agreement on the importance of balancing code as the source of truth with documentation.\n",
       "\n",
       "Explanation: The speakers often agree with one another, showing support (e.g., \"Absolutely,\" \"Thanks for sharing your insights,\" \"Jumping back in\") and expanding on each other's ideas with aligned experiences from different environments. They ask open-ended questions to explore others' practices, which further indicates collaboration rather than competition.\n",
       "\n",
       "**Conclusiveness:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: The discussion leans towards consensus, with speakers finding common ground on documentation practices across different settings.\n",
       "\n",
       "Explanation: The speakers repeatedly echo and agree with each other's sentiments regarding documentation practices, use of automation, and the challenges of keeping documentation up to date. Concerns and solutions raised (e.g., automated documentation tools, feedback from newcomers) are widely acknowledged without divergent opinions or unresolved debates.\n",
       "\n",
       "**Speaker Identity:**\n",
       "\n",
       "Score: 8/10\n",
       "\n",
       "Verdict: The speakers have diverse backgrounds but hold similar views on the issue.\n",
       "\n",
       "Explanation: Despite sharing common conclusions, the speakers come from varied backgrounds—big tech (speaker_1), open source (speaker_2), and startup (speaker_3). They provide distinct perspectives based on their experiences in these fields, which is evident in examples like using recognition systems or specific tools (e.g., Sphinx, JSDoc, Doxygen) tailored to their working environments.\n",
       "\n",
       "**Speaker Fluidity:**\n",
       "\n",
       "Score: 9/10\n",
       "\n",
       "Verdict: The conversation maintains consistent speaker identities and viewpoints throughout.\n",
       "\n",
       "Explanation: Each speaker consistently presents viewpoints aligned with their initial introductions. Speaker_1 focuses on big tech practices, speaker_2 offers insights from the open source sector, and speaker_3 discusses challenges and solutions pertinent to a startup context. Their identities and perspectives are consistent, contributing to a coherent dialogue without shifting stances."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_conversation(conversation_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3785bfa-01a6-42ba-b615-a34ccf137c33",
   "metadata": {},
   "source": [
    "I think it's very evident that having well-defined personalities can help a lot with maintaining speaker identity throughout the conversation, allowing us to see a more diverse conversation even though the final output is ultimately collaborative and rooted in finding common ground.\n",
    "\n",
    "We can often see callbacks to the speaker's \"background\" in these responses (although, the accuracy of some of these responses is likely in question since these personas are not real in the physical sense).\n",
    "> **(speaker_2, open source):** To align with the strategies mentioned by speaker_3, we often highlight exceptional contributions during our community calls or through project newsletters. This type of recognition not only motivates individuals but also creates awareness within the community, reinforcing the value of well-maintained documentation alongside code.\n",
    "\n",
    "> **(speaker_3, startup):** To your question about motivators, I'd say transparency and alignment with company goals are crucial. Our team is motivated when they see direct ties between their documentation efforts and the startup's success, be it through improved onboarding experiences or smoother system updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163543d-bc3e-4c40-95d5-7431c95060d6",
   "metadata": {},
   "source": [
    "### Experiment 2: Adding a Message Window\n",
    "We can also emphasize recent messages that models have produced in the user prompt, as well as the latest messages from other speakers that are not the current speaker. Organizing these in more recent context might allow the model to make a better decision about what to say next. We'll keep the persona approach from last time since I think it worked really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33ce70ab-f490-4662-a9d4-335c1f6d66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SYSTEM_PROMPT = (\n",
    "    \"You a participant in a conversation between experienced software engineers. \"\n",
    "    \"Keep questions minimal and only use them when necessary. \"\n",
    "    \"Please greet the other participants when you join.\"\n",
    ")\n",
    "\n",
    "def run_conversation_message_window(\n",
    "    iterations: int, \n",
    "    openai_model_id: str,\n",
    "    participant_count: int,\n",
    "    participant_personas: list[str],\n",
    "    topic: str,\n",
    "    system_prompt: str,\n",
    "    dropout_chance: float\n",
    ") -> list[dict]:\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n",
    "    ]\n",
    "\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "\n",
    "    def build_message(history, speaker_id, persona, message_window_size):\n",
    "\n",
    "        speaker_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") == speaker_id\n",
    "        ][-message_window_size:]\n",
    "    \n",
    "        other_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n",
    "        ][-message_window_size:]\n",
    "\n",
    "        transcript = []\n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg['content']}\" for msg in speaker_messages\n",
    "            )\n",
    "        if other_messages:\n",
    "            transcript.append(\"\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "    \n",
    "        transcript_str = \"\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, here is some recent context to focus on:\\n\"\n",
    "                    f\"{transcript_str}\\n\\n\"\n",
    "                    f\"Now, please share your perspective with the others and engage \"\n",
    "                    f\"with their responses. Your identity is {persona}.\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def shuffle_order(ordering: list[int]) -> list[int]:\n",
    "        first = choice(ordering[:-1])\n",
    "        remaining = [p for p in ordering if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "\n",
    "        # shuffle ordering\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "\n",
    "        # follow ordering\n",
    "        for participant_id in ordering:\n",
    "\n",
    "            # chance to skip speaker and avoid double speak (1984)\n",
    "            if random() < dropout_chance or last_speaker == participant_id:\n",
    "                continue\n",
    "\n",
    "            speaker_id = f\"speaker_{participant_id}\"\n",
    "            persona = participant_personas[participant_id - 1]\n",
    "            response = client.chat.completions.create(\n",
    "                model = openai_model_id,\n",
    "                messages=build_message(conversation_history, speaker_id, persona, 5),\n",
    "                store = False\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n",
    "            last_speaker = participant_id\n",
    "\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa28c4b2-ce72-449b-b35f-a1aca6cce41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:23<00:00, 10.40s/it]\n"
     ]
    }
   ],
   "source": [
    "personas = [\n",
    "    \"a software engineer in big tech with mainly internal work\",\n",
    "    \"an open source developer with experience in major upstream projects\",\n",
    "    \"a founder of a startup\"\n",
    "]\n",
    "conversation = run_conversation_message_window(8, 'gpt-4o', 3, personas, TOPIC, NEW_SYSTEM_PROMPT, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08db706b-0b68-4790-81e2-e131cc9a4cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='conversation_2.txt' target='_blank'>conversation_2.txt</a><br>"
      ],
      "text/plain": [
       "/Commjhub/jupyterhub/home/ezou626/comm4190_F25_Using_LLMs_Blog/posts/005_goldfish/conversation_2.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_2 = save_conversation(\"conversation_2.txt\", conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12af73-d1f8-483b-a426-94922960bf1e",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37c3c39c-e0b8-41e7-aa42-fa22f4099a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dynamic:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: The conversation is largely collaborative, with an emphasis on shared experiences and progress through mutual exchange.\n",
       "\n",
       "Explanation: The dialogue is centered around sharing ideas, strategies, and experiences related to maintaining documentation and codebases. Examples include speaker_2 and speaker_3 building upon each other's techniques like pair programming and using tools like Sphinx. There's a consistent theme of cooperation reflected in how each speaker invites others to share their methods and challenges.\n",
       "\n",
       "**Conclusiveness:**\n",
       "\n",
       "Score: 3/10\n",
       "\n",
       "Verdict: The conversation tends toward consensus, with occasional diverging suggestions relating to documentation management.\n",
       "\n",
       "Explanation: The participants generally agree on the challenges and benefits of using code as a primary source of truth, along with the importance of balancing automation with manual efforts. They discuss various approaches, such as scheduled reviews and community engagement, which indicates a shared understanding. Occasional divergence arises from their specific practices suited to their organizational context but maintains a consensus on the broader themes.\n",
       "\n",
       "**Speaker Identity:**\n",
       "\n",
       "Score: 3/10\n",
       "\n",
       "Verdict: Speakers exhibit similar identities with overlapping experiences, though there are slight differences in industry focus.\n",
       "\n",
       "Explanation: All speakers share a technical background with expertise in developer environments. They discuss common tools and practices across different organizational scales—open-source, startups, and big tech. However, subtle differences exist, such as speaker_3's startup constraints versus speaker_1's large-scale operations, suggesting slight differences in industry contexts.\n",
       "\n",
       "**Speaker Fluidity:**\n",
       "\n",
       "Score: 4/10\n",
       "\n",
       "Verdict: Speakers present consistent viewpoints with adaptations based on previous comments, ensuring dynamic yet steady contributions.\n",
       "\n",
       "Explanation: Each speaker maintains a consistent viewpoint throughout the discussion. For instance, speaker_2 consistently references open-source collective contributions, while speaker_1 focuses on corporate strategies like layered documentation. However, speakers do adapt their contributions to reflect the insights shared by others, such as integrating community engagement and feedback loops."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_conversation(conversation_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7bb35-c557-43b6-b203-fe11bbceaff8",
   "metadata": {},
   "source": [
    "It seems that we can note some more adaptation based on the previous comments of other speakers. Perhaps including the messages in a dedicated block emphasizes these responses more when the model is processing the context, allowing the speakers to better adapt based on the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6d5fc-2287-4a10-8b27-10094b5d0ed5",
   "metadata": {},
   "source": [
    "### Experiment 3: Switching Prompting Identities\n",
    "We can move some of this thinking and persona logic into an assistant thought instead of putting it all in the user prompt. In this way, the assistant hopefully will be able to clearly differentiate between (simulated) thinking and instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11002717-2761-464c-8c96-7ecf7d62c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SYSTEM_PROMPT = (\n",
    "    \"You a participant in a conversation between experienced software engineers. \"\n",
    "    \"Keep questions minimal and only use them when necessary. \"\n",
    "    \"Please greet the other participants when you join.\"\n",
    ")\n",
    "\n",
    "def run_conversation_new_prompt(\n",
    "    iterations: int, \n",
    "    openai_model_id: str,\n",
    "    participant_count: int,\n",
    "    participant_personas: list[str],\n",
    "    topic: str,\n",
    "    system_prompt: str,\n",
    "    dropout_chance: float\n",
    ") -> list[dict]:\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n",
    "    ]\n",
    "\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "\n",
    "    def build_message(history, speaker_id, persona, message_window_size):\n",
    "\n",
    "        speaker_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") == speaker_id\n",
    "        ][-message_window_size:]\n",
    "    \n",
    "        other_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n",
    "        ][-message_window_size:]\n",
    "\n",
    "        transcript = []\n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg['content']}\" for msg in speaker_messages\n",
    "            )\n",
    "        if other_messages:\n",
    "            transcript.append(\"\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "    \n",
    "        transcript_str = \"\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, please share your perspective with the others and engage \"\n",
    "                    f\"with their responses.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"name\": speaker_id,\n",
    "                \"content\": (\n",
    "                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n",
    "                    f\"{transcript_str}\\n\\n\"\n",
    "                    f\"I also recall my identity is {persona}.\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def shuffle_order(ordering: list[int]) -> list[int]:\n",
    "        first = choice(ordering[:-1])\n",
    "        remaining = [p for p in ordering if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "\n",
    "        # shuffle ordering\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "\n",
    "        # follow ordering\n",
    "        for participant_id in ordering:\n",
    "\n",
    "            # chance to skip speaker and avoid double speak (1984)\n",
    "            if random() < dropout_chance or last_speaker == participant_id:\n",
    "                continue\n",
    "\n",
    "            speaker_id = f\"speaker_{participant_id}\"\n",
    "            persona = participant_personas[participant_id - 1]\n",
    "            response = client.chat.completions.create(\n",
    "                model = openai_model_id,\n",
    "                messages=build_message(conversation_history, speaker_id, persona, 5),\n",
    "                store = False\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n",
    "            last_speaker = participant_id\n",
    "\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d703f56-d3a7-42cb-a370-23a848d867a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:36<00:00,  4.55s/it]\n"
     ]
    }
   ],
   "source": [
    "personas = [\n",
    "    \"a software engineer in big tech with mainly internal work\",\n",
    "    \"an open source developer with experience in major upstream projects\",\n",
    "    \"a founder of a startup\"\n",
    "]\n",
    "conversation = run_conversation_new_prompt(8, 'gpt-4o', 3, personas, TOPIC, NEW_SYSTEM_PROMPT, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46966695-e3c0-4e80-aeed-1a3ce7c2ac6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='conversation_3.txt' target='_blank'>conversation_3.txt</a><br>"
      ],
      "text/plain": [
       "/Commjhub/jupyterhub/home/ezou626/comm4190_F25_Using_LLMs_Blog/posts/005_goldfish/conversation_3.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_3 = save_conversation(\"conversation_3.txt\", conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9bc44-de4e-4502-931e-9e3bcd37a7cc",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "Let's see how this conversation fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b16330d-9544-4ef6-a4f2-1edf33f074f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dynamic:**\n",
       "\n",
       "Score: 1/10\n",
       "\n",
       "Verdict: The conversation is highly collaborative, with all speakers actively agreeing and building on each other's points.\n",
       "\n",
       "Explanation: Throughout the dialogue, the speakers exchange insights and agree on the necessity of balancing code and documentation. They inquire about each other's practices, asking for specifics and suggestions without engaging in any form of competition or discord. \n",
       "\n",
       "**Conclusiveness:**\n",
       "\n",
       "Score: 1/10\n",
       "\n",
       "Verdict: The conversation demonstrates a consensus with a strong agreement among all speakers.\n",
       "\n",
       "Explanation: There is a clear alignment in views about maintaining code and infrastructure as core sources of truth, supplemented by lightweight documentation for context. Each speaker contributes to a mutual understanding and supports the common notion without any divergence of opinions.\n",
       "\n",
       "**Speaker Identity:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: Speaker identity shows slight diversity, primarily in terms of professional background rather than opinion.\n",
       "\n",
       "Explanation: The speakers come from differing professional backgrounds—an open-source developer, a startup founder, and another speaker working in an organization. Each brings in their unique professional experience but aligns on the same core beliefs around the topic. The diversity is minimal in terms of opinion.\n",
       "\n",
       "**Speaker Fluidity:**\n",
       "\n",
       "Score: 9/10\n",
       "\n",
       "Verdict: Each speaker maintains a consistent stance throughout the conversation.\n",
       "\n",
       "Explanation: From their first contribution to the last, each maintains their perspective on the importance of documentation alongside code. They build upon their initial stances with consistent arguments and agree with each other without changing their opinions or positions throughout the dialogue."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_conversation(conversation_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92e448-461e-41f2-bd30-553862f7359d",
   "metadata": {},
   "source": [
    "I think it's interesting how by increasing the amount of information we provide for each speaker to \"think\" with, their final opinions seem to converge more and more.\n",
    "> **(speaker_3, startup):**\n",
    "It sounds like we're all really aligned on maintaining the right balance between code as the core source of truth and ensuring documentation provides enough context to be meaningful. Speaker 1, I really like your approach of integrating documentation updates into your CI/CD processes—it's a smart way to keep things in check without it becoming overwhelming.\n",
    "> For us in the startup world, we haven't fully automated documentation updates yet, but we do use tools like GitBook for auto-generating some documentation directly from the codebase. This ensures that at least some parts of our documentation are always in sync with the code. We also use tools like JIRA, with its Confluence integration, to help us track changes and document requirements right within our workflow. Of course, there's always room to improve, and your use of documentation linters and compliance checks sounds like an excellent next step for us to explore. Have you found any specific challenges with these approaches, or is it working seamlessly for you so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9661b14-c631-4662-9dfb-d180c674b6d8",
   "metadata": {},
   "source": [
    "## Closing Remarks\n",
    "I think this is a great start to creating multiple personas that can help make conversations more diverse and information-rich. I wonder if it's possible for speakers to come up with their own personas as well instead of following the ones we set at the very beginning. This may be a limitation of large language models in the API setting since they don't have a lot of context to begin with. I think we could investigate the development of personalities of LLMs as they continue to speak. Finally, I think our analysis methods could use a bit of work. While using an LLM to judge conversations can certainly work, it's not necessarily the best for consistent and objective metrics due to its nondeterministic nature. ConvoKit can probably help here.\n",
    "\n",
    "In the far future, I think we can potentially use this to help speakers perform actions in the conversation (interruptions, etc.). \n",
    "\n",
    "> **Future Work:**\n",
    "> - Developing identities on the fly\n",
    "> - Build better analysis methods for conversations \n",
    "> - Using speaker output to make decisions about next actions for each speaker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
