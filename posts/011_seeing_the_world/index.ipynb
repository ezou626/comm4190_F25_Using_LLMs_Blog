{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dcb803e8",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Seeing the World\"\n",
    "description: \"Giving LLMs actual eyes: Multimodal agents in a 2D grid\"\n",
    "author: \"Eric Zou\"\n",
    "date: \"12/03/2025\"\n",
    "categories:\n",
    "  - Agents\n",
    "  - Vision\n",
    "  - Multimodal\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc79c74",
   "metadata": {},
   "source": [
    "# True Vision\n",
    "\n",
    "In the previous post, [Agents in Space](../010_agents_in_space), we simulated \"sight\" by feeding a text description of coordinates to the model (e.g., \"You are at (5,5), Bob is at (10,10)\").\n",
    "\n",
    "But modern LLMs are multimodal. Why tell them where they are when we can *show* them?\n",
    "\n",
    "In this experiment, I'm going to render the 2D grid as an image at every step and pass it to GPT-4o. The agents will have to look at the pixels to figure out where they are and where to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d307ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "# Load keys\n",
    "_ = load_dotenv(\"../../.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "@dataclass\n",
    "class Agent:\n",
    "    name: str\n",
    "    x: int\n",
    "    y: int\n",
    "    color: str\n",
    "    history: list = field(default_factory=list)\n",
    "\n",
    "    def move(self, dx, dy):\n",
    "        self.x += dx\n",
    "        self.y += dy\n",
    "\n",
    "agents = [\n",
    "    Agent(\"Alice\", 5, 5, \"red\"),\n",
    "    Agent(\"Bob\", 15, 15, \"blue\"),\n",
    "    Agent(\"Charlie\", 5, 15, \"green\"),\n",
    "    Agent(\"Dave\", 15, 5, \"orange\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_image_base64(agents):\n",
    "    # Create plot without showing it\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.xlim(0, 20)\n",
    "    plt.ylim(0, 20)\n",
    "    \n",
    "    for agent in agents:\n",
    "        plt.scatter(agent.x, agent.y, c=agent.color, s=300, edgecolors='black', label=agent.name)\n",
    "        # Add text labels so the model knows who is who\n",
    "        plt.text(agent.x, agent.y + 1, agent.name, ha='center', weight='bold', fontsize=12)\n",
    "    \n",
    "    plt.grid(True, linestyle= '--', alpha=0.5)\n",
    "    plt.title(\"Current World State\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    \n",
    "    # Save to buffer\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    plt.close()\n",
    "    return image_base64\n",
    "\n",
    "# Test it works (displaying for us humans)\n",
    "img_str = get_grid_image_base64(agents)\n",
    "print(f\"Generated base64 string of length {len(img_str)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2473a",
   "metadata": {},
   "source": [
    "## The Visual Agent Loop\n",
    "\n",
    "We'll perform a similar simulation to the last post, but the system prompt will change violently. Instead of \"Your location is (5,5)\", we just say: \"Look at the image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85f9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visual_step(agent, all_agents):\n",
    "    # 1. Render the world\n",
    "    base64_image = get_grid_image_base64(all_agents)\n",
    "    \n",
    "    # 2. Construct the multimodal prompt\n",
    "    system_prompt = f\"\"\"\n",
    "You are the {agent.color.upper()} agent named {agent.name}.\n",
    "The image provided shows the current state of a 20x20 grid.\n",
    "There are no explicit objectives here, but try to coordinate with the other agents.\n",
    "Messages can be seen globally. This is like an online chatroom.\n",
    "\n",
    "Output format:\n",
    "THOUGHT: (Analysis of the image)\n",
    "MOVE: [UP/DOWN/LEFT/RIGHT]\n",
    "MESSAGE: (Short message to the other agents)\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": system_prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 3. Call the model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    print(f\"--- {agent.name}'s Turn ---\")\n",
    "    print(content)\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    # 4. Execute Move (Simple regex parsing)\n",
    "    match = re.search(r'MOVE:\\s*(\\w+)', content)\n",
    "    if match:\n",
    "        direction = match.group(1).upper()\n",
    "        if direction == \"UP\": agent.move(0, 1)\n",
    "        elif direction == \"DOWN\": agent.move(0, -1)\n",
    "        elif direction == \"LEFT\": agent.move(-1, 0)\n",
    "        elif direction == \"RIGHT\": agent.move(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23946ebf",
   "metadata": {},
   "source": [
    "### 2 Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2afad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 1 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: Alice is near the bottom-left (5,5) and Bob is towards the top-right (15,15). Consider moving closer for coordination.\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Moving right towards Bob! Where should we meet?\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm positioned at (15, 15). Alice is at (5, 5). No explicit objective, so moving towards Alice could be a way to coordinate better.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Moving left to coordinate with you, Alice.\n",
      "--------------------\n",
      "\n",
      "=== STEP 2 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm positioned at (5, 5), and I see Bob at (15, 15). There might be more value in moving towards Bob to coordinate better.\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Moving towards you, Bob! Let's meet up.\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I am located at (12, 15), and Alice is at (7, 5). There's no specific objective besides possibly coordinating with Alice.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Moving down to get closer. What's our plan, Alice?\n",
      "--------------------\n",
      "\n",
      "=== STEP 3 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm at (7, 5) and Bob is at (13, 14). Moving towards Bob could be a good idea if we want to meet up.\n",
      "\n",
      "MOVE: UP\n",
      "\n",
      "MESSAGE: Heading north. Let's coordinate!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm currently positioned at (12, 14). Alice is at (6, 5). We could converge, explore separately, or follow another strategy.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Heading left. Alice, what's your next move?\n",
      "--------------------\n",
      "\n",
      "=== STEP 4 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm at position (6, 7) and Bob is at (13, 15). Moving right will bring me closer to Bob.\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Hey Bob, moving closer to you!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm positioned at (12, 15), and Alice is at (8, 6). I'm higher up on the grid compared to Alice.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Moving towards you, Alice!\n",
      "--------------------\n",
      "\n",
      "=== STEP 5 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: Bob is positioned to the northeast relative to me. Coordination could involve getting closer or exploring different parts of the grid.\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Moving right to see if we can meet up closer. Let me know your move!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: Alice is towards the lower part of the grid, while I'm higher up. We should consider moving closer to coordinate.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Alice, I'm moving down to get closer. Let me know your direction!\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Reset\n",
    "agents = [\n",
    "    Agent(\"Alice\", 5, 5, \"red\"),\n",
    "    Agent(\"Bob\", 15, 15, \"blue\"),\n",
    "]\n",
    "\n",
    "# Run a few steps\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== STEP {i+1} ===\")\n",
    "    for agent in agents:\n",
    "        run_visual_step(agent, agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126c587",
   "metadata": {},
   "source": [
    "### 4 Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9fd1826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 1 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm currently at position (5, 5). The other agents are scattered across the grid. Moving closer to the center may facilitate better coordination.\n",
      "\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Moving towards the center to regroup!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm positioned near the top right at (15,16). Other agents are spread out. No immediate objectives are visible.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Exploring the left side of the grid. Where is everyone heading?\n",
      "--------------------\n",
      "--- Charlie's Turn ---\n",
      "THOUGHT: I'm positioned at (5, 15). Alice is below at (5, 5), Bob is to the right at (12, 15), and Dave is at (15, 5). We are somewhat spread out. Alice and I are aligned vertically.\n",
      "\n",
      "MOVE: DOWN\n",
      "\n",
      "MESSAGE: Moving down towards Alice, let's see if we can group up.\n",
      "--------------------\n",
      "--- Dave's Turn ---\n",
      "THOUGHT: I'm on the right side of the grid, positioned at (15, 5). Alice is near me, while Charlie and Bob are further away. Moving towards the center could facilitate better coordination.\n",
      "\n",
      "MOVE: LEFT\n",
      "\n",
      "MESSAGE: Heading towards the center for better coordination!\n",
      "--------------------\n",
      "\n",
      "=== STEP 2 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm positioned at (5, 5). Charlie is above me, Bob is diagonally up to the right, and Dave is to my right. It might be strategic to move closer to someone.\n",
      "\n",
      "MOVE: RIGHT\n",
      "\n",
      "MESSAGE: Moving right to get closer to Dave. Let's see what happens!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm positioned at the top of the grid, near the center. Other agents are dispersed in the bottom half.\n",
      "MOVE: UP\n",
      "MESSAGE: Moving up to explore the edge of the grid.\n",
      "--------------------\n",
      "--- Charlie's Turn ---\n",
      "THOUGHT: I am at (5, 15). Alice is below me at (5, 5), Bob is to my right at (10, 15), and Dave is to the southeast at (15, 5). Moving toward the others might be useful.\n",
      "\n",
      "MOVE: DOWN\n",
      "\n",
      "MESSAGE: Moving closer to you all!\n",
      "--------------------\n",
      "--- Dave's Turn ---\n",
      "THOUGHT: I'm on the right side, with Bob further up and Charlie and Alice to the left. No immediate goals, just exploring for now.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Moving towards the center to see what's happening.\n",
      "--------------------\n",
      "\n",
      "=== STEP 3 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm at coordinates (5,5). Other agents are around. It might be useful to form a cluster.\n",
      "MOVE: RIGHT\n",
      "MESSAGE: Moving right to form a group. Let's cluster near (7,5)!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I am positioned at a higher area of the grid. Charlie is nearby to the left, with Alice and Dave positioned further down. I should coordinate to get closer to Alice and Dave.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Moving down to get closer to everyone. Let's gather!\n",
      "--------------------\n",
      "--- Charlie's Turn ---\n",
      "THOUGHT: I am positioned at (5,13). Bob is to the right and slightly higher, Alice and Dave are below me in the grid.\n",
      "\n",
      "MOVE: DOWN\n",
      "\n",
      "MESSAGE: Moving closer to Alice and Dave to see what they're up to.\n",
      "--------------------\n",
      "--- Dave's Turn ---\n",
      "THOUGHT: I'm positioned at (12, 5), close to Alice, who is at (8, 5). Bob and Charlie are farther away. There are no explicit objectives, so I should try to stay coordinated.\n",
      "\n",
      "MOVE: LEFT\n",
      "\n",
      "MESSAGE: I'm moving closer to you, Alice. Letâ€™s work together!\n",
      "--------------------\n",
      "\n",
      "=== STEP 4 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm positioned at (7, 5) near Dave, with Charlie and Bob farther up. There's no clear objective. Moving towards the center could be strategic for coordination.\n",
      "\n",
      "MOVE: UP\n",
      "MESSAGE: Moving up to explore. Let's stay coordinated, team!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm currently positioned at (14, 15). The other agents are scattered around the grid. Moving closer to them could promote coordination or interaction.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Moving left to coordinate with others. Where are you heading?\n",
      "--------------------\n",
      "--- Charlie's Turn ---\n",
      "THOUGHT: I'm currently positioned at (5, 13). Alice is nearby at (7, 6), Bob is at (12, 15), and Dave is at (12, 4). No defined objectives, but staying near Alice could be useful.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Moving towards Alice. Let's see if we can coordinate from here!\n",
      "--------------------\n",
      "--- Dave's Turn ---\n",
      "THOUGHT: I am located at (11, 4), close to Alice. Charlie and Bob are farther away. \n",
      "MOVE: UP\n",
      "MESSAGE: Heading up towards Alice!\n",
      "--------------------\n",
      "\n",
      "=== STEP 5 ===\n",
      "--- Alice's Turn ---\n",
      "THOUGHT: I'm positioned at (7, 5). Dave is nearby at (12, 5). Charlie and Bob are further away. I should consider moving closer to one of them for potential coordination.\n",
      "\n",
      "MOVE: RIGHT\n",
      "\n",
      "MESSAGE: Moving closer to you, Dave. Let's see what's ahead!\n",
      "--------------------\n",
      "--- Bob's Turn ---\n",
      "THOUGHT: I'm located at (11, 15) and the closest agent is Charlie at (6, 11). Alice and Dave are near each other at lower coordinates.\n",
      "MOVE: LEFT\n",
      "MESSAGE: Moving towards Charlie for potential rendezvous or collaboration.\n",
      "--------------------\n",
      "--- Charlie's Turn ---\n",
      "THOUGHT: I am located at (5, 12). Other agents are spread out, with Alice and Dave nearby. Coordination could involve moving towards them to form a cluster.\n",
      "MOVE: DOWN\n",
      "MESSAGE: Moving towards you, Alice and Dave. Let's coordinate!\n",
      "--------------------\n",
      "--- Dave's Turn ---\n",
      "THOUGHT: I am positioned near Alice, with Charlie and Bob further away. No specific goal is apparent, but staying coordinated might be beneficial.\n",
      "\n",
      "MOVE: RIGHT\n",
      "\n",
      "MESSAGE: Moving right to explore and maintain coordination.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Reset\n",
    "agents = [\n",
    "    Agent(\"Alice\", 5, 5, \"red\"),\n",
    "    Agent(\"Bob\", 15, 15, \"blue\"),\n",
    "    Agent(\"Charlie\", 5, 15, \"green\"),\n",
    "    Agent(\"Dave\", 15, 5, \"orange\")\n",
    "]\n",
    "\n",
    "# Run a few steps\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== STEP {i+1} ===\")\n",
    "    for agent in agents:\n",
    "        run_visual_step(agent, agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe340f",
   "metadata": {},
   "source": [
    "## Contrast with Text-Based Coordinates\n",
    "\n",
    "Comparing this to the coordinate-based approach in the previous post:\n",
    "\n",
    "### 1. Spatial Awareness\n",
    "*   **Text (Post 010)**: The model has to do arithmetic to figure out \"I am at (5,5) and Bob is at (10,10), so I need to increase X and Y\". LLMs are notoriously hit-or-miss at arithmetic.\n",
    "*   **Vision (Post 011)**: The model can \"see\" the spatial relationship. This might be much more robust for complex pathfinding (e.g., if there was a wall in the middle).\n",
    "\n",
    "### 2. Ambiguity & Resolution\n",
    "*   **Text**: 100% precise. (5,5) is mathematically exact.\n",
    "*   **Vision**: Can be fuzzy. If the grid lines aren't clear, or if two agents overlap, the model might hallucinate positions.\n",
    "\n",
    "### 3. Cost & Latency\n",
    "*   **Text**: Very cheap. A few tokens.\n",
    "*   **Vision**: Processing images is significantly more expensive and slower.\n",
    "\n",
    "For a simple open grid, text coords are efficient. But for a rich, messy world with real-time updates and timing? Vision might be an important piece of context for these kinds of virtual environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a65fc3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "I think we've gotten some good ideas about what these models can do in these environments. I think now is definitely a good time to see if we can encourage higher-level goals for the agents so that they can have more interesting discussions rather than just coordinating where to move. Humans regularly speak about other topics in online chatrooms and games not necessarily related to the game. I think it would be interesting to see if we can get the agents to do the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
