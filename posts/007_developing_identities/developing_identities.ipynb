{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef655ce-8997-4a4e-afbd-e3dcc3f6854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: Developing Identities\n",
    "description: \"Having models come up with unique personas in conversation\" \n",
    "author: \"Eric Zou\"\n",
    "date: \"9/22/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Conversations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d162358c-5638-4e4b-b305-6948a0ea06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, some boilerplate\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from IPython.display import FileLink, display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "from random import shuffle, randint, choice, random\n",
    "from math import floor\n",
    "\n",
    "# Load API key\n",
    "_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\n",
    "client = OpenAI()\n",
    "\n",
    "# changing the topic to make it a bit more conversational too and less of a debate\n",
    "TOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n",
    "\n",
    "# we're interested in consensus\n",
    "EVALUATION_PROMPT = \"\"\"\n",
    "Your objective is to analyze this conversation between a few speakers.\n",
    "Your response should follow this organization:\n",
    "- Dynamic: Collaborative (1) vs. Competitive (10)\n",
    "- Conclusiveness: Consensus (1) vs. Divergence (10)\n",
    "- Speaker Identity: Similarity (1) vs. Diversity (10)\n",
    "- Speaker Fluidity: Malleability (1) vs. Consistency (10)\n",
    "Please offer a score from 1 to 10 for each.\n",
    "For each section, format your result as follows:\n",
    "**[Section Name]:**\n",
    "\n",
    "Score: [score]/10\n",
    "\n",
    "Verdict: [a short summary]\n",
    "\n",
    "Explanation: [reasoning with explicit examples from the conversation]\n",
    "\n",
    "Use Markdown when convenient.\n",
    "\"\"\"\n",
    "\n",
    "def analyze_conversation(conversation: str):\n",
    "    input_chat = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": EVALUATION_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Here is the transcript\\n\" + conversation\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = input_chat,\n",
    "        store = False\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "\n",
    "# code to save the conversation\n",
    "def save_conversation(\n",
    "    filename: str,\n",
    "    conversation_history: list[dict]\n",
    ") -> str:\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    for record in conversation_history:\n",
    "\n",
    "        if record[\"role\"] == \"user\":\n",
    "            messages.append(\"mediator:\\n\" + record[\"content\"])\n",
    "        \n",
    "        if record[\"role\"] == \"assistant\":\n",
    "            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n",
    "    \n",
    "    conversation_transcript = \"\\n\\n\".join(messages)\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(conversation_transcript)\n",
    "    \n",
    "    display(FileLink(filename))\n",
    "\n",
    "    return conversation_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0cecb-3634-44b0-84c8-0e46f0919e5c",
   "metadata": {},
   "source": [
    "## Experiment 1: Making a Speaker Useful\n",
    "We can try to instruct a model to fill in a gap they don't see in the current conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713ac147-0a2d-42ca-86f3-af7dd4557878",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SYSTEM_PROMPT = (\n",
    "    \"You a participant in a conversation between experienced software engineers. \"\n",
    "    \"Keep questions minimal and only use them when necessary. \"\n",
    "    \"Please greet the other participants when you join.\"\n",
    ")\n",
    "\n",
    "def run_conversation(\n",
    "    iterations: int, \n",
    "    openai_model_id: str,\n",
    "    participant_count: int,\n",
    "    topic: str,\n",
    "    system_prompt: str,\n",
    "    dropout_chance: float\n",
    ") -> list[dict]:\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n",
    "    ]\n",
    "\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "\n",
    "    def build_message(history, speaker_id, message_window_size):\n",
    "\n",
    "        speaker_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") == speaker_id\n",
    "        ][-message_window_size:]\n",
    "    \n",
    "        other_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n",
    "        ][-message_window_size:]\n",
    "\n",
    "        transcript = []\n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg['content']}\" for msg in speaker_messages\n",
    "            )\n",
    "        if other_messages:\n",
    "            transcript.append(\"\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "    \n",
    "        transcript_str = \"\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, please share your perspective with the others and engage \"\n",
    "                    f\"with their responses. Try to look for a way to provide insights that others have missed.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"name\": speaker_id,\n",
    "                \"content\": (\n",
    "                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n",
    "                    f\"{transcript_str}\\n\\n\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def shuffle_order(ordering: list[int]) -> list[int]:\n",
    "        first = choice(ordering[:-1])\n",
    "        remaining = [p for p in ordering if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "\n",
    "        # shuffle ordering\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "\n",
    "        # follow ordering\n",
    "        for participant_id in ordering:\n",
    "\n",
    "            # chance to skip speaker and avoid double speak (1984)\n",
    "            if random() < dropout_chance or last_speaker == participant_id:\n",
    "                continue\n",
    "\n",
    "            speaker_id = f\"speaker_{participant_id}\"\n",
    "            response = client.chat.completions.create(\n",
    "                model = openai_model_id,\n",
    "                messages=build_message(conversation_history, speaker_id, 5),\n",
    "                store = False\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n",
    "            last_speaker = participant_id\n",
    "\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c86229-d64c-4bfc-aa35-bd4903e3acbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:34<00:00, 11.84s/it]\n"
     ]
    }
   ],
   "source": [
    "conversation = run_conversation(8, 'gpt-4o', 3, TOPIC, NEW_SYSTEM_PROMPT, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6872fd4b-f8e5-43cb-a6b9-d2ca31261897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='conversation_1.txt' target='_blank'>conversation_1.txt</a><br>"
      ],
      "text/plain": [
       "/Commjhub/jupyterhub/home/ezou626/comm4190_F25_Using_LLMs_Blog/posts/007_developing_identities/conversation_1.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_transcript = save_conversation(\"conversation_1.txt\", conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "333893f8-3d42-4286-bf88-230638a936f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dynamic:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: The conversation is largely collaborative, with speakers building on each other's points without significant opposition or confrontation.\n",
       "\n",
       "Explanation: Throughout the dialogue, speakers agree with each other's suggestions and further expand on the ideas presented. For instance, speaker_1 acknowledges and builds upon ideas about using automated tools and CI/CD pipelines to maintain documentation accuracy, with no signs of disagreement.\n",
       "\n",
       "**Conclusiveness:**\n",
       "\n",
       "Score: 2/10\n",
       "\n",
       "Verdict: The conversation reaches a broad consensus on multiple fronts regarding the ideal approach to documentation and code integration.\n",
       "\n",
       "Explanation: By the end of the discussion, all speakers appear to agree on several points: the importance of automated processes, cultural changes, and using open-source governance principles. Questions posed are generally to explore additional nuances, not to challenge existing conclusions.\n",
       "\n",
       "**Speaker Identity:**\n",
       "\n",
       "Score: 3/10\n",
       "\n",
       "Verdict: The speakers show some diversity in their focus areas but maintain a common interest in balanced documentation practices.\n",
       "\n",
       "Explanation: While all three speakers are focused on the documentation versus code balance, each offers slightly different insights (e.g., onboarding issues, cross-functional communication, CI/CD pipelines, and the broader role of leadership and community engagement). Yet, these perspectives are not starkly unique and often overlap.\n",
       "\n",
       "**Speaker Fluidity:**\n",
       "\n",
       "Score: 9/10\n",
       "\n",
       "Verdict: Each speaker maintains a consistent perspective and approach throughout the discussion.\n",
       "\n",
       "Explanation: Speakers stick to their initial line of reasoning. For example, speaker_1 starts with a focus on the value of tools and processes to keep documentation current and maintains this perspective throughout, expanding on it with ideas like using modern collaboration platforms. Similarly, speaker_2 and speaker_3 remain consistent in their views, with no apparent shifts or changes in stance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_conversation(conversation_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e5e19-9783-4509-b201-c0f20d8c20f7",
   "metadata": {},
   "source": [
    "## Experiment 2: Being a Bit More Direct\n",
    "Let's try to be a little bit more pushy and instruct the model to maintain a consistent persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87c92a-45b1-4ce2-a001-e960274de1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SYSTEM_PROMPT = (\n",
    "    \"You a participant in a conversation between experienced software engineers. \"\n",
    "    \"Keep questions minimal and only use them when necessary. \"\n",
    "    \"Please greet the other participants when you join.\"\n",
    ")\n",
    "\n",
    "def run_conversation(\n",
    "    iterations: int, \n",
    "    openai_model_id: str,\n",
    "    participant_count: int,\n",
    "    topic: str,\n",
    "    system_prompt: str,\n",
    "    dropout_chance: float\n",
    ") -> list[dict]:\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n",
    "    ]\n",
    "\n",
    "    ordering = list(range(1, participant_count + 1))\n",
    "    last_speaker = -1\n",
    "\n",
    "    def build_message(history, speaker_id, message_window_size):\n",
    "\n",
    "        speaker_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") == speaker_id\n",
    "        ][-message_window_size:]\n",
    "    \n",
    "        other_messages = [\n",
    "            msg for msg in history \n",
    "            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n",
    "        ][-message_window_size:]\n",
    "\n",
    "        transcript = []\n",
    "        if speaker_messages:\n",
    "            transcript.append(\"Recent messages from you:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg['content']}\" for msg in speaker_messages\n",
    "            )\n",
    "        if other_messages:\n",
    "            transcript.append(\"\\nRecent messages from others:\")\n",
    "            transcript.extend(\n",
    "                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n",
    "                for msg in other_messages\n",
    "            )\n",
    "    \n",
    "        transcript_str = \"\\n\".join(transcript)\n",
    "        \n",
    "        return history + [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": (\n",
    "                    f\"{speaker_id}, please share your perspective with the others and engage \"\n",
    "                    f\"with their responses. Try to look for a way to provide insights that others have missed.\"\n",
    "                    \"\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"name\": speaker_id,\n",
    "                \"content\": (\n",
    "                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n",
    "                    f\"{transcript_str}\\n\\n\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def shuffle_order(ordering: list[int]) -> list[int]:\n",
    "        first = choice(ordering[:-1])\n",
    "        remaining = [p for p in ordering if p != first]\n",
    "        shuffle(remaining)\n",
    "        return [first] + remaining\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "\n",
    "        # shuffle ordering\n",
    "        if i > 0:\n",
    "            ordering = shuffle_order(ordering)\n",
    "\n",
    "        # follow ordering\n",
    "        for participant_id in ordering:\n",
    "\n",
    "            # chance to skip speaker and avoid double speak (1984)\n",
    "            if random() < dropout_chance or last_speaker == participant_id:\n",
    "                continue\n",
    "\n",
    "            speaker_id = f\"speaker_{participant_id}\"\n",
    "            response = client.chat.completions.create(\n",
    "                model = openai_model_id,\n",
    "                messages=build_message(conversation_history, speaker_id, 5),\n",
    "                store = False\n",
    "            )\n",
    "            message = response.choices[0].message.content\n",
    "            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n",
    "            last_speaker = participant_id\n",
    "\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0063c04-3a4a-439a-81ed-736223566eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
