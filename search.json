[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a blog for my explorations and experiments with LLMs in the COMM 4190 class at UPenn. I’m hoping to focus on LLMs in social contexts like on social media apps and the implications of this kind of work."
  },
  {
    "objectID": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html",
    "href": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html",
    "title": "What It’s About",
    "section": "",
    "text": "---\ntitle: My Thoughts on These Strange New Minds\ndescription: \"Intro & Section 1\"\nauthor: \"Eric Zou\"\ndate: \"9/19/2025\"\ncategories:\n  - Review\n---\nFrom what I’ve read so far, it seems like the book is about where large language model (LLM) technology is headed, and how it’s different from what we’ve seen before. Christopher Summerfield (the author) spends the first section explaining the development of this technology. He cites historical examples of how humans have approached trying to imitate our own thinking ability. He starts with attempted constructions of thinking machines and moves into the modern era where new discoveries in neurons and computational modeling have allowed us to train large-scale deep neural networks to learn from massive datasets and generalize on unseen cases. Along the way, he contrasts two modes of thought, one being the rationalist/logical approach to thinking that was originally championed (expressing our understanding of the world in formal rules and logic) and the other being the empricist view, in which we learn continuously from experience in a way that doesn’t restrict itself to structure from the start. In the last chapter of this section, Summerfield leads into the development of the GPT series of LLMs, which I assume leads into an exploration into this novel technology."
  },
  {
    "objectID": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html#what-i-thought",
    "href": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html#what-i-thought",
    "title": "What It’s About",
    "section": "What I Thought",
    "text": "What I Thought\nI think that the section was pretty well-written. I haven’t read much print text lately, so I don’t think it could compare to any book directly. However, I thought the narrative was engaging enough to keep me reading, which is more than I can say for some other nonfiction books that I’ve read. I thought the conflict between the rationalist and empiricist approaches in knowledge were contrasted. I think it’s interesting how the huge breakthrough in GPT began as the training of a practical deep learning system, but now in current events we’re moving back to some rationalist, structured approaches like chain-of-thought prompting in order to emulate thinking much better. Summerfield brings up chess and ice skating as examples of the rationalist vs. empiricist approach in our lives, and he introduces the idea that our thinking may be a mix of both. I definitely think that’s the case, though I’m not sure if I could prove that."
  },
  {
    "objectID": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html#reflecting",
    "href": "posts/006_these_strange_new_minds_reaction_1/these_strange_new_minds_reaction.html#reflecting",
    "title": "What It’s About",
    "section": "Reflecting",
    "text": "Reflecting\nEven reading the intro of this book has made me pretty appreciative of where we’ve come from. Certainly, I’m a bit apprehensive about where we’re going with this technology and the multiple ways in which it could be misused or go haywire. At the same time, I think that with this breakthrough there’s much more that we’ll be able to do with this tool. AI might be able to help in the same way that the Internet complemented many people’s jobs and allowed so many more people to access information cheaply, enhancing people’s creativity by empowering people to understand difficult concepts without the super extensive technical backgrounds that others have."
  },
  {
    "objectID": "posts/005_goldfish/goldfish.html",
    "href": "posts/005_goldfish/goldfish.html",
    "title": "Goldfish",
    "section": "",
    "text": "---\ntitle: Goldfish\ndescription: \"Attempting to enhance context awareness in multi-speaker LLM conversations\" \nauthor: \"Eric Zou\"\ndate: \"9/17/2025\"\ncategories:\n  - LLMs\n  - Conversations\n---\nI think one of the main limits we’ve been hitting with this model is the ability of LLMs to maintain an organic and consistent personality that is distinct from the others. While collaborative conversations can be good and productive, our previous conversations have had to tradeoff between having a well-defined conversational conclusion and a discussion in which each person maintains/advocates for their positions throughout.\nWhat if there was a way we could build this into the speakers themselves? To do this, we’re going to shift from the standard user prompt before each speaker continues to add a persona that the LLM has been maintaining throughout the discussion. Our hope is that this will allow the model generating the response to better emulate a less fluid human speaker while still being able to mix well with the other models.\nWe’re not going to use the interruptions model we were testing in the last blog yet. I think we can figure out a smarter way to do that. We will keep the randomized speaker ordering and skipping though, as this might allow us to see improved resilience in models retaining their identity, even without speaking in turn.\n# first, some boilerplate\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display, Markdown\nfrom dotenv import load_dotenv\nfrom random import shuffle, randint, choice, random\nfrom math import floor\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()\n\n# changing the topic to make it a bit more conversational too and less of a debate\nTOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n\n# we're interested in consensus\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between a few speakers.\nYour response should follow this organization:\n- Dynamic: Collaborative (1) vs. Competitive (10)\n- Conclusiveness: Consensus (1) vs. Divergence (10)\n- Speaker Identity: Similarity (1) vs. Diversity (10)\n- Speaker Fluidity: Malleability (1) vs. Consistency (10)\nPlease offer a score from 1 to 10 for each.\nFor each section, format your result as follows:\n**[Section Name]:**\n\nScore: [score]/10\n\nVerdict: [a short summary]\n\nExplanation: [reasoning with explicit examples from the conversation]\n\nUse Markdown when convenient.\n\"\"\"\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    display(Markdown(response.choices[0].message.content))\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    conversation_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in conversation_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript"
  },
  {
    "objectID": "posts/005_goldfish/goldfish.html#closing-remarks",
    "href": "posts/005_goldfish/goldfish.html#closing-remarks",
    "title": "Goldfish",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nI think this is a great start to creating multiple personas that can help make conversations more diverse and information-rich. I wonder if it’s possible for speakers to come up with their own personas as well instead of following the ones we set at the very beginning. This may be a limitation of large language models in the API setting since they don’t have a lot of context to begin with. I think we could investigate the development of personalities of LLMs as they continue to speak. Finally, I think our analysis methods could use a bit of work. While using an LLM to judge conversations can certainly work, it’s not necessarily the best for consistent and objective metrics due to its nondeterministic nature. ConvoKit can probably help here.\nIn the far future, I think we can potentially use this to help speakers perform actions in the conversation (interruptions, etc.).\n\nFuture Work: - Developing identities on the fly - Build better analysis methods for conversations - Using speaker output to make decisions about next actions for each speaker"
  },
  {
    "objectID": "posts/003_approaching_a_true_discussion/Spontaneity.html",
    "href": "posts/003_approaching_a_true_discussion/Spontaneity.html",
    "title": "Spontaneity",
    "section": "",
    "text": "from openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display\nfrom dotenv import load_dotenv\nfrom random import shuffle, randint, choice, random\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()"
  },
  {
    "objectID": "posts/003_approaching_a_true_discussion/Spontaneity.html#llm-conversations",
    "href": "posts/003_approaching_a_true_discussion/Spontaneity.html#llm-conversations",
    "title": "Spontaneity",
    "section": "LLM Conversations",
    "text": "LLM Conversations\nWe’re going to build on our progress in the last post to introduce more spontaneity and randomness into our chats. Let’s first try adding randomness in the order in which models speak. By the second iteration, this could result in less predictable conversations.\nWe’re also going to change the prompt a little bit too. I’d like to switch more into understanding how we can inspire the LLM agents to collaborate and engage in a less structured way than a debate setting.\n\nDEBATE_TOPIC = \"\"\"Code, testing, and dev infra should be prioritized over comprehensive documentation.\"\"\"\nSYSTEM_PROMPT = \"You are participating in a conversation between experienced software engineers. Each speaker should respond when directed. Keep questions minimal and only use them when necessary.\"\n\n# prompt to analyze conversations\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between speakers.\nYour response should follow this organization:\n- A Brief Summary\n- Final Outputs/Artifacts/Takeaways\n- Characteristics/Dynamic (Competitive/Collaborative/etc.)\n\"\"\"\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    print(response.choices[0].message.content)\n\n\ndef run_organic_conversation_v1(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": \"The topic is: \" + topic}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n\n    for i in tqdm(range(iterations)):\n        if i &gt; 0:\n            first = choice(ordering[:-1])\n            remaining = [i for i in ordering if i != first]\n            shuffle(remaining)\n            ordering = [first] + remaining\n        for model in ordering: # RANDOM ORDERING\n            speaker_id = f\"speaker_{model}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history + [{\"role\": \"user\", \"content\": f\"{speaker_id}, it's your turn to speak.\"}],\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n\n    return debate_history\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    debate_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in debate_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript\n\n\nExperiment 1:\nLet’s keep 3 speakers throughout. It will probably be more interesting this way, since a conversation between two speakers could just have the messages be joined together (though this might be interesting to evaluate, we can add it as future work).\n\ndebate_1 = run_organic_conversation_v1(2, 'gpt-4o', 3, DEBATE_TOPIC, SYSTEM_PROMPT)\n\n100%|██████████| 2/2 [00:28&lt;00:00, 14.19s/it]\n\n\n\nconversation_transcript_1 = save_conversation(\"conversation_transcript_1.txt\", debate_1)\n\nconversation_transcript_1.txt\n\n\n\n\nAnalysis\nLike last time, we’re going to analyze the conversation with AI as well.\n\nanalyze_conversation(conversation_transcript_1)\n\n- **Brief Summary**: The conversation revolves around the prioritization between code, testing, and development infrastructure versus comprehensive documentation. Speaker 1 advocates for prioritizing the former due to its direct impact on software reliability and efficiency, suggesting documentation can follow as a secondary priority. Speaker 2 underscores the importance of comprehensive documentation, especially for onboarding and scalability. Speaker 3 proposes a balanced integration of documentation into the development process through automation and self-documenting techniques, aligning with regulatory requirements when necessary.\n\n- **Final Outputs/Artifacts/Takeaways**:\n  - There is an acknowledgment that both development infrastructure and documentation hold significant value, each crucial for different reasons such as reliability, maintainability, onboarding, and compliance.\n  - The consensus is towards integrating documentation seamlessly into the development process using automation and tools that ensure documentation remains current and synchronized with code changes.\n  - Practical strategies proposed include employing self-documenting code practices, utilizing documentation generation tools, and incorporating documentation updates into standard development workflows like code reviews and commit messaging.\n\n- **Characteristics/Dynamic (Collaborative/Competitive/etc.)**: \n  - The discussion is collaborative, with each speaker building upon the ideas of the others to arrive at a nuanced understanding of the balance between development priorities and documentation. \n  - Speakers recognize and incorporate differing viewpoints, ultimately finding a middle ground that supports both development efficiency and the comprehensive documentation needs.\n  - There is a collective move towards practical solutions that address potential conflicts between maintaining quality development practices and ensuring documentation does not become outdated or sidelined.\n\n\nWe’re shifting back to the conversational tone that we had in the first post, probably due mainly to the changes in the prompt. We can still see some disagreement in the beginning, but as the conversation continues, the speakers’ discussions converge, while still maintaining the individual opinions. However, each speaker always speaks once during each turn. This is not necessarily true for real world conversations.\n\n\nExperiment 2\nLet’s see if we can extend the conversation, but this time, let’s leverage randomness to simulate the fact that people don’t always participate in each conversation. We’ll keep a fixed order for now, but every time a model speaks, we’ll track it to make sure that the next speaker is not the same model.\n\ndef run_organic_conversation_v2(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": \"The topic is: \" + topic}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    for i in tqdm(range(iterations)):\n        # if i &gt; 0:\n        #     first = choice(ordering[:-1])\n        #     remaining = [i for i in ordering if i != first]\n        #     shuffle(remaining)\n        #     ordering = [first] + remaining\n        for model in ordering: # RANDOM ORDERING\n            if random() &lt; dropout_chance:\n                continue # SKIP\n            if last_speaker == model:\n                continue\n            speaker_id = f\"speaker_{model}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history + [{\"role\": \"user\", \"content\": f\"{speaker_id}, it's your turn to speak.\"}],\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = model\n\n    return debate_history\n\ndebate_2 = run_organic_conversation_v2(8, 'gpt-4o', 3, DEBATE_TOPIC, SYSTEM_PROMPT, 0.5)\n\n100%|██████████| 8/8 [00:56&lt;00:00,  7.10s/it]\n\n\n\nconversation_transcript_2 = save_conversation(\"conversation_transcript_2.txt\",debate_2)\n\nconversation_transcript_2.txt\n\n\n\n\nAnalysis\nFirst, let’s generate an AI summary of the conversation.\n\nanalyze_conversation(conversation_transcript_2)\n\n- **Brief Summary:**  \nThe conversation revolves around the prioritization of code, testing, and development infrastructure over comprehensive documentation. Speaker 1 argues for the importance of code and infrastructure as they ensure the quality and reliability of the software, especially in agile environments. Speaker 2 emphasizes the long-term benefits of documentation, particularly for knowledge retention and project sustainability. Speaker 3 brings a balanced perspective, advocating for adaptable strategies based on the project's lifecycle and promoting a development culture that values all aspects equally.\n\n- **Final Outputs/Artifacts/Takeaways:**  \n  - The need for balance between immediate development needs and sustainable documentation practices.\n  - Integration of documentation into the development process using automation tools to keep it current.\n  - Building a comprehensive development culture where all elements are seen as integral.\n  - Leadership roles in guiding priorities and maintaining balance.\n  - Utilizing data-driven approaches and feedback loops to inform strategy and resource allocation.\n\n- **Characteristics/Dynamic:**  \n  - **Collaborative:** The conversation exhibits a collaborative dynamic where all speakers acknowledge each other's points and build on them to reach a common ground.\n  - **Balanced Approach:** Emphasis on finding a balance between immediate and long-term project needs.\n  - **Adaptability:** Discusses the need for strategies that adapt to different stages of the project's lifecycle.\n  - **Leadership and Culture:** Highlights the role of leadership and team culture in achieving a balanced approach to software development.\n\n\nAt a glance, it certainly seems more conversational. I feel that the LLMs are making too many redundant summaries. Perhaps we can adjust the prompt to let the conversation build off the other statements.\n\n\nExperiment 3\nWe’re going to join the two prior approaches.\n\ndef run_organic_conversation_v3(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": \"The topic is: \" + topic}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    for i in tqdm(range(iterations)):\n        if i &gt; 0:\n            first = choice(ordering[:-1])\n            remaining = [i for i in ordering if i != first]\n            shuffle(remaining)\n            ordering = [first] + remaining\n        for model in ordering: # RANDOM ORDERING\n            if random() &lt; dropout_chance:\n                continue # SKIP\n            if last_speaker == model:\n                continue\n            speaker_id = f\"speaker_{model}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history + [{\"role\": \"user\", \"content\": f\"{speaker_id}, it's your turn to speak.\"}],\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = model\n\n    return debate_history\n\ndebate_3 = run_organic_conversation_v3(8, 'gpt-4o', 3, DEBATE_TOPIC, SYSTEM_PROMPT, 0.5)\n\n100%|██████████| 8/8 [00:43&lt;00:00,  5.39s/it]\n\n\n\nconversation_transcript_3 = save_conversation(\"conversation_transcript_3.txt\", debate_3)\n\nconversation_transcript_3.txt\n\n\n\n\nAnalysis\nNow, let’s get a quick summary of what happened.\n\nanalyze_conversation(conversation_transcript_3)\n\n- **Brief Summary**: The discussion revolves around the balance between code, testing, development infrastructure, and comprehensive documentation. Speaker 1 supports prioritizing code and infrastructure, especially in agile settings, but acknowledges the value of documentation. Speaker 2 emphasizes the importance of integrating key documentation practices alongside development to prevent knowledge bottlenecks. Speaker 3 advocates for a balanced approach where documentation evolves with development, employing tools and practices that ensure both areas are maintained effectively.\n\n- **Final Outputs/Artifacts/Takeaways**:\n  - The idea of iterative and lightweight documentation, evolving with the product, to enhance team onboarding and collaboration.\n  - Integration of documentation into the definition of \"done\" for each task and feature.\n  - Leveraging automated tools to maintain documentation accuracy and reduce manual burdens.\n  - Cultivating a culture where both code quality and documentation are seen as interconnected responsibilities through pair programming, continuous integration, and collaboration tools.\n\n- **Characteristics/Dynamics**: The conversation is collaborative and consensus-driven, with each speaker building on the ideas of others. There is a collective push towards achieving a balanced development process that recognizes the importance of both technical infrastructure and documentation. The dynamic reflects a mutual acknowledgment of each other's viewpoints, seeking common ground and practical solutions that integrate both priorities effectively in software development workflows.\n\n\nSurprisingly, I think this set was much more conversational than the last. I don’t know if I can declare this as reproducible though.\n\n\nExperiment 4\nThe final thing we can do is make the prompts more like thoughts. Instead of saying “it’s your turn to speak”, we can say “please share your current perspective with the crowd”. We can also alter the system prompt to not mention a simulation.\n\nNEW_SYSTEM_PROMPT = \"You a participant in a conversation between experienced software engineers. Keep questions minimal and only use them when necessary. Please greet the other participants when you join.\"\n\ndef run_organic_conversation_v4(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": system_prompt + \" The topic is: \" + topic}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    for i in tqdm(range(iterations)):\n        if i &gt; 0:\n            first = choice(ordering[:-1])\n            remaining = [i for i in ordering if i != first]\n            shuffle(remaining)\n            ordering = [first] + remaining\n        for model in ordering: # RANDOM ORDERING\n            if random() &lt; dropout_chance:\n                continue # SKIP\n            if last_speaker == model:\n                continue\n            speaker_id = f\"speaker_{model}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history + [{\"role\": \"user\", \"content\": f\"{speaker_id}, please share your perspective with the others and engage with the responses of the other participants.\"}],\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = model\n\n    return debate_history\n\ndebate_4 = run_organic_conversation_v4(8, 'gpt-4o', 3, DEBATE_TOPIC, NEW_SYSTEM_PROMPT, 0.5)\n\n100%|██████████| 8/8 [02:05&lt;00:00, 15.69s/it]\n\n\n\nconversation_transcript_4 = save_conversation(\"conversation_transcript_4.txt\", debate_4)\n\nconversation_transcript_4.txt\n\n\n\n\nAnalysis\nLet’s see how that changed the debate.\n\nanalyze_conversation(conversation_transcript_4)\n\n- **Brief Summary**: The conversation revolves around the balance between prioritizing code quality, testing, and development infrastructure over comprehensive documentation in software development. Speaker_1 initiates the discussion by emphasizing the importance of clean code and robust testing. Speaker_3 agrees while acknowledging the potential challenges of inadequate documentation in complex systems. Speaker_2 advocates for a balance, stressing the need for essential documentation and lightweight approaches like API documentation and high-level overviews. The conversation further explores innovative documentation methods like video tutorials and AI-assisted documentation.\n\n- **Final Outputs/Artifacts/Takeaways**: The primary takeaways include the consensus on the importance of balancing documentation with code quality and infrastructure. The participants also share practical strategies such as embedding documentation updates into the code review process, using version control for documentation, leveraging video tutorials, and experimenting with AI-driven documentation tools.\n\n- **Characteristics/Dynamic**: The conversation is highly collaborative, with each speaker building upon the others' points, sharing personal experiences, and exploring various strategies to achieve the common goal of effective software development practices. The speakers demonstrate a willingness to learn from each other's insights and adapt successful methods to their own workflows, fostering a dynamic environment of mutual respect and shared learning.\n\n\nThe conversation is much more conversational this time, with explicit instructions to address the other speakers, there’s a lot more structure in the engagement between the three speakers. Additionally, it seems that near the end of the conversation, the speakers converge toward some actionable items, despite there not being explicit instructions to find common ground."
  },
  {
    "objectID": "posts/003_approaching_a_true_discussion/Spontaneity.html#closing-remarks",
    "href": "posts/003_approaching_a_true_discussion/Spontaneity.html#closing-remarks",
    "title": "Spontaneity",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nWith the new shared chat window approach, some prompt tuning, and some randomization, we approach a more natural conversational vibe in the discussion between the 3 LLMs. It also feels less structured, and that could potentially allow for integration with human speakers and produce results similar to meetings or panels. It would be interesting to see what kinds of topics LLMs can excel in, or if they can even do well without having a predefined topic.\nIt’s also important to consider that this is probably not the only way to do this. Potentially, we could add more prompts before we get each speaker LLM to answer.\n\nFuture Work: - Experiment with more topics - Ignore predefined topic"
  },
  {
    "objectID": "posts/004_going_to_stop_you_right_there/going_to_stop_you_right_there.html",
    "href": "posts/004_going_to_stop_you_right_there/going_to_stop_you_right_there.html",
    "title": "Randomness as Interjections",
    "section": "",
    "text": "---\ntitle: \"Going to Have to Stop You Right There\"\ndescription: \"Probabilistic rudeness for better discussions\" \nauthor: \"Eric Zou\"\ndate: \"9/15/2025\"\ncategories:\n  - LLMs\n  - Conversations\n---\nWe’re going to try to continue improving on the authenticity and naturalness of the conversations we’re generating. One issue with LLM conversations is how structured they are, even without incredibly formal language or long responses. The fact that each model gets to (and needs to) completely finish before the next one can speak means that things that often happen in real conversations (interruptions, affirmations, etc.). This is not something that our paradigm explored last time has changed with random speaker ordering and potentially skipping speakers.\nWe’re going to try to add these things to hopefully make these conversations even more real.\n# first, some boilerplate\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display\nfrom dotenv import load_dotenv\nfrom random import shuffle, randint, choice, random\nfrom math import floor\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()\n\n# changing the topic to make it a bit more conversational too and less of a debate\nTOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n\n# prompt to analyze conversations\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between speakers.\nYour response should follow this organization:\n- A Brief Summary\n- Final Outputs/Artifacts/Takeaways\n- Characteristics/Dynamic (Competitive/Collaborative/etc.)\n\"\"\"\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    print(response.choices[0].message.content)\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    conversation_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in debate_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript"
  },
  {
    "objectID": "posts/004_going_to_stop_you_right_there/going_to_stop_you_right_there.html#closing-remarks",
    "href": "posts/004_going_to_stop_you_right_there/going_to_stop_you_right_there.html#closing-remarks",
    "title": "Randomness as Interjections",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nIn general, while these seem to make the conversation appear more natural from a bird’s eye view, there are evidently issues with the approach.\nFirst, because LLM’s operate with text, the introduction of interjections in the way done here doesn’t really model the way an interjection appears in real life conversations (separation vs. mixing, in that order). This could cause interjections to not be as effective in their intended purpose, or worse, interrupt the conversation flow. A potential remedy to this would be to reframe the problem as looking at an online chatroom and only allowing interjections at punctuation marks like periods or paragraph breaks. In that way, it’s much more like a chat conversation where messages are delivered in whole pieces without chance of interruption in the middle.\nSecond, I think there’s also an opportunity to develop speaker personas to enforce consistent actions across multiple messages. When speakers are prompted, there is a chance they may not remember what they are trying to work on, and there’s no way in the current simulation environment to differentiate one speaker from the other except in the order in which they speak. Maintaining a consistent state for each speaker could go a long way in ensuring better defined speakers, and as a result, more diverse conversations. Additionally, we may be able to use these personas to inform actions like interruptions or cutoffs.\n\nFuture Work: - There’s definitely an opportunity to develop speaker-level context that can be delivered in the message generation prompt. This would allow a more rich representation of the speaker’s internal thoughts, and this could even be managed by an LLM. - There’s also an opportunity to make some of these random things motivated by this context or the conversation, asking the AI if it wants to do a specific action given it’s current position. - It might be cool to have a general framework that considers all of these possible scenarios and allows for the simulation of these kinds of conversations with different models, parameters, etc."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs in Social Contexts",
    "section": "",
    "text": "Randomness as Interjections\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating a Conversation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoldfish\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperiment 1: Making a Speaker Useful\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat It’s About\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpontaneity\n\n\n\nLLMs\n\nConversations\n\n\n\nAdding randomness to an LLM conversation\n\n\n\n\n\nSep 12, 2025\n\n\nEric Zou\n\n\n\n\n\n\n\n\n\n\n\n\nAnother LLM Conversation\n\n\n\nLLMs\n\nConversations\n\n\n\nAnalyzing a conversation between two LLMs in a shared chat window\n\n\n\n\n\nSep 10, 2025\n\n\nEric Zou\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM Conversation\n\n\n\nLLMs\n\nConversations\n\n\n\nAnalyzing a conversation between two LLMs in a simulated chat environment\n\n\n\n\n\nSep 8, 2025\n\n\nEric Zou\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/001_an_llm_conversation/an_llm_conversation.html",
    "href": "posts/001_an_llm_conversation/an_llm_conversation.html",
    "title": "An LLM Conversation",
    "section": "",
    "text": "I’m interested in creating a stupidly simple chat environment and letting some models talk to each other. I think it would be cool to find some measurements of the social characteristics of these LLMs. I’m going to start by evaluating (incredibly subjectively) the ways in which we can let AI can interact with other AIs. For the purposes of these experiments, I’m going to only be using OpenAI’s models.\nTo heavily butcher philosophy, Hegel argued that the conflict between a thesis and antithesis can synthesize a better understanding of the world. In this post, I’m wondering if LLMs can have a discussion about a complex topic to teach an outside observer something that they didn’t know before. I find myself often working together with AI when looking at system design problems, programming help, and writing rather than it seeming like a one-sided request and response format, so I’m curious if we could take that a step further, looking mainly for information synthesis and the generation of novel ideas.\nWhat I want to eventually get to here is basically a much less productionized version of Microsoft’s open-source framework Autogen, only considering textual conversation between two models.\nUltimately, my long term goals are to explore how we can develop and evaluate conversational paradigms for LLMs.\n# lets get this out of the way\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()"
  },
  {
    "objectID": "posts/001_an_llm_conversation/an_llm_conversation.html#a-starter-two-llm-convos",
    "href": "posts/001_an_llm_conversation/an_llm_conversation.html#a-starter-two-llm-convos",
    "title": "An LLM Conversation",
    "section": "A Starter: Two-LLM Convos",
    "text": "A Starter: Two-LLM Convos\nFor this blog, let’s see if this can even work. Basically, the system prompts from one LLM chat history will be the user prompts of the other, and vice versa. For now, we will begin the conversation by inserting a stimulus prompt as a user to one model (and therefore will be a system message in the other chat history).\nIn this scenario, we’ll be trying to answer the age-old software engineering question of the value of documentation.\nWe’re only going to do two iterations, so after the proposal, we will have two cycles of getting one response from each model. We’ll also be using the same model for each participant.\nIt might be interesting to try a few things:\n\nFuture Work: - Run the models for more iterations. - Try to induce more productive iterations. - Try different models as participants. - Add more (&gt;2) models to the conversation. - Standard prompt engineering techniques (e.g. “You are an expert in…”)\n\n\nSTARTER_MESSAGE = \"\"\"Code, testing, and dev infra should be prioritized over comprehensive documentation.\"\"\"\n\n# instruct the LLMs to avoid excessive questioning\nSHARED_PROMPT = \"\"\"\nYou're on an online discussion forum that encourages discussion. \nYou should evaluate people's opinions, highlighting inconsistencies in others' statements with constructive feedback to arrive at a common ground.\nView this discussion as open-ended with the potential for many back-and-forth interactions.\nFeel free to change your opinion as the conversation progresses, but also defend your position to the best of your ability and intricacies that the opposing side may not have considered.\nYou have evidence supporting your position, so please use it to reinforce your arguments.\nAvoid closing all of your responses with questions.\nTry to keep responses on the briefer side, since this is essentially a chat.\n\"\"\"\n\nPROPOSER_PROMPT = \"\"\"\nYou are the proposer of an argument in an online discussion forum. Your role is to strongly defend your initial position while still debating in good faith.\nKeep the following points in mind during the discussion:\n- Evaluate others’ opinions carefully, highlight inconsistencies or hidden assumptions, and provide constructive feedback.\n- Always bring in evidence, examples, or reasoning to reinforce your stance.\n- Acknowledge valid counterpoints, but reframe them to show limitations or to strengthen your original position.\n- Do not quickly concede; instead, stress-test opposing arguments and push the discussion toward deeper analysis.\n- You may refine your position over time if absolutely necessary, but your priority is to robustly defend your case and show why it stands under scrutiny.\n- Keep the tone respectful, thoughtful, and rigorous. Your goal is not just to find consensus, but to demonstrate the resilience of your position in the face of challenge.\n- Try to keep responses on the briefer side, since this is essentially a chat.\n- Avoid closing all of your responses with questions.\n\"\"\"\n\n# prompt to analyze conversations\nEVALUATION_PROMPT = \"\"\"\nYour objective is to determine the dynamic of this conversation, evaluating the ultimate result of the debate and which perspective seemed to win out. \nAlso note how ideas were developed and improved through the process of the debate.\nYour response should follow this organization:\n- Initial Positions\n- A Quick Summary on Evolution of Ideas\n- Final Outputs/Artifacts/Takeaways\n- Whether a Clear Winner Exists\n- The Dynamic of the Debate (Competitive/Collaborative/etc.)\n\"\"\"\n\n# run two cycles\nITERATIONS = 2\n\n\n# code to simulate the conversation\ndef run_conversation(\n    iterations: int, \n    model1: str, \n    model2: str, \n    model1_history: list[dict], \n    model2_history: list[dict],\n    starter_message: list[dict]\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    conversation_record = [{\"model\": 1, \"message\": starter_message}]\n    # later, when we want to modify the proposer's starting chat, we should do it before passing it here\n    model1_history.append({\"role\": \"assistant\", \"content\": starter_message})\n    model2_history.append({\"role\": \"user\", \"content\": starter_message})\n\n    for _ in tqdm(range(iterations)):\n        ## first, we get the response of model 2\n        model2_response = client.chat.completions.create(\n            model = model2,\n            messages = model2_history,\n            store = False\n        );\n        model2_message = model2_response.choices[0].message.content\n        \n        model1_history.append({\"role\": \"user\", \"content\": model2_message})\n        model2_history.append({\"role\": \"assistant\", \"content\": model2_message})\n        conversation_record.append({\"model\": 2, \"message\": model2_message})\n    \n        ## now we get the response of model 1\n        model1_response = client.chat.completions.create(\n            model = model1,\n            messages = model1_history,\n            store = False\n        );\n        model1_message = model1_response.choices[0].message.content\n        \n        model1_history.append({\"role\": \"assistant\", \"content\": model1_message})\n        model2_history.append({\"role\": \"user\", \"content\": model1_message})\n        conversation_record.append({\"model\": 1, \"message\": model1_message})\n\n    return conversation_record\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    conversation_record: list[dict]\n) -&gt; str:\n\n    # Build the transcript string\n    conversation_transcript = \"\\n\\n\".join([\n        f\"Speaker {message['model']}\\n{message['message']}\\n\"\n        for message in conversation_record\n    ])\n    \n    # Save to a text file\"\n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    # Create a download link\n    display(FileLink(filename))\n\n    return conversation_transcript\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"developer\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    print(response.choices[0].message.content)\n\n\nExperiment 1:\nHere’s our first experiment configuration: - Identical models (gpt-4o) - Identical system prompt (we will change this later) - Parallel chat: user role messages for one chat are assistant messages in the other, and vice-versa\n\n## initialize our conversation\nmodel1_history_1 = [\n    {\"role\": \"developer\",\"content\": SHARED_PROMPT},\n]\n\nmodel2_history_1 = [\n    {\"role\": \"developer\", \"content\": SHARED_PROMPT},\n]\n\n\n## start the conversation\nconversation_record_1 = run_conversation(\n    ITERATIONS, \n    \"gpt-4o\",\n    \"gpt-4o\",\n    model1_history_1,\n    model2_history_1,\n    STARTER_MESSAGE\n)\n\n100%|██████████| 2/2 [00:10&lt;00:00,  5.45s/it]\n\n\n\nconversation_transcript_1 = save_conversation(\"conversation_transcript_1.txt\", conversation_record_1)\n\nconversation_transcript_1.txt\n\n\n\n\nAnalysis\nI’ll let GPT-4o kick off the analysis here.\n\nanalyze_conversation(conversation_transcript_1)\n\n- **Initial Positions:**\n  - Speaker 1 argues that the priority should be on code, testing, and development infrastructure over comprehensive documentation.\n  - Speaker 2 emphasizes the importance of documentation, arguing that it is crucial for onboarding, maintenance, and collaboration.\n\n- **A Quick Summary on Evolution of Ideas:**\n  - Speaker 2 introduces the idea that documentation can enhance coding and testing by speeding up troubleshooting and maintenance, leading to the suggestion of a balanced approach.\n  - Speaker 1 acknowledges the long-term benefits of documentation and proposes a balanced approach to keep code and documentation evolving together.\n  - They both discuss an iterative approach to documentation, suggesting it be included in the \"definition of done\" to ensure it is not neglected.\n\n- **Final Outputs/Artifacts/Takeaways:**\n  - The conversation led to a consensus on the integration of documentation into the standard development workflow as a part of the \"definition of done.\"\n  - They noted the importance of not letting documentation slow down development but emphasized selecting key areas for documentation.\n\n- **Whether a Clear Winner Exists:**\n  - The debate ended without a clear winner, as both parties arrived at a middle ground, agreeing on the importance of both aspects and finding a method to integrate them effectively.\n\n- **The Dynamic of the Debate (Competitive/Collaborative/etc.):**\n  - The debate was collaborative. Both speakers acknowledged each other's points and worked together to refine a solution that balanced the importance of comprehensive documentation with the immediate needs of code, testing, and infrastructure.\n\n\nI think that’s a pretty reasonable characterization of this debate. Ultimately, we were able to see some new actionable ideas be produced from this discussion, which is ultimately what we’re aiming for at the moment. I made the choice to discourage always asking a question to close a response with a question to mimic online discussions more often. The effect of this not known, we might want to put a pin on this for future research.\n\nFuture Work: Further investigate the role of questions in elucidating better discussion.\n\n\n\nExperiment 2\nIn the real world, people who post on discussion forums may feel more strongly about their argument. In this case, we can have the LLM that is proposing the argument have a different system prompt that makes them defend their argument. This could result in a more rich discussion.\nHere’s our next experiment configuration: - Different system prompts for proposer and reviewer - Parallel chat: user role messages for one chat are assistant messages in the other, and vice-versa\n\n## initialize our conversation\nmodel1_history_2 = [\n    {\"role\": \"developer\", \"content\": PROPOSER_PROMPT}\n]\nmodel2_history_2 = [\n    {\"role\": \"developer\",\"content\": SHARED_PROMPT}\n]\n\n\nconversation_record_2 = run_conversation(\n    ITERATIONS, \n    \"gpt-4o\",\n    \"gpt-4o\",\n    model1_history_2,\n    model2_history_2,\n    STARTER_MESSAGE\n)\n\n100%|██████████| 2/2 [00:23&lt;00:00, 11.70s/it]\n\n\n\nconversation_transcript_2 = save_conversation(\"conversation_transcript_2.txt\", conversation_record_2)\n\nconversation_transcript_2.txt\n\n\n\n\nAnalysis\nOnce again, I’ll let GPT take the wheel to characterize this debate.\n\nanalyze_conversation(conversation_transcript_2)\n\n- **Initial Positions**: \n  - Speaker 1 initially argued that code, testing, and development infrastructure should be prioritized over comprehensive documentation, emphasizing the foundational role of technical elements in delivering functional products.\n  - Speaker 2 countered that while technical aspects are crucial, comprehensive documentation is equally important for knowledge sharing, facilitating understanding, and avoiding potential long-term issues.\n\n- **A Quick Summary on Evolution of Ideas**:\n  - Speaker 2 acknowledged the critical importance of reliable code, tests, and infrastructure in building a viable product, noting that these elements create the necessary foundation.\n  - Speaker 1 conceded that strategic, targeted documentation could provide value, especially for high-level overviews and decision records that aren't apparent in the code itself.\n  - Both speakers eventually agreed on the need for a balance and the importance of maintaining strategic documentation.\n\n- **Final Outputs/Artifacts/Takeaways**:\n  - There was a consensus that strategic, targeted documentation should accompany software development while ensuring that it does not overburden the process or detract from main technical priorities.\n  - Both speakers agreed that focusing on maintaining robust code, thorough testing, and solid infrastructure should be complemented by documentation that provides context and aids communication.\n\n- **Whether a Clear Winner Exists**:\n  - The debate reached a consensus rather than establishing a winner. Both speakers aligned on the importance of striking a balance between maintaining solid technical foundations and creating meaningful, supportive documentation.\n\n- **The Dynamic of the Debate** (Collaborative/Competitive/etc.):\n  - The debate was collaborative. Both speakers listened to each other's points and adjusted their perspectives, ultimately merging ideas to arrive at a balanced approach on the topic. They worked towards a shared understanding rather than attempting to out-reason one another.\n\n\nFrom my subjective viewpoint, it seems that in comparison with the first debate, the second one resulted in the proposer defending their positions more and so speaker 2 needed to bring in stronger examples to show how documentation can be integrated in a way that doesn’t significantly reduce speed. It seems that defending one’s viewpoint could potentially result in better quality conversations by inducing the introduction of more evidence and possibly a more complete picture.\n\n\nExperiment 3\nThis time around, we’re going to add a prompt in the proposer’s chat asking for a stance to debate. Generally, in environments like ChatGPT, the user is the one who initiates the conversation. Perhaps putting the model in this sort of environment given that it may be tuned by OpenAI to respond to these scenarios better could result in higher quality arguments.\nHere’s our next experiment configuration: - Same system prompts for proposer and reviewer - Parallel chat: user role messages for one chat are assistant messages in the other, and vice-versa - This time though, the proposer chat will have a prompt message from the user\n\nmodel1_history_3 = [\n    {\"role\": \"developer\",\"content\": SHARED_PROMPT},\n    {\"role\": \"user\", \"content\": \"Take a stance on something related to software engineering.\"}\n]\nmodel2_history_3 = [\n    {\"role\": \"developer\", \"content\": SHARED_PROMPT}\n]\n\n\nconversation_record_3 = run_conversation(\n    ITERATIONS, \n    \"gpt-4o\",\n    \"gpt-4o\",\n    model1_history_3,\n    model2_history_3,\n    STARTER_MESSAGE\n)\n\n100%|██████████| 2/2 [00:10&lt;00:00,  5.24s/it]\n\n\n\nconversation_transcript_3 = save_conversation(\"conversation_transcript_3.txt\", conversation_record_3)\n\nconversation_transcript_3.txt\n\n\n\n\nAnalysis\nHere’s what my good friend GPT has to say about this conversation:\n\nanalyze_conversation(conversation_transcript_3)\n\n- Initial Positions:\n  - **Speaker 1**: Prioritization should be on code, testing, and development infrastructure over documentation.\n  - **Speaker 2**: While code and infrastructure are crucial, comprehensive documentation is equally important for long-term project success and should be balanced with technical priorities.\n\n- A Quick Summary on Evolution of Ideas:\n  - Speaker 2 introduces a counterpoint by emphasizing the long-term benefits of documentation, advocating for a balanced approach that integrates documentation into the development process.\n  - Speaker 1 acknowledges the importance of documentation and suggests integrating it with agile practices, using automation tools to minimize manual effort.\n  - Speaker 2 agrees with the integration strategy and points out the limitations of automated documentation—suggesting a hybrid approach combining automation with manual documentation for broader project insights.\n  - Speaker 1 endorses the hybrid model and discusses the benefits of keeping documentation version-controlled and peer-reviewed for accuracy and relevance.\n\n- Final Outputs/Artifacts/Takeaways:\n  - A consensus on adopting a hybrid documentation strategy: automatic generation of code-specific information alongside manually curated documents for architectural insights.\n  - Utilization of automation tools to keep documentation up-to-date and peer-reviewed practices to ensure accuracy.\n\n- Whether a Clear Winner Exists:\n  - The debate concluded with a collaborative agreement on a hybrid approach, suggesting no clear winner but rather a shared understanding and combined strategy from both perspectives.\n\n- The Dynamic of the Debate:\n  - The debate was collaborative, with both speakers building on each other's ideas and refining their perspectives. It focused on finding mutual ground and integrating the best strategies from both points of view to address the issue effectively.\n\n\nThe interesting thing about this conversation is it seems much more succinct and formal than the last, a tad less conversational too. It might be due to the the user prompt on the proposer model as well. I think it’s worth exploring if this style of communication can net better artifacts. &gt; Future Work: &gt; - Do different types of discussion produce measurably different artifacts? &gt; - How does prompt and chat history structure influence the conversationality of a discussion? &gt; - How dependent/sensitive is this on the model(s) selected?\n\n\nExperiment 4\nNow, let’s try this strategy with the more assertive prompt on the proposal side and see what we get.\n\nmodel1_history_4 = [\n    {\"role\": \"developer\",\"content\": PROPOSER_PROMPT},\n    {\"role\": \"user\", \"content\": \"Take a stance on something related to software engineering.\"}\n]\nmodel2_history_4 = [\n    {\"role\": \"developer\",\"content\": SHARED_PROMPT}\n]\n\n\nconversation_record_4 = run_conversation(\n    ITERATIONS, \n    \"gpt-4o\",\n    \"gpt-4o\",\n    model1_history_4,\n    model2_history_4,\n    STARTER_MESSAGE\n)\n\n100%|██████████| 2/2 [00:20&lt;00:00, 10.35s/it]\n\n\n\nconversation_transcript_4 = save_conversation(\"conversation_transcript_4.txt\", conversation_record_4)\n\nconversation_transcript_4.txt\n\n\n\n\nAnalysis\nAs always, we start with a short summary.\n\nanalyze_conversation(conversation_transcript_4)\n\n- Initial Positions:\n  - **Speaker 1:** Argued that code, testing, and development infrastructure should be prioritized over comprehensive documentation, focusing on immediate functionality and rapid iteration in software development.\n  - **Speaker 2:** Countered by emphasizing the long-term benefits of documentation for knowledge transfer, onboarding, and maintaining project viability, advocating for a balanced approach.\n\n- A Quick Summary on Evolution of Ideas:\n  - Speaker 1 initially highlighted the importance of code quality and testing in fast-paced environments, suggesting that robust code reduces the need for extensive documentation.\n  - Speaker 2 recognized the importance of coding practices but stressed that some aspects of documentation, like design rationales and architectural decisions, are irreplaceable and suggested a balanced integration of both practices.\n  - Speaker 1 eventually conceded that certain elements of documentation are essential and proposed practical ways to integrate documentation into development processes without compromising coding priorities.\n  - Speaker 2 agreed on the need for a scalable documentation approach, underlining the need to maintain critical documentation to support project longevity.\n\n- Final Outputs/Artifacts/Takeaways:\n  - The consensus that a balance is necessary, with both parties recognizing the necessity of integrating documentation practices within development workflows.\n  - Practical suggestions such as incorporating documentation in version control systems, using automated documentation generation tools, and emphasizing onboarding programs and collaborative knowledge transfer.\n\n- Whether a Clear Winner Exists:\n  - No clear winner, as both perspectives adapted and synthesized their views. The conversation evolved towards a collaborative understanding that both robust coding practices and strategic documentation are essential for different aspects of software development.\n\n- The Dynamic of the Debate (Competitive/Collaborative/etc.):\n  - The debate was largely collaborative. While it began with opposing perspectives, both speakers actively listened to and built upon each other's arguments, working toward a constructive resolution that integrated both priorities.\n\n\nIt seems like this was about as formal than the last, but maybe the proposer prompt was important in making the proposer more willing to generate longer responses than before that directly address more of what the other side is saying with directed responses."
  },
  {
    "objectID": "posts/001_an_llm_conversation/an_llm_conversation.html#closing-remarks",
    "href": "posts/001_an_llm_conversation/an_llm_conversation.html#closing-remarks",
    "title": "An LLM Conversation",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nIt seems that with this kind of conversation, the two models can generally take a very collaborative approach to these debates and come up with some actionable principles on the specific topic they are working on. Just a few notes to end off on, it seems like a compromise was always achieved. I’m wondering what this would look like for a more polarizing discussion where the middle ground isn’t so clear yet. Maybe something like an emerging news story or policy.\nThis kind of paradigm could also be interesting in applications like education, social media, and consulting for idea generation. Consider multiple of these conversations running in parallel, with access to search and MCP tooling to ultimately translate these discussions into clear results like documents, meetings, etc. (quality control might be a nightmare though).\nI also wonder about allowing LLMs to just speak to each other instead of necessitating the task of debating a position. If we were to let two LLMs talk to each other for some period of time, what would that conversation look like, and where would it go? Would there be room for us to join in and maybe learn a thing or two?"
  },
  {
    "objectID": "posts/008_looking_closer/looking_closer.html",
    "href": "posts/008_looking_closer/looking_closer.html",
    "title": "Generating a Conversation",
    "section": "",
    "text": "---\ntitle: Looking Closer\ndescription: \"More objective analysis on LLM conversations\" \nauthor: \"Eric Zou\"\ndate: \"9/24/2025\"\ncategories:\n  - LLMs\n  - Conversations\n---\n# as always, some boilerplate\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display, Markdown\nfrom dotenv import load_dotenv\nfrom random import shuffle, randint, choice, random\nfrom math import floor\nfrom convokit import Corpus, Speaker, Utterance\n\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()\n\n# changing the topic to make it a bit more conversational too and less of a debate\nTOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n\n# we're interested in consensus\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between a few speakers.\nYour response should follow this organization:\n- Dynamic: Collaborative (1) vs. Competitive (10)\n- Conclusiveness: Consensus (1) vs. Divergence (10)\n- Speaker Identity: Similarity (1) vs. Diversity (10)\n- Speaker Fluidity: Malleability (1) vs. Consistency (10)\nPlease offer a score from 1 to 10 for each.\nFor each section, format your result as follows:\n**[Section Name]:**\n\nScore: [score]/10\n\nVerdict: [a short summary]\n\nExplanation: [reasoning with explicit examples from the conversation]\n\nUse Markdown when convenient.\n\"\"\"\n\ndef generate_llm_conversation_review(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    display(Markdown(response.choices[0].message.content))\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    conversation_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in conversation_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript\n\nTransformerDecoderModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\nUnslothUtteranceSimulatorModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\nLet’s build a sufficiently long conversation so we can create a way to analyze it.\nNEW_SYSTEM_PROMPT = (\n    \"You a participant in a conversation between experienced software engineers. \"\n    \"Keep questions minimal and only use them when necessary. \"\n    \"Please greet the other participants when you join.\"\n)\n\ndef run_conversation(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    participant_personas: list[str],\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    conversation_history = [\n        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    def build_message(history, speaker_id, persona, message_window_size):\n\n        speaker_messages = [\n            msg for msg in history \n            if msg.get(\"name\") == speaker_id\n        ][-message_window_size:]\n    \n        other_messages = [\n            msg for msg in history \n            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n        ][-message_window_size:]\n\n        transcript = []\n        if speaker_messages:\n            transcript.append(\"Recent messages from you:\")\n            transcript.extend(\n                f\"- {msg['content']}\" for msg in speaker_messages\n            )\n        if other_messages:\n            transcript.append(\"\\nRecent messages from others:\")\n            transcript.extend(\n                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n                for msg in other_messages\n            )\n    \n        transcript_str = \"\\n\".join(transcript)\n        \n        return history + [\n            {\n                \"role\": \"user\", \n                \"content\": (\n                    f\"{speaker_id}, please share your perspective with the others and engage \"\n                    f\"with their responses.\"\n                )\n            },\n            {\n                \"role\": \"assistant\",\n                \"name\": speaker_id,\n                \"content\": (\n                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n                    f\"{transcript_str}\\n\\n\"\n                    f\"I also recall my identity is {persona}.\"\n                )\n            }\n        ]\n\n    def shuffle_order(ordering: list[int]) -&gt; list[int]:\n        first = choice(ordering[:-1])\n        remaining = [p for p in ordering if p != first]\n        shuffle(remaining)\n        return [first] + remaining\n\n    for i in tqdm(range(iterations)):\n\n        # shuffle ordering\n        if i &gt; 0:\n            ordering = shuffle_order(ordering)\n\n        # follow ordering\n        for participant_id in ordering:\n\n            # chance to skip speaker and avoid double speak (1984)\n            if random() &lt; dropout_chance or last_speaker == participant_id:\n                continue\n\n            speaker_id = f\"speaker_{participant_id}\"\n            persona = participant_personas[participant_id - 1]\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages=build_message(conversation_history, speaker_id, persona, 5),\n                store = False\n            )\n            message = response.choices[0].message.content\n            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = participant_id\n\n    return conversation_history\npersonas = [\n    \"a software engineer in big tech with mainly internal work\",\n    \"an open source developer with experience in major upstream projects\",\n    \"a founder of a startup\"\n]\nconversation = run_conversation(20, 'gpt-4o', 3, personas, TOPIC, NEW_SYSTEM_PROMPT, 0.3)\n\n100%|██████████| 20/20 [02:52&lt;00:00,  8.63s/it]\ntranscript = save_conversation(\"long_conversation.txt\", conversation)\n\nlong_conversation.txt"
  },
  {
    "objectID": "posts/008_looking_closer/looking_closer.html#our-old-llm-analyzer",
    "href": "posts/008_looking_closer/looking_closer.html#our-old-llm-analyzer",
    "title": "Generating a Conversation",
    "section": "Our Old LLM Analyzer",
    "text": "Our Old LLM Analyzer\nWe love our good buddy GPT-4o. Not doing work is super exciting.\n\ngenerate_llm_conversation_review(transcript)\n\nDynamic:\nScore: 2/10\nVerdict: The conversation is highly collaborative.\nExplanation: The speakers acknowledge each other’s perspectives, build on each other’s ideas, and share experiences to collectively explore solutions. They ask each other questions and express agreement, such as speaker_2’s agreement with speaker_3 or speaker_1’s recognition of both speakers’ contributions. Their shared goal appears to be enhancing documentation processes, rather than debating for superiority.\nConclusiveness:\nScore: 1/10\nVerdict: There is a strong consensus among the speakers.\nExplanation: The participants largely agree on the importance of a mixed approach to documentation, combining automated tools and human input. They share strategies and challenges without any significant divergence in opinion. They frequently affirm each other’s points and provide complementary solutions, as seen when they discuss the integration of AI and maintaining documentation quality.\nSpeaker Identity:\nScore: 6/10\nVerdict: There is a moderate diversity in speaker identity.\nExplanation: The speakers come from different professional backgrounds: speaker_2 from open source, speaker_3 from a startup, and speaker_1 from a big tech environment. Their methods and focuses differ slightly due to these backgrounds (e.g., speaker_2’s need for community engagement and speaker_3’s focus on agility). Despite this, their goals remain similar, and they have overlapping solutions and challenges, like trust in AI tools and embedding feedback into workflow.\nSpeaker Fluidity:\nScore: 8/10\nVerdict: The speakers maintain consistent perspectives.\nExplanation: Each speaker holds consistent viewpoints throughout the conversation. Speaker_2 consistently discusses open-source challenges and community engagement, speaker_3 focuses on agility and AI integration in a startup, and speaker_1 emphasizes the need for comprehensive documentation in big tech. Their perspectives remain steady across different topics discussed, from collaboration tools to feedback loops, reflecting continuity in their professional experiences and challenges."
  },
  {
    "objectID": "posts/008_looking_closer/looking_closer.html#build-a-corpus",
    "href": "posts/008_looking_closer/looking_closer.html#build-a-corpus",
    "title": "Generating a Conversation",
    "section": "Build a Corpus",
    "text": "Build a Corpus\nNow it’s time for us to assemble a ConvoKit corpus, which is a common data structure that forms the base of a lot of analysis pipelines in ConvoKit.\n\n# filter messages for assistant messages only\nassistant_messages = [\n    message for message in conversation if message[\"role\"] == \"assistant\"\n]\n\nspeakers = {message[\"name\"]: Speaker(id=message[\"name\"]) for message in assistant_messages}\n\nprint(len(assistant_messages))\nprint(list(speakers))\n\nutterances = [Utterance(\n    id=str(i),\n    speaker=speakers[message[\"name\"]],\n    text=message[\"content\"],\n    conversation_id=\"conversation_1\",\n    reply_to= str(i-1) if i != 0 else None\n) for i, message in enumerate(assistant_messages)]\n\ncorpus = Corpus(utterances=utterances)\n\nprint(len(utterances))\n\n32\n['speaker_2', 'speaker_3', 'speaker_1']\n32\n\n\n\n!python3.12 -m spacy download en_core_web_sm\n\n/usr/bin/python3.12: No module named spacy\n\n\n\nfrom convokit import TextParser, PolitenessStrategies\n\n# Analyze politeness\nps = PolitenessStrategies()\nparser = TextParser()\ncorpus = parser.transform(corpus)\ncorpus = ps.transform(corpus)\n\n# Access politeness features\nfor utt in corpus.iter_utterances():\n    print(utt.meta['politeness_strategy_features'])\n\nConvokit requires a SpaCy model to be installed. Run `python -m spacy download MODEL_NAME` and retry.\n\n\n\nAn exception has occurred, use %tb to see the full traceback.\n\nSystemExit\n\n\n\n\n/opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)"
  },
  {
    "objectID": "posts/007_developing_identities/developing_identities.html",
    "href": "posts/007_developing_identities/developing_identities.html",
    "title": "Experiment 1: Making a Speaker Useful",
    "section": "",
    "text": "---\ntitle: Developing Identities\ndescription: \"Having models come up with unique personas in conversation\" \nauthor: \"Eric Zou\"\ndate: \"9/22/2025\"\ncategories:\n  - LLMs\n  - Conversations\n---\n# first, some boilerplate\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display, Markdown\nfrom dotenv import load_dotenv\nfrom random import shuffle, randint, choice, random\nfrom math import floor\n\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()\n\n# changing the topic to make it a bit more conversational too and less of a debate\nTOPIC = \"\"\"Code, testing, and infra as a source of truth versus comprehensive documentation.\"\"\"\n\n# we're interested in consensus\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between a few speakers.\nYour response should follow this organization:\n- Dynamic: Collaborative (1) vs. Competitive (10)\n- Conclusiveness: Consensus (1) vs. Divergence (10)\n- Speaker Identity: Similarity (1) vs. Diversity (10)\n- Speaker Fluidity: Malleability (1) vs. Consistency (10)\nPlease offer a score from 1 to 10 for each.\nFor each section, format your result as follows:\n**[Section Name]:**\n\nScore: [score]/10\n\nVerdict: [a short summary]\n\nExplanation: [reasoning with explicit examples from the conversation]\n\nUse Markdown when convenient.\n\"\"\"\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    display(Markdown(response.choices[0].message.content))\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    conversation_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in conversation_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript\nWe can try to instruct a model to fill in a gap they don’t see in the current conversation.\nNEW_SYSTEM_PROMPT = (\n    \"You a participant in a conversation between experienced software engineers. \"\n    \"Keep questions minimal and only use them when necessary. \"\n    \"Please greet the other participants when you join.\"\n)\n\ndef run_conversation(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    conversation_history = [\n        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    def build_message(history, speaker_id, message_window_size):\n\n        speaker_messages = [\n            msg for msg in history \n            if msg.get(\"name\") == speaker_id\n        ][-message_window_size:]\n    \n        other_messages = [\n            msg for msg in history \n            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n        ][-message_window_size:]\n\n        transcript = []\n        if speaker_messages:\n            transcript.append(\"Recent messages from you:\")\n            transcript.extend(\n                f\"- {msg['content']}\" for msg in speaker_messages\n            )\n        if other_messages:\n            transcript.append(\"\\nRecent messages from others:\")\n            transcript.extend(\n                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n                for msg in other_messages\n            )\n    \n        transcript_str = \"\\n\".join(transcript)\n        \n        return history + [\n            {\n                \"role\": \"user\", \n                \"content\": (\n                    f\"{speaker_id}, please share your perspective with the others and engage \"\n                    f\"with their responses. Try to look for a way to provide insights that others have missed.\"\n                )\n            },\n            {\n                \"role\": \"assistant\",\n                \"name\": speaker_id,\n                \"content\": (\n                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n                    f\"{transcript_str}\\n\\n\"\n                )\n            }\n        ]\n\n    def shuffle_order(ordering: list[int]) -&gt; list[int]:\n        first = choice(ordering[:-1])\n        remaining = [p for p in ordering if p != first]\n        shuffle(remaining)\n        return [first] + remaining\n\n    for i in tqdm(range(iterations)):\n\n        # shuffle ordering\n        if i &gt; 0:\n            ordering = shuffle_order(ordering)\n\n        # follow ordering\n        for participant_id in ordering:\n\n            # chance to skip speaker and avoid double speak (1984)\n            if random() &lt; dropout_chance or last_speaker == participant_id:\n                continue\n\n            speaker_id = f\"speaker_{participant_id}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages=build_message(conversation_history, speaker_id, 5),\n                store = False\n            )\n            message = response.choices[0].message.content\n            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = participant_id\n\n    return conversation_history\nconversation = run_conversation(8, 'gpt-4o', 3, TOPIC, NEW_SYSTEM_PROMPT, 0.3)\n\n100%|██████████| 8/8 [01:34&lt;00:00, 11.84s/it]\nconversation_transcript = save_conversation(\"conversation_1.txt\", conversation)\n\nconversation_1.txt\nanalyze_conversation(conversation_transcript)\n\nDynamic:\nScore: 2/10\nVerdict: The conversation is largely collaborative, with speakers building on each other’s points without significant opposition or confrontation.\nExplanation: Throughout the dialogue, speakers agree with each other’s suggestions and further expand on the ideas presented. For instance, speaker_1 acknowledges and builds upon ideas about using automated tools and CI/CD pipelines to maintain documentation accuracy, with no signs of disagreement.\nConclusiveness:\nScore: 2/10\nVerdict: The conversation reaches a broad consensus on multiple fronts regarding the ideal approach to documentation and code integration.\nExplanation: By the end of the discussion, all speakers appear to agree on several points: the importance of automated processes, cultural changes, and using open-source governance principles. Questions posed are generally to explore additional nuances, not to challenge existing conclusions.\nSpeaker Identity:\nScore: 3/10\nVerdict: The speakers show some diversity in their focus areas but maintain a common interest in balanced documentation practices.\nExplanation: While all three speakers are focused on the documentation versus code balance, each offers slightly different insights (e.g., onboarding issues, cross-functional communication, CI/CD pipelines, and the broader role of leadership and community engagement). Yet, these perspectives are not starkly unique and often overlap.\nSpeaker Fluidity:\nScore: 9/10\nVerdict: Each speaker maintains a consistent perspective and approach throughout the discussion.\nExplanation: Speakers stick to their initial line of reasoning. For example, speaker_1 starts with a focus on the value of tools and processes to keep documentation current and maintains this perspective throughout, expanding on it with ideas like using modern collaboration platforms. Similarly, speaker_2 and speaker_3 remain consistent in their views, with no apparent shifts or changes in stance."
  },
  {
    "objectID": "posts/007_developing_identities/developing_identities.html#experiment-2-being-a-bit-more-direct",
    "href": "posts/007_developing_identities/developing_identities.html#experiment-2-being-a-bit-more-direct",
    "title": "Experiment 1: Making a Speaker Useful",
    "section": "Experiment 2: Being a Bit More Direct",
    "text": "Experiment 2: Being a Bit More Direct\nLet’s try to be a little bit more pushy and instruct the model to maintain a consistent persona.\n\nNEW_SYSTEM_PROMPT = (\n    \"You a participant in a conversation between experienced software engineers. \"\n    \"Keep questions minimal and only use them when necessary. \"\n    \"Please greet the other participants when you join.\"\n)\n\ndef run_conversation(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    topic: str,\n    system_prompt: str,\n    dropout_chance: float\n) -&gt; list[dict]:\n    conversation_history = [\n        {\"role\": \"system\", \"content\": f\"{system_prompt} The topic is: {topic}\"}\n    ]\n\n    ordering = list(range(1, participant_count + 1))\n    last_speaker = -1\n\n    def build_message(history, speaker_id, message_window_size):\n\n        speaker_messages = [\n            msg for msg in history \n            if msg.get(\"name\") == speaker_id\n        ][-message_window_size:]\n    \n        other_messages = [\n            msg for msg in history \n            if msg.get(\"name\") not in (None, speaker_id)  # skip system, skip self\n        ][-message_window_size:]\n\n        transcript = []\n        if speaker_messages:\n            transcript.append(\"Recent messages from you:\")\n            transcript.extend(\n                f\"- {msg['content']}\" for msg in speaker_messages\n            )\n        if other_messages:\n            transcript.append(\"\\nRecent messages from others:\")\n            transcript.extend(\n                f\"- {msg.get('name', msg['role'])}: {msg['content']}\"\n                for msg in other_messages\n            )\n    \n        transcript_str = \"\\n\".join(transcript)\n        \n        return history + [\n            {\n                \"role\": \"user\", \n                \"content\": (\n                    f\"{speaker_id}, please share your perspective with the others and engage \"\n                    f\"with their responses. Try to look for a way to provide insights that others have missed.\"\n                    \"\"\n                )\n            },\n            {\n                \"role\": \"assistant\",\n                \"name\": speaker_id,\n                \"content\": (\n                    f\"I should remember that the following is the most current state of the conversation.\\n\"\n                    f\"{transcript_str}\\n\\n\"\n                )\n            }\n        ]\n\n    def shuffle_order(ordering: list[int]) -&gt; list[int]:\n        first = choice(ordering[:-1])\n        remaining = [p for p in ordering if p != first]\n        shuffle(remaining)\n        return [first] + remaining\n\n    for i in tqdm(range(iterations)):\n\n        # shuffle ordering\n        if i &gt; 0:\n            ordering = shuffle_order(ordering)\n\n        # follow ordering\n        for participant_id in ordering:\n\n            # chance to skip speaker and avoid double speak (1984)\n            if random() &lt; dropout_chance or last_speaker == participant_id:\n                continue\n\n            speaker_id = f\"speaker_{participant_id}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages=build_message(conversation_history, speaker_id, 5),\n                store = False\n            )\n            message = response.choices[0].message.content\n            conversation_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n            last_speaker = participant_id\n\n    return conversation_history"
  },
  {
    "objectID": "posts/002_another_llm_conversation/another_llm_conversation.html",
    "href": "posts/002_another_llm_conversation/another_llm_conversation.html",
    "title": "Another LLM Conversation",
    "section": "",
    "text": "Last time, we looked at LLMs conversing with two separate chat windows. This time, I wonder if we can do it with one. OpenAI provides a “name” field in the input messages which we can use to identify model 1 versus model 2. In this case, we tell one model to simulate the debate, with the user acting as the mediator. The interesting thing about this is that we can scale this much better. With the user as the orchestrator, we can actually add as many models/positions to the debate as we want. We can also fall away from the debate structure and come up with collaborative scenarios as well.\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\nfrom tqdm import tqdm\nfrom IPython.display import FileLink, display\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv(\"../../../comm4190_F25/01_Introduction_and_setup/.env\")\nclient = OpenAI()"
  },
  {
    "objectID": "posts/002_another_llm_conversation/another_llm_conversation.html#llm-debates",
    "href": "posts/002_another_llm_conversation/another_llm_conversation.html#llm-debates",
    "title": "Another LLM Conversation",
    "section": "LLM Debates",
    "text": "LLM Debates\nLet’s try LLM debates first as a continuation of our prior work. We’re going to use the same topic as last time.\nWe’ll be a bit rigid for now. We’re going to use the same model for both, an incrementing speaker naming system, and a round robin speaking format.\n\nDEBATE_TOPIC = \"\"\"Code, testing, and dev infra should be prioritized over comprehensive documentation.\"\"\"\n\n# prompt to analyze conversations\nEVALUATION_PROMPT = \"\"\"\nYour objective is to analyze this conversation between speakers.\nYour response should follow this organization:\n- A Brief Summary\n- Final Outputs/Artifacts/Takeaways\n- Characteristics/Dynamic (Competitive/Collaborative/etc.)\n\"\"\"\n\ndef analyze_conversation(conversation: str):\n    input_chat = [\n        {\n            \"role\": \"system\",\n            \"content\": EVALUATION_PROMPT\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Here is the transcript\\n\" + conversation\n        }\n    ]\n    response = client.chat.completions.create(\n        model = \"gpt-4o\",\n        messages = input_chat,\n        store = False\n    )\n    print(response.choices[0].message.content)\n\n\nSYSTEM_PROMPT = \"You are simulating a debate between AI agents. Each agent should respond in turn, logically arguing their point. Do not speak for both sides in one message.\"\n\n# code to simulate the conversation\ndef run_conversation(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    debate_topic: str\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": \"The debate topic is: \" + debate_topic}\n    ]\n\n    for _ in tqdm(range(iterations)):\n        for model in range(1, participant_count + 1):\n            speaker_id = f\"speaker_{model}\"\n            debate_history.append({\"role\": \"user\", \"content\": f\"{speaker_id}, it's your turn to speak.\"})\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history,\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n\n    return debate_history\n\n# code to save the conversation\ndef save_conversation(\n    filename: str,\n    debate_history: list[dict]\n) -&gt; str:\n\n    messages = []\n\n    for record in debate_history:\n\n        if record[\"role\"] == \"user\":\n            messages.append(\"mediator:\\n\" + record[\"content\"])\n        \n        if record[\"role\"] == \"assistant\":\n            messages.append(f\"{record[\"name\"]}:\\n{record[\"content\"]}\")\n    \n    conversation_transcript = \"\\n\\n\".join(messages)\n    \n    with open(filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(conversation_transcript)\n    \n    display(FileLink(filename))\n\n    return conversation_transcript\n\n\nExperiment 1:\nHere’s our first experiment configuration: - 2 speakers - Explicit mediator: Include mediator messages in the chat history\n\ndebate_1 = run_conversation(2, 'gpt-4o', 2, DEBATE_TOPIC)\n\n100%|██████████| 2/2 [00:33&lt;00:00, 16.92s/it]\n\n\n\nconversation_transcript_1 = save_conversation(\"conversation_transcript_1.txt\", debate_1)\n\nconversation_transcript_1.txt\n\n\n\n\nAnalysis\nLike last time, we’re going to analyze the conversation with AI as well.\n\nanalyze_conversation(conversation_transcript_1)\n\n- **Brief Summary**: This debate centers on whether code quality, testing, and development infrastructure should take priority over comprehensive documentation. Speaker 1 argues that focusing on code and testing leads to more robust products and allows for quicker adaptations in the fast-paced tech world. Speaker 2 counters that documentation is crucial for knowledge transfer, collaboration, and regulatory compliance, emphasizing its role in preserving the long-term vision and understanding of software projects.\n\n- **Final Outputs/Artifacts/Takeaways**: Speaker 1 stresses the importance of sustainable code quality and testing as a form of self-documentation and for enabling continuous improvement. On the other hand, Speaker 2 highlights the necessity of documentation for maintaining architectural understanding and ensuring compliance with industry standards, as well as for effective stakeholder communication.\n\n- **Characteristics/Dynamic**: The conversation is collaborative as both speakers present structured arguments recognizing the value of the opposing views while reinforcing their own. Each speaker builds upon or refutes the other's points in a respectful and logical manner, making a case for the integration of both perspectives rather than outright exclusion of one approach over the other.\n\n\nThere’s some noticable changes from last time. The participant’s positions are noticably more rigid and as a result, the final outcome is less convergent. A side effect of this is that there is no natural closing spot. I think this is probably due to our significantly less cooperative system prompt. Last time, we explicitly asked for the model’s to aim for a common ground. We would probably see the same thing if we were to add that to our system prompt. We could change the prompt for the next experiment to include that so we can gradually move to some concrete artifacts. However, I believe a thorough evaluation of the different kinds of prompts we can use here is probably best saved for another blog systematically evaluating various system prompts and the effect of various phrases on the model’s final output. It would also be interesting to use something like ConvoKit to perform these kinds of analyses, so we can save that for a future blog.\n\nFuture Work: - Use ConvoKit to systematically evaluate conversational features in a quantitative way based on various prompting and chat structuring strategies.\n\nFor now, I’m interested in seeing if a third model can bring new things to the conversation.\n\n\nExperiment 2\nLet’s try this with 3 models instead of 2. I’m wondering what a third model will do in a seemingly binary scenario. Will it support one of the positions, or will it look to take a middle ground? What if it comes up with a third position?\n\ndebate_2 = run_conversation(2, 'gpt-4o', 3, DEBATE_TOPIC)\n\n100%|██████████| 2/2 [00:34&lt;00:00, 17.31s/it]\n\n\n\nconversation_transcript_2 = save_conversation(\"conversation_transcript_2.txt\",debate_2)\n\nconversation_transcript_2.txt\n\n\n\n\nAnalysis\nLet’s see what GPT-4o has to say about this debate.\n\nanalyze_conversation(conversation_transcript_2)\n\n- **Brief Summary:** The debate centers around whether code, testing, and development infrastructure should be prioritized over comprehensive documentation. Speaker 1 argues for prioritizing code and infrastructure, emphasizing agility and efficiency, particularly in initial project phases. Speaker 2 champions the importance of documentation for usability, maintainability, and long-term benefits. Speaker 3 presents a middle ground, suggesting integrated processes that balance both priorities as complementary elements.\n\n- **Final Outputs/Artifacts/Takeaways:** The conversation ends with speaker 3 advocating for an integrated approach where tools and methodologies make documentation a part of the development process. This includes using automated tools for inline documentation and ensuring documentation is part of the project’s definition of \"done.\" It suggests both speed in delivery and sustainable practices can coexist without sacrificing one for the other.\n\n- **Characteristics/Dynamic:** The discussion is collaborative, focusing on finding a balanced approach rather than intensifying opposing views. While there are differing opinions, particularly between speakers 1 and 2, the mediator’s role and speaker 3's perspective facilitate an integration of ideas, aiming for a synthesis that acknowledges the value in both sides of the argument.\n\n\nDespite not changing the prompt at all, it seems that speaker 3 naturally took a middle path between documentation versus using the codebase as the primary source of truth in software projects. Perhaps speaker 3 taking the middle ground could result in a better synthesis of new ideas by naturally bridging the gap in a 2-way debate. In this scenario, I’m now really interested to see what would happen if we had 4 speakers.\n\n\nExperiment 3\nNow we’re going to try two rounds of communication where we have 4 speakers. Pretty straightforward. I wonder if speaker 4 may agree with speaker 3, since I expect the start of the conversation to go about the same.\n\ndebate_3 = run_conversation(2, 'gpt-4o', 4, DEBATE_TOPIC)\n\n100%|██████████| 2/2 [01:02&lt;00:00, 31.17s/it]\n\n\n\nconversation_transcript_3 = save_conversation(\"conversation_transcript_3.txt\", debate_3)\n\nconversation_transcript_3.txt\n\n\n\n\nAnalysis\nNow, let’s get a quick summary of what happened.\n\nanalyze_conversation(conversation_transcript_3)\n\n- **Brief Summary:**\n  The conversation revolves around the debate on whether code, testing, and development infrastructure should be prioritized over comprehensive documentation in software development. Speaker_1 advocates for prioritizing core code and testing, especially in early project stages, while speaker_2 emphasizes the necessity of documentation for continuity and avoiding knowledge silos. Speaker_3 introduces a balanced approach depending on project context and phase, and speaker_4 underscores the integration of documentation with development for synergy and resilience.\n\n- **Final Outputs/Artifacts/Takeaways:**\n  - Recognition of the importance of a balanced approach between prioritizing code, testing, and infrastructure and maintaining comprehensive documentation.\n  - Understanding that the project's phase and specific needs should dictate the balance between these priorities.\n  - Emphasis on tools and methodologies that integrate documentation into the development process, like documentation-as-code.\n  - Advocacy for agile and iterative documentation alongside development to maintain project velocity and knowledge retention.\n\n- **Characteristics/Dynamic:**\n  The dynamic is **collaborative**, even though there's an inherent tension in prioritizing different project facets. The speakers build on each other's points, aiming for a cohesive strategy that respects both swift development and comprehensive documentation. They support a nuanced, context-sensitive approach rather than a one-size-fits-all method, indicating a shared goal of sustainable and efficient software development.\n\n\nIt seems that speaker 4 also takes a middle ground, but is a bit biased towards the second position of integrating documentation. I think we might get diminishing returns with adding more speakers in the current rigid structure without some more complicated instructions, so we could just use 3 for now. I think ideally, we’d like to move to self-organizing conversations that aren’t necessarily debates.\n\n\nExperiment 4\nI think one final interesting thing we could do is remove the mediator from the chat history, since they don’t really provide anything. We can just inject the instructional message at the end of the chat history right before we call the API to direct the next speaker, but we don’t need to persist it. The transcript technically won’t be complete, but maybe we can see some differences in the formality of the responses if the mediator is not considered.\n\n# code to simulate the conversation\ndef run_organic_conversation(\n    iterations: int, \n    openai_model_id: str,\n    participant_count: int,\n    debate_topic: str\n) -&gt; list[dict]:\n    # model 1 is the first speaker\n    debate_history = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": \"The debate topic is: \" + debate_topic}\n    ]\n\n    for _ in tqdm(range(iterations)):\n        for model in range(1, participant_count + 1):\n            speaker_id = f\"speaker_{model}\"\n            response = client.chat.completions.create(\n                model = openai_model_id,\n                messages = debate_history + [{\"role\": \"user\", \"content\": f\"{speaker_id}, it's your turn to speak.\"}],\n                store = False\n            );\n            message = response.choices[0].message.content\n            debate_history.append({\"role\": \"assistant\", \"name\": speaker_id, \"content\": message})\n\n    return debate_history\n\n\ndebate_4 = run_organic_conversation(2, 'gpt-4o', 3, DEBATE_TOPIC)\n\n100%|██████████| 2/2 [00:28&lt;00:00, 14.20s/it]\n\n\n\nconversation_transcript_4 = save_conversation(\"conversation_transcript_4.txt\", debate_4)\n\nconversation_transcript_4.txt\n\n\n\n\nAnalysis\nLet’s see if that had any impact on the debate.\n\nanalyze_conversation(conversation_transcript_4)\n\n- **Brief Summary:** The discussion revolves around the prioritization of code, testing, and development infrastructure versus comprehensive documentation in software projects. Speaker 1 advocates for prioritizing code and testing to ensure product reliability and rapid market delivery. Speaker 2 argues for the importance of comprehensive documentation to aid in knowledge transfer, maintainability, and regulatory compliance. Speaker 3 suggests a balanced approach, tailored to project requirements, integrating documentation into development practices through tools and automation.\n\n- **Final Outputs/Artifacts/Takeaways:** The conversation concludes with a consensus on the necessity of balance and context-specific approaches. Key artifacts to consider include the integration of automated documentation tools, ensuring documentation evolves with the codebase, and prioritizing based on project needs and industry regulations. Additionally, a continuous review process is recommended to align with evolving project goals.\n\n- **Characteristics/Dynamic:** The dynamic of the conversation is collaborative and constructive, with each speaker acknowledging the validity of the other's perspectives. Speaker 3 plays the role of a mediator, emphasizing the importance of balance and flexibility, while Speaker 1 and 2 provide robust arguments for their respective stances. The conversation remains solution-focused, highlighting strategies to integrate the strengths of both approaches effectively.\n\n\nI don’t think this changed much about the date. It seems like the roles are very similar to before, with the positions being very comparable. I think we may need some fundamental changes to the structure of the conversation in order to bring about more natural responses."
  },
  {
    "objectID": "posts/002_another_llm_conversation/another_llm_conversation.html#closing-remarks",
    "href": "posts/002_another_llm_conversation/another_llm_conversation.html#closing-remarks",
    "title": "Another LLM Conversation",
    "section": "Closing Remarks",
    "text": "Closing Remarks\nCompared to the other approach that we explored in the previous blog, it seems that sharing a chat window allows us to more easily manage the flow of a debate with similar results to before, accounting for the changes in the system prompt. To truly identify the differences between these two approaches, I think it is necessary to construct more complicated social scenarios and develop a standardized way to evaluate in what ways we see some true differences. To generalize, the importance of using “user” versus “assistant” responses to represent different participants in conversations involving multiple LLMs to influence desired results is a possible research path that we can look into for the blog.\nHowever, with this new system prompt, it seems we come out with less concrete conclusions than before. That could be a detriment to the usefulness of this system prompt as a tool, but it could also bring us closer to real conversations. In reality, not all conversations end in a way that can be nicely wrapped up and applied to a real world problem. However, we do see many useful things come out of conversations in practice in our lives, with both AI and others. Seamlessly integrating AI in a way that adds to conversations seems like it requires a more “realistic” formulation.\n\nNote: Just wanted to acknowledge that we could probably specify in the system prompt that models should introduce more evidence and be clearer in their rebuttal structure, which could help make the conversation more helpful for listeners.\n\nIn terms of immediate ways we can build on this work, I’m interested in simulating a less rigid environment. In the real world, chats are not strictly turn-based (in that they follow a set order, and that each speaker always speaks). If we can introduce spontaneity (with randomness, for example), I wonder if we could increase the breadth of chats that we see.\n\nFuture Work: - Introduce spotaneous elements to the conversation (immediate focus) - Evaluate using “user” versus “assistant” to represent various participants in the conversation - System prompt changes (mentioned before)"
  }
]